{
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 384.62518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-04T21:49:40Z",
      "updated_at": "2021-11-13T20:48:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:50:19Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.6195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 384.62518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 363.12488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up <em>Infinite</em> <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-04T21:49:40Z",
      "updated_at": "2021-11-13T20:48:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.62488,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.45352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.7586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.0993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.45337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.75842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.09918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.45337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.75842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.09918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.45322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.7583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.45322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.7583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.81888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.80359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> data, telemetry tools rely on data sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.79857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.81888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.80359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> data, telemetry tools rely on data sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.79857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-04T21:52:51Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.64621,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.81888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.80359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that <em>data</em> into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> <em>data</em>, telemetry tools rely on <em>data</em> sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-04T21:52:51Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.6462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.81879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.8035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that <em>data</em> into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> <em>data</em>, telemetry tools rely on <em>data</em> sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-04T21:50:18Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.81879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:58Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.8035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that <em>data</em> into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> <em>data</em>, telemetry tools rely on <em>data</em> sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-04T21:47:12Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.79846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> <em>data</em>, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/errors-inbox/error-limiting": [
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-04T21:33:05Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.95651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "sections": [
        "Know your data limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting system limits",
        "Account-level limits",
        "Data ingest API limits",
        "Finding other agent and integration limits"
      ],
      "title": "Know your data limits",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "7c540d94a8b5e4f024d175ad53cab9fab343187c",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/view-system-limits/",
      "published_at": "2021-12-04T21:46:36Z",
      "updated_at": "2021-10-31T06:37:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting system limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Distributed tracing: Max age of span timestamp values 20 minutes. Timestamp must be within 20 minutes of current time at ingest or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Distributed tracing: Max spans per minute per account Dependent on agreement. Max limit: 2M. Distributed tracing: Max spans per trace 50K Distributed tracing: Max attributes per span 200 Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest API limits Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Finding other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our quickstarts here. Some default reporting limits are located in these tools' configuration docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.62036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Know your data <em>limits</em>",
        "sections": "Know your data <em>limits</em>",
        "body": " monitoring a new high-traffic application, or have a sudden data spike. When you do <em>reach</em> a <em>limit</em>, New Relic responds according to the type of data and the <em>limit</em> that’s <em>reached</em>. For example: We place a <em>limit</em> on the number of ingested requests per minute (RPM) per data type. When this <em>limit</em> is <em>reached</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "7ac33e47dfcfb91089e020a39097c9d648389f51",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/query-limits/",
      "published_at": "2021-12-04T21:46:37Z",
      "updated_at": "2021-11-13T19:58:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events provide data on many limits types, resource limit metrics currently only cover request rate ingestion and API query rate limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit that’s reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesn’t always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if you’re barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, you’ll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, you’ll see a 0. An NrIntegrationError event is generated when you experience impact and is a good way to quickly see if you’re experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIntegrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries limit max Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName limit max Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute limit max Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource you’re currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit max Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName: The Name of the limit for the metric data, for example RPM Metric API. dataType: What kind of data the metric is tracking, for example Metric, Log, or APM. Resource: What resource is being consumed, for example Requests or DPM. limitTimeInterval: What time window this resource is evaluated for limiting. consumingAccountId: The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType: The kind of data that is being impacted, for example Metric, Log, or APM. Resource: What resource is being impacted, for example Request Rate. Impact: A count of what is happening when resource has exceeded set limit, for example dropped requests. consumingAccountId: The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.75355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query system <em>limits</em>",
        "sections": "What happens when you <em>reach</em> a <em>limit</em>",
        "tags": "system <em>limits</em>",
        "body": " insight into your limits status. Important While NrIntegration<em>Error</em> events provide data on many limits types, resource <em>limit</em> metrics currently only cover request rate ingestion and API query rate limits. What happens when you <em>reach</em> a <em>limit</em> Our response to reaching a <em>limit</em> depends on a handful"
      },
      "id": "608abed9196a67a63064a7a6"
    }
  ],
  "/docs/errors-inbox/errors-inbox": [
    {
      "image": "https://docs.newrelic.com/static/45de34e3a56f26f44cbd62f69d1bb8b6/ae694/error.png",
      "url": "https://docs.newrelic.com/whats-new/2021/06/errors-inbox/",
      "sections": [
        "Errors Inbox: Error tracking across your entire stack"
      ],
      "published_at": "2021-12-05T09:28:50Z",
      "title": "Errors Inbox: Error tracking across your entire stack",
      "updated_at": "2021-06-25T12:10:39Z",
      "type": "docs",
      "external_id": "9ee9b292d1ae812a2b6cff8dbf6f0a2b19a9caa0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Recently, we launched New Relic Errors Inbox, an error tracking solution that provides you a single place to view, triage and resolve errors across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates in our blog post and watch a demo in the latest Nerdlog episode here. What’s Included with New Relic Errors Inbox: Errors Inbox. Errors are grouped and displayed on a single screen for visibility and easy triaging. Filter to just the applications and services that you care about. Rich Error Details. Resolve errors faster with context of the full stack, including APM, Browser (RUM), Mobile, and Serverless (AWS Lambda Function) data. Error data persists to provide continued context for recurring errors. Log Data. Logs in Context are provided alongside other error data right in the error group details for even more information to resolve errors faster. Cross Team Collaboration. Work errors as a team with shared error visibility, shared comments, and an integration with Slack. Next Steps New Relic Errors Inbox is available to all New Relic Full-Stack Observability customers in the U.S. datacenter. To enable Errors Inbox, sign up for a free account or log in to your existing account and follow these steps: From one.newrelic.com, select More in the top right and click Errors Inbox. If this is your first time accessing Errors Inbox, you will be prompted to select a workload in the top left.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.40396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "sections": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "body": "Recently, we launched New Relic <em>Errors</em> <em>Inbox</em>, an <em>error</em> <em>tracking</em> solution that provides you a single place to view, triage and resolve <em>errors</em> across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates"
      },
      "id": "60d5c7bfe7b9d208f1d67792"
    },
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-04T21:33:05Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.91945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "image": "https://docs.newrelic.com/static/43b6374d961bba813b6b0cac7118cf56/ae694/Errorsinbox_Jira.png",
      "url": "https://docs.newrelic.com/whats-new/2021/11/EI_Jira/",
      "sections": [
        "The Jira integration for errors inbox is now available",
        "We’re excited to announce the New Relic errors inbox Jira integration."
      ],
      "published_at": "2021-12-08T01:44:15Z",
      "title": "The Jira integration for errors inbox is now available",
      "updated_at": "2021-11-23T21:24:24Z",
      "type": "docs",
      "external_id": "9647462564e73c6366b152c94f58512b2d52d94d",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’re excited to announce the New Relic errors inbox Jira integration. With the Jira integration you can start tracking, managing, and updating tickets from New Relic errors inbox. Continue to work and collaborate in the tools you're already familiar with without losing context, for faster error resolution. Start your errors inbox journey today!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.55267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The Jira integration for <em>errors</em> <em>inbox</em> is now available",
        "sections": "The Jira integration for <em>errors</em> <em>inbox</em> is now available",
        "body": "We’re excited to announce the New Relic <em>errors</em> <em>inbox</em> Jira integration. With the Jira integration you can start <em>tracking</em>, managing, and updating tickets from New Relic <em>errors</em> <em>inbox</em>. Continue to work and collaborate in the tools you&#x27;re already familiar with without losing context, for faster <em>error</em> resolution. Start your <em>errors</em> <em>inbox</em> journey today!"
      },
      "id": "619d5c0828ccbc3c38b993a7"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-04T21:48:30Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, we’ll explain the definition of metrics from a monitoring industry perspective, and then we’ll explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minute’s time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a “CPU% used” status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be “rolled up” to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, we’ll explain the definition of events from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply “things that occur in a system.” For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, we’ll explain the definition of logs from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, we’ll explain the definition of traces from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a program’s subroutines. For large modern systems, which are often distributed across many services and micro-services, “tracing” often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "New Relic <em>data</em> types",
        "tags": "Ingest and manage <em>data</em>",
        "body": " to &quot;metrics,&quot; regardless of how that <em>data</em> is reported, unless there&#x27;s a reason you need to know more (like understanding how to query your <em>data</em>). Here are some of the ways metrics are reported and stored across the New Relic <em>platform</em>: Dimensional metrics (used by Metric <em>API</em> and many integrations"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "Amazon API Gateway monitoring integration",
        "Features",
        "Requirements",
        "Tip",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Inventory data",
        "Dimensions"
      ],
      "title": "Amazon API Gateway monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "dbeb75bde2ffb29fe6c7eb41b536fa477c2b80ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration/",
      "published_at": "2021-12-04T16:57:48Z",
      "updated_at": "2021-10-23T16:39:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon API Gateway data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features Amazon's API Gateway is a fully managed service that allows you to create, publish, maintain, monitor, and secure APIs at any scale. With the New Relic API Gateway integration, you get more data about how your API layer is working behind the scenes. You'll receive metric data about the number of API calls, the requests served, the number of errors, latency counts, and more. You can monitor and alert on your API Gateway data directly from New Relic, and query data and create dashboards. Requirements API Gateway will not send \"Call count by resource\", \"4xx error by resource\" and \"5xx errors by resource\" metrics unless you have explicitly enabled detailed CloudWatch metrics. Tip Enabling these metrics may add additional charges to your Amazon CloudWatch account pricing. To enable CloudWatch metrics, use either of these options: Go to the AWS Management Console, select the Settings option for CloudWatch, then select the option to enable detailed CloudWatch metrics. Call the stage:update action of the Amazon API Gateway REST API to update the metricsEnabled property to true. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon API gateway integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the API Gateway integration links. You can query and explore your data using the ApiGatewaySample event type. For more on how to use your data, see Understand and use integration data. Metric data This New Relic infrastructure integration collects the following Amazon API Gateway data: Metric Description 4XXError The number of client-side errors captured 5XXError The number of server-side errors captured. CacheHitCount The number of requests served from the API cache. CacheMissCount The number of requests served from the back end when API caching is enabled. Count The number of calls to API methods. IntegrationLatency The time in milliseconds between when API Gateway relays a request to the back end and when it receives a response from the back end. Latency The time in milliseconds between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Inventory data Inventory data provides information about the service's state and configuration. API Gateway configuration options are reported as inventory data. For more about inventory data, see Understand and use data. Object Inventory data /aws/apigateway/api apiId apiName awsRegion /aws/apigateway/resource awsRegion methods resource resourceid /aws/apigateway/stage apiName awsRegion cacheClusterEnable cacheClusterSize cacheClusterStatus lastUpdatedDate stageName /aws/apigateway/stage/variables value /aws/apigateway/stage/settings CacheDataEncrypted CacheTtlInSeconds CachingEnabled DataTraceEnabled LoginLevel MetricsEnabled RequireAuthorizationForCacheControl UnauthorizedCacheControlHeaderStrategy ThrottlingBurstLimit ThrottlingRateLimit /aws/apigateway/stage/resource-with-metrics apiName awsRegion method resource stageName Dimensions You can use the dimensions in the following table to filter API Gateway metrics. Dimensions Description ApiName Filters API Gateway metrics for an API of the specified API name. ApiName, Method, Resource, Stage Filters API Gateway metrics for an API method of the specified API, stage, resource, and method. ApiName, Stage Filters API Gateway metrics for an API stage of the specified API and stage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.93303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "sections": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "body": ", and more. You can monitor and alert on your <em>API</em> <em>Gateway</em> <em>data</em> directly <em>from</em> New Relic, and query <em>data</em> and create dashboards. Requirements <em>API</em> <em>Gateway</em> will not send &quot;Call count by resource&quot;, &quot;4xx error by resource&quot; and &quot;5xx errors by resource&quot; metrics unless you have explicitly enabled detailed CloudWatch"
      },
      "id": "617db3a028ccbc92a1801133"
    },
    {
      "sections": [
        "Azure API Management monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "API Management Service data"
      ],
      "title": "Azure API Management monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b4592ae87ea541c9673052fe5c9ee2392ab4926e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/azure-integrations-list/azure-api-management-monitoring-integration/",
      "published_at": "2021-12-04T17:47:04Z",
      "updated_at": "2021-10-23T17:36:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Microsoft Azure API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure API Management integration: New Relic polling interval: 5 minutes View and use data To view your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. Data is attached to the following event type: Entity Event type Provider Service AzureApiManagementServiceSample AzureApiManagementService For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure API Management data for Service. API Management Service data Metric Unit Description totalRequests Count The total number of gateway requests in a given period. successfulRequests Count The total number of successful gateway requests in a given period. unauthorizedRequests Count The total number of unauthorized gateway requests in a given period. failedRequests Count The total number of failed gateway requests in a given period. otherRequests Count The total number of gateway requests in a given period that do not fall into the successful, unauthorized, or failed categories. durationMilliseconds Milliseconds The time between when API Management receives a request from a client and when it returns a response to the client. capacityPercent Percent Indicator of load on an API Management instance. eventHubTotalEvents Count The total number of events sent to EventHub from API Management in a given period. eventHubSuccessfulEvents Count The total number of successful EventHub events in a given period. eventHubTotalFailedEvents Count The total number of failed EventHub events in a given period. eventHubRejectedEvents Count The total number of rejected EventHub events (wrong configuration or unauthorized) in a given period. eventHubThrottledEvents Count The total number of throttled EventHub events in a given period. eventHubTimedoutEvents Count The total number of timed out EventHub events in a given period. eventHubDroppedEvents Count The total number of events skipped because of queue size limit reached in a given period. eventHubTotalBytesSentBytes Bytes The total size of EventHub events in bytes in a given period.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.09315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Azure <em>API</em> Management monitoring integration",
        "sections": "<em>API</em> Management Service <em>data</em>",
        "body": " Azure <em>API</em> Management <em>data</em> for Service. <em>API</em> Management Service <em>data</em> Metric Unit Description totalRequests Count The total number of <em>gateway</em> requests in a given period. successfulRequests Count The total number of successful <em>gateway</em> requests in a given period. unauthorizedRequests Count The total"
      },
      "id": "617da8f428ccbcc09f7ff203"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-04T17:00:58Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.96524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71165,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71165,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80211,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80211,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80191,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-04T17:00:58Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.9652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80191,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-04T17:00:58Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.96516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.80139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.7115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.83752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.8012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-04T17:09:37Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.71149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.976654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.824104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.45547,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.13092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.48407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.45546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.13091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.483795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.45546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.48406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.483795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.45546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.13091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.48406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.130905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.484055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.48379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.45546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.130905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-04T17:12:46Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.484055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.976494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.8241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.976494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.72405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.97644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.97644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.97644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.976395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95761,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.976395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95761,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.1812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " to 24 hours. Inventory: the Inventory page is not supported with AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> (inventory telemetry is not included in the <em>stream</em>). <em>Integrations</em> not fully replaced by <em>metric</em> <em>streams</em> The AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration only collects <em>CloudWatch</em> metrics, resource metadata"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/cloud-integration-release-notes/new-aws-cloudwatch-metric-stream/",
      "sections": [
        "AWS CloudWatch Metric Streams",
        "New"
      ],
      "published_at": "2021-12-05T02:37:01Z",
      "title": "AWS CloudWatch Metric Streams",
      "updated_at": "2021-12-04T09:48:54Z",
      "type": "docs",
      "external_id": "8f8aa5c15a6e2ce7415de7dcb59c5c053989a8f7",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "New Amazon CloudWatch Metric Streams is a new way to send metrics for all AWS services and custom namespaces to New Relic One. Learn more from the following resources: New Relic blog post AWS News blog New Relic Product Documentation",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em>",
        "sections": "AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em>",
        "body": "New <em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> is a new way to send metrics for all AWS services and custom namespaces to New Relic One. Learn more from the following resources: New Relic blog post AWS News blog New Relic Product Documentation"
      },
      "id": "61ab398664441fe025927cdc"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-04T17:13:23Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.54242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration is the recommended solution to monitor all <em>CloudWatch</em> metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-04T17:07:45Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.97633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-04T17:01:49Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.95756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-04T17:13:59Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.65987,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.51804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-04T17:17:04Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.19716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-04T17:17:04Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.36084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-04T17:17:04Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.58286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-04T17:17:04Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.48555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.77753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "617db44c28ccbc965d80120d"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.48553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.34897,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "6373cb619a787c0a22f4d91c954cd2a8d6ad3b41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2021-12-04T17:17:40Z",
      "updated_at": "2021-11-13T16:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName, awsRegion, ecsLaunchType and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName, ecsLaunchType and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.24902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "617db48de7b9d24953c05054"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.65984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "2adc4dd0bff89ea0d3e05fa756ba4d30adf9bf53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-12-04T17:17:04Z",
      "updated_at": "2021-10-24T01:53:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "617db48e64441f3722fbe764"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.65982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-04T17:16:25Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.51797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.9444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.23961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.9444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.23961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.23961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.23961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.2396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataproc-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.2396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-database-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.2396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-hosting-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-04T17:22:32Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-04T17:21:21Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.94096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "8a2aa784d97c13b6ecfc505764f371f6b57be3dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-12-04T17:23:44Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.2396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dbadce7b9d2024bc03f1c"
    }
  ]
}