{
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.0305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Outlier detection (NRQL alert)",
        "Important",
        "What is outlier detection?",
        "Tip",
        "Example use cases",
        "Notify if load-balanced servers have uneven workload",
        "Notify if load-balanced application has misbehaving instances",
        "Notify of changes in different environments",
        "Notify for timezone-related changes",
        "Create an outlier alert condition",
        "Rules and logic",
        "Details about alert condition logic",
        "NRQL query rules and limits",
        "Zero values for unreturned data"
      ],
      "title": "Outlier detection (NRQL alert)",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "499fa55abd48a0ccdd897fbdf64ccea2d9f98d11",
      "image": "https://docs.newrelic.com/static/f235d0630576bc2010ff07adc7a69621/f73a1/NRQL_outlier_violations.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert/",
      "published_at": "2021-12-05T05:06:51Z",
      "updated_at": "2021-11-25T19:50:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts offers NRQL conditions in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and NRQL queries, and explains how to create an outlier condition. Important NRQL alerts do not affect Alerts policies for a Synthetic monitor. For example, muting a NRQL alert will not mute a Synthetic monitor's alerts. What is outlier detection? In software development and operations, it is common to have a group consisting of members you expect to behave approximately the same. For example: for servers using a load balancer, the traffic to the servers may go up or down, but the traffic for all the servers should remain in a fairly tight grouping. See outlier detection in action in this NerdBytes video (2:51 minutes). The NRQL alert outlier detection feature parses the data returned by your faceted NRQL query and: Looks for the number of expected groups that you specify Looks for outliers (values deviating from a group) based on the sensitivity and time range you set Additionally, for queries that have more than one group, you can choose to be notified when groups start behaving the same. This visual aid will help you understand the types of situations that will trigger a violation and those that won't. For more on the rules and logic behind this calculation, see Outlier detection rules. Tip Note: this feature does not take into account the past behavior of the monitored values; it looks for outliers only in the currently reported data. For an alert type that takes into account past behavior, see Baseline alerting. Example use cases These use cases will help you understand when to use the outlier threshold type. Note that the outlier feature requires a NRQL query with a FACET clause. Notify if load-balanced servers have uneven workload A load balancer divides web traffic approximately evenly across five different servers. You can set a notification to be sent if any server starts getting significantly more or less traffic than the other servers. Example query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Notify if load-balanced application has misbehaving instances Application instances behind a load balancer should have similar throughput, error rates, and response times. If an instance is in a bad state, or a load balancer is misconfigured, this will not be the case. Detecting one or two bad app instances using aggregate metrics may be difficult if there is not a significant rise in the overall error rate of the application. You can set a notification for when an app instance’s throughput, error rate, or response time deviates too far from the rest of the group. Example query: SELECT average(duration) FROM Transaction WHERE appName = 'MY-APP-NAME' FACET host Copy Notify of changes in different environments An application is deployed in two different environments, with ten application instances in each. One environment is experimental and gets more errors than the other. But the instances that are in the same environment should get approximately the same number of errors. You can set a notification for when an instance starts getting more errors than the other instances in the same environment. Also, you can set a notification for when the two environments start to have the same number of errors as each other. Notify for timezone-related changes The number of logged in users for a company is about the same for each of four applications, but varies significantly by each of the three time zones the company operates in. You can set a notification for when any application starts getting more or less traffic from a certain timezone than the other applications. Sometimes the traffic from the different time zones are the same, so you would set up the alert condition to not be notified if the time zone groups overlap. For more details on how this feature works, see Outlier rules and logic. Create an outlier alert condition To create a NRQL alert that uses outlier detection: When creating a condition, under Select a product, select NRQL. For Threshold type, select Outlier. Create a NRQL query with a FACET clause that returns the values you want to alert on. Depending on how the returned values group together, set the Number of expected groups. Adjust the deviation from the center of the group(s) and the duration that will trigger a violation. Optional: Add a warning threshold and set its deviation. Set any remaining available options and save. Rules and logic Here are the rules and logic behind how outlier detection works: Details about alert condition logic After the condition is created, the query is run once every harvest cycle and the condition is applied. Unlike baseline alerts, outlier detection uses no historical data in its calculation; it's calculated using the currently collected data. Alerts will attempt to divide the data returned from the query into the number of groups selected during condition creation. For each group, the approximate average value is calculated. The allowable deviation you have chosen when creating the condition is centered around that average value. If a member of the group is outside the allowed deviation, it produces a violation. If Trigger when groups overlap has been selected, Alerts detects a convergence of groups. If the condition is looking for two or more groups, and the returned values cannot be separated into that number of distinct groups, then that will produce a violation. This type of “overlap” event is represented on a chart by group bands touching. Because this feature does not take past behavior into account, data is never considered to \"belong\" to a certain group. For example, a value that switches places with another value wouldn't trigger a violation. Additionally, an entire group that moves together also wouldn't trigger a violation. NRQL query rules and limits The NRQL query must be a faceted query. The number of unique values returned must be 500 or less. If the query returns more than this number of values, the condition won't be created. If the query later returns more than this number after being created, the alert will fail. Zero values for unreturned data When a query returns a set of values, only values that are actually returned are taken into account. If a value is not available for calculation (including if it goes from being collected one harvest cycle to not being collected), it is rendered as a zero and is not considered. In other words, the behavior of unreturned zero values will never trigger violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.17238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Outlier detection (NRQL <em>alert</em>)",
        "sections": "Create an outlier <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> offers NRQL <em>conditions</em> in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and NRQL queries, and explains how to create an outlier condition. Important NRQL <em>alerts</em> do not affect <em>Alerts</em> policies"
      },
      "id": "6130be72196a6793654948e7"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-12-08T01:43:24Z",
      "updated_at": "2021-11-24T14:48:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Ready to get started? Make sure you have a New Relic account. It's free, forever! Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.91104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.0305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View violation and event details for incidents",
        "View the incidents index and violation details",
        "Tip",
        "View the events in an incident",
        "Time between violation and notification",
        "Anomalous behavior detection",
        "Alerts notification in Slack"
      ],
      "title": "View violation and event details for incidents",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert incidents"
      ],
      "external_id": "7c01873917140e1922227598b7532b36343e308a",
      "image": "https://docs.newrelic.com/static/5878dd9ec30c9251961517a34ba88dc5/8c557/screen-alerts-incident-page_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents/",
      "published_at": "2021-12-04T21:26:05Z",
      "updated_at": "2021-11-06T13:12:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When violations of the threshold set in a condition occur, depending on the policy's Incident preference settings, Alerts may create an incident. You can review information about incidents in several ways: View the incidents index so you can scan for patterns in a list of incidents. View the violations included in a specific incident to examine associated performance details. View the events included in a specific incident to review the timestamps for events, such as a violation opening or closing, notifications, and acknowledgments. one.newrelic.com > Alerts & AI > Incidents > (select an incident): Notice that the condition's threshold was violated around 2pm (the blue line went over the red dotted line), but the alert wasn't triggered until the violation occurred for more than five minutes, as specified in the condition. View the incidents index and violation details Violations are grouped together into incidents. If you want to change how violations are grouped, open the associated policy and change the Incident preference setting. To view violation details: In the one.newrelic.com top nav, click Alerts & AI, click Incidents, then click Open incidents or All incidents. Select an incident row. Click Violations to view a list of the violations included in this incident. Select one of the violations to see a chart and details for it. Details for individual violation charts include: Timing information: The shaded red area on the chart shows you the time period when the violation occurred, where the preceding shaded pink area represents the degradation period. If you select a violation that lasted longer than two hours, the timeline on the bottom of the chart will be jagged. To provide context for events in the incident, the chart also shows the time frame surrounding the violation. Chart guidelines: The red dotted line marks the threshold for the condition. The blue line depicts performance information. Anomalous behavior: If Alerts detects anomalous behavior near the time of the violation, you'll see a notification in the violation details. From this page, you can take action regarding the incident: If you want to... Do this Assume responsibility for the incident Acknowledge the incident by selecting the acknowledge icon or button. View information about events Mouse over any spot on the blue line in the chart to display event information. Manually close the violation Below the chart, select the Manually close violation link. Tip Anyone in the account who can view the violation can also close it. Edit the policy or condition Select the Settings gear icon or select the name of the policy above the chart. View the events in an incident If you want to view alerting events across all products, go to one.newrelic.com, then click Explorer. To view the events for just one incident: Go to one.newrelic.com, then click Explorer. Select an entity row. In the left nav under Events, click Violations. Select one of the events to view a chart and details for it. Time between violation and notification There may be a difference of up to three minutes between the violation event time and the initial notification time due to variances in data processing time. Notification time: The time in the notification reflects the timestamp of when we received the request to deliver a notification. Violation time: The time you see on the Events page for the violation reflects the timestamp of data collection for the last data point that contributed to opening the violation. Anomalous behavior detection When we detect large changes in key signals in the alerting entity and/or upstream/downstream applications of the alerting entity, an \"anomalous behavior detected\" notification appears on the violation's page and in notification channels. You can: Expand the notification for details about the detected anomaly (web only). See upstream/downstream anomalies (Slack only). Select a link to go to the relevant product chart for further investigation. Alerts notification in Slack Example of an \"anomalous behavior detected\" notification in Slack.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.98093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View violation <em>and</em> event details for <em>incidents</em>",
        "sections": "View violation <em>and</em> event details for <em>incidents</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "When violations of the threshold set in a condition occur, depending on the policy&#x27;s Incident preference settings, <em>Alerts</em> may create an incident. You can review information about <em>incidents</em> in several ways: View the <em>incidents</em> index so you can scan for patterns in a list of <em>incidents</em>. View"
      },
      "id": "60440c01196a67ba9c960f3c"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.0304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.5249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-11-24T04:37:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. Ready to get started? Make sure you have a New Relic account. It's free, forever! After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.43416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " <em>incidents</em>, and automatically detects anomalies. By applying machine learning to your data and feedback, <em>Applied</em> <em>Intelligence</em> is designed to improve functionality and deliver smarter context over time. Ready to get started? Make sure you have a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever! After connecting your"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/delete-alert-notification-channels": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-12-05T04:12:40Z",
      "updated_at": "2021-11-07T10:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. Possible values: (object) \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.37381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " violation_chart_url=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-12-05T04:12:40Z",
      "updated_at": "2021-11-07T10:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. Possible values: (object) \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.3738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " violation_chart_url=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/notification-channels-control-where-send-alerts": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-12-05T04:12:40Z",
      "updated_at": "2021-11-07T10:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. Possible values: (object) \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.3738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " violation_chart_url=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/test-alert-notification-channels": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-12-05T04:12:40Z",
      "updated_at": "2021-11-07T10:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. Possible values: (object) \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.37378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " violation_chart_url=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-12-05T04:12:40Z",
      "updated_at": "2021-11-07T10:00:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. Possible values: (object) \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.37378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " violation_chart_url=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/create-edit-or-find-alert-policy": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.03006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing model",
        "Original pricing model",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-12-04T15:31:54Z",
      "updated_at": "2021-11-14T07:53:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing model or our New Relic One pricing model: New Relic One pricing model See Users and roles. Original pricing model For accounts on our original product-based pricing model, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.1423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, mobile monitoring, synthetic monitoring, etc.) any <em>New</em> <em>Relic</em> product"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/specify-when-alerts-create-incidents": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.03006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing model",
        "Original pricing model",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-12-04T15:31:54Z",
      "updated_at": "2021-11-14T07:53:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing model or our New Relic One pricing model: New Relic One pricing model See Users and roles. Original pricing model For accounts on our original product-based pricing model, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.1423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, mobile monitoring, synthetic monitoring, etc.) any <em>New</em> <em>Relic</em> product"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/update-or-disable-policies-conditions": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.02995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing model",
        "Original pricing model",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-12-04T15:31:54Z",
      "updated_at": "2021-11-14T07:53:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing model or our New Relic One pricing model: New Relic One pricing model See Users and roles. Original pricing model For accounts on our original product-based pricing model, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.14229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, mobile monitoring, synthetic monitoring, etc.) any <em>New</em> <em>Relic</em> product"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/view-policies-conditions-our-products": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.02995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing model",
        "Original pricing model",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-12-04T15:31:54Z",
      "updated_at": "2021-11-14T07:53:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing model or our New Relic One pricing model: New Relic One pricing model See Users and roles. Original pricing model For accounts on our original product-based pricing model, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.14229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> <em>policies</em>: <em>Alert</em> policy name 1 character 64 characters <em>Policies</em> per account n&#x2F;a 10000 <em>policies</em> Products per policy any <em>New</em> <em>Relic</em> product (APM, mobile monitoring, synthetic monitoring, etc.) any <em>New</em> <em>Relic</em> product"
      },
      "id": "60442974196a678217960f33"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click <em>Policies</em>. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.02985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Violation event attributes",
        "What is a violation event?",
        "Important",
        "BETA FEATURE"
      ],
      "title": "Violation event attributes",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "4c7da02e30f309b8bc6ac1bc3c49d3b610f3d9eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes/",
      "published_at": "2021-12-05T04:53:28Z",
      "updated_at": "2021-10-31T08:15:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see Alerts concepts. What is a violation event? The violation of a condition generates a violation event. This event has various attributes (metadata) attached to it and different attributes can be used by different features. Important The violation event is a concept used to determine alerting features. While you can query some of its associated attributes via NerdGraph, you cannot directly query the violation event. Violation event attributes This table shows violation event attributes. The violation event data type is collected in NrAiIncident. BETA FEATURE NrAiIncident is still in development, so may be subject to unannounced changes, but we encourage you to try it out! You may be wondering why we're using NrAiIncident as the name for the violation event data type. Although we currently refer to these events as \"violations,\" they'll be called \"incidents\" in our new, upcoming naming scheme. This name prepares for and reflects our future intentions. All attributes are available for use in a description. Read about attributes available for muting rules. Attribute Description accountId The ID of the account where the violation occurred. Available for muting rules. aggregationDuration The active condition's aggregation window. closeCause If applicable, what caused the incident to close. Available values: CONDITION_DELETED, POLICY_DELETED, EVALUATOR, EXPIRED, CONDITION_MODIFIED, LOSS_OF_SIGNAL, USER, TARGET_REMOVED, and CONDITION_DISABLED. closeTime If applicable, the timestamp when the incident was closed. closeViolationsOnExpiration If true, open violations on the signal are closed if the signal is lost. Default is false. To use this field, an expirationDuration must be specified. conditionId The ID of the condition that triggered the violation. Available for muting rules. conditionName The name of the condition that triggered the violation. Available for muting rules. degradationTime The timestamp when the targeted metric started to breach the active condition’s threshold. description The contents of the active condition’s Violation Description field. NRQL or Infrastructure conditions only. entity.guid The targeted entity's globally unique identifier, if available. Available for muting rules. entity.name The targeted entity's name, if available. entity.type The targeted entity's type, if available. evaluationOffsetSeconds The active condition's evaluation offset. A time delay (in seconds) to ensure data points are placed in the correct aggregation window. If you use the Delay/timer setting in the UI, it clears evaluationOffsetSeconds and uses Delay/timer instead. evaluationType The reason the violation was opened. Available values: Threshold (the condition threshold was breached) Expiration (the entity's signal was lost) event The record's event type. Available values: Open and Close. expirationDuration The active condition's signal loss time window. incidentID The unique identifier of the violation. muted Shows whether the active condition was muted at the time of the violation event. mutingRuleID The unqiue identifier of the muting rule that caused the violation to be muted. nrqlEventType The type of data targeted by a NRQL condition. In this context, this refers to any NRQL-queryable data type. Available for muting rules. nrqlQuery The full string of the NRQL query. Can be used for sub-string matching on attributes in the WHERE clause. Available for muting rules. openTime The timestamp when the violation was opened. operator The violation threshold's operator, such as =, <, or >. For signal loss violations, this is an empty string. policyId The ID of the policy that triggered the violation. Available for muting rules. policyName The name of the policy that triggered the violation. Available for muting rules. priority The level of the violation: warning or critical. recoveryTime The timestamp when the active condition's targeted metric stops breaching the threshold. runbookUrl The runbook URL for the condition that triggered the violation. Available for muting rules. tags.* Arbitrary key-value metadata, or tags, associated with the violation. tags. is the prefix and * is the metadata/tag name. For details on how to use this, see the documentation for muting rules or description. Available for muting rules. targetName The name of the violation’s target. This can be an entity or a query. Available for muting rules. threshold The active condition's threshold value. thresholdDuration The active condition's threshold time window. thresholdOccurrences Shows whether for at least or at least once in occurrence values are being used in the active condition's threshold. Available values: all or any. timestamp The event's wall clock time using an epoch timestamp. title The incident's title. type The incident's type. Available value: Incident. valueFunction The active condition's aggregation function. Used in APM, browser, and mobile alert condition types. violationTimeLimitSeconds The active condition's violation time limit setting. violationUuId Deprecated. Do not use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.59683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Violation</em> event attributes",
        "sections": "<em>Violation</em> event attributes",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of <em>violations</em> and other terms, see <em>Alerts</em> concepts. What is a violation event? The violation of a condition generates a violation event. This event has various"
      },
      "id": "6130c05428ccbc6d0d56a834"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/view-alert-violations-our-products": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.02985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.52441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Violation event attributes",
        "What is a violation event?",
        "Important",
        "BETA FEATURE"
      ],
      "title": "Violation event attributes",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "4c7da02e30f309b8bc6ac1bc3c49d3b610f3d9eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes/",
      "published_at": "2021-12-05T04:53:28Z",
      "updated_at": "2021-10-31T08:15:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see Alerts concepts. What is a violation event? The violation of a condition generates a violation event. This event has various attributes (metadata) attached to it and different attributes can be used by different features. Important The violation event is a concept used to determine alerting features. While you can query some of its associated attributes via NerdGraph, you cannot directly query the violation event. Violation event attributes This table shows violation event attributes. The violation event data type is collected in NrAiIncident. BETA FEATURE NrAiIncident is still in development, so may be subject to unannounced changes, but we encourage you to try it out! You may be wondering why we're using NrAiIncident as the name for the violation event data type. Although we currently refer to these events as \"violations,\" they'll be called \"incidents\" in our new, upcoming naming scheme. This name prepares for and reflects our future intentions. All attributes are available for use in a description. Read about attributes available for muting rules. Attribute Description accountId The ID of the account where the violation occurred. Available for muting rules. aggregationDuration The active condition's aggregation window. closeCause If applicable, what caused the incident to close. Available values: CONDITION_DELETED, POLICY_DELETED, EVALUATOR, EXPIRED, CONDITION_MODIFIED, LOSS_OF_SIGNAL, USER, TARGET_REMOVED, and CONDITION_DISABLED. closeTime If applicable, the timestamp when the incident was closed. closeViolationsOnExpiration If true, open violations on the signal are closed if the signal is lost. Default is false. To use this field, an expirationDuration must be specified. conditionId The ID of the condition that triggered the violation. Available for muting rules. conditionName The name of the condition that triggered the violation. Available for muting rules. degradationTime The timestamp when the targeted metric started to breach the active condition’s threshold. description The contents of the active condition’s Violation Description field. NRQL or Infrastructure conditions only. entity.guid The targeted entity's globally unique identifier, if available. Available for muting rules. entity.name The targeted entity's name, if available. entity.type The targeted entity's type, if available. evaluationOffsetSeconds The active condition's evaluation offset. A time delay (in seconds) to ensure data points are placed in the correct aggregation window. If you use the Delay/timer setting in the UI, it clears evaluationOffsetSeconds and uses Delay/timer instead. evaluationType The reason the violation was opened. Available values: Threshold (the condition threshold was breached) Expiration (the entity's signal was lost) event The record's event type. Available values: Open and Close. expirationDuration The active condition's signal loss time window. incidentID The unique identifier of the violation. muted Shows whether the active condition was muted at the time of the violation event. mutingRuleID The unqiue identifier of the muting rule that caused the violation to be muted. nrqlEventType The type of data targeted by a NRQL condition. In this context, this refers to any NRQL-queryable data type. Available for muting rules. nrqlQuery The full string of the NRQL query. Can be used for sub-string matching on attributes in the WHERE clause. Available for muting rules. openTime The timestamp when the violation was opened. operator The violation threshold's operator, such as =, <, or >. For signal loss violations, this is an empty string. policyId The ID of the policy that triggered the violation. Available for muting rules. policyName The name of the policy that triggered the violation. Available for muting rules. priority The level of the violation: warning or critical. recoveryTime The timestamp when the active condition's targeted metric stops breaching the threshold. runbookUrl The runbook URL for the condition that triggered the violation. Available for muting rules. tags.* Arbitrary key-value metadata, or tags, associated with the violation. tags. is the prefix and * is the metadata/tag name. For details on how to use this, see the documentation for muting rules or description. Available for muting rules. targetName The name of the violation’s target. This can be an entity or a query. Available for muting rules. threshold The active condition's threshold value. thresholdDuration The active condition's threshold time window. thresholdOccurrences Shows whether for at least or at least once in occurrence values are being used in the active condition's threshold. Available values: all or any. timestamp The event's wall clock time using an epoch timestamp. title The incident's title. type The incident's type. Available value: Incident. valueFunction The active condition's aggregation function. Used in APM, browser, and mobile alert condition types. violationTimeLimitSeconds The active condition's violation time limit setting. violationUuId Deprecated. Do not use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.59683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Violation</em> event attributes",
        "sections": "<em>Violation</em> event attributes",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of <em>violations</em> and other terms, see <em>Alerts</em> concepts. What is a violation event? The violation of a condition generates a violation event. This event has various"
      },
      "id": "6130c05428ccbc6d0d56a834"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/alerts-ai-overview-page": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-11-24T04:37:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. Ready to get started? Make sure you have a New Relic account. It's free, forever! After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.6907,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " are surfaced in the <em>Applied</em> <em>Intelligence</em> anomalies feed, <em>New</em> <em>Relic</em> One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and&#x2F;or added as a source for Incident <em>Intelligence</em> correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and <em>alerts</em> via the analysis page. To <em>get</em> <em>started</em>, see Proactive Detection."
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Outlier detection (NRQL alert)",
        "Important",
        "What is outlier detection?",
        "Tip",
        "Example use cases",
        "Notify if load-balanced servers have uneven workload",
        "Notify if load-balanced application has misbehaving instances",
        "Notify of changes in different environments",
        "Notify for timezone-related changes",
        "Create an outlier alert condition",
        "Rules and logic",
        "Details about alert condition logic",
        "NRQL query rules and limits",
        "Zero values for unreturned data"
      ],
      "title": "Outlier detection (NRQL alert)",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "499fa55abd48a0ccdd897fbdf64ccea2d9f98d11",
      "image": "https://docs.newrelic.com/static/f235d0630576bc2010ff07adc7a69621/f73a1/NRQL_outlier_violations.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert/",
      "published_at": "2021-12-05T05:06:51Z",
      "updated_at": "2021-11-25T19:50:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts offers NRQL conditions in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and NRQL queries, and explains how to create an outlier condition. Important NRQL alerts do not affect Alerts policies for a Synthetic monitor. For example, muting a NRQL alert will not mute a Synthetic monitor's alerts. What is outlier detection? In software development and operations, it is common to have a group consisting of members you expect to behave approximately the same. For example: for servers using a load balancer, the traffic to the servers may go up or down, but the traffic for all the servers should remain in a fairly tight grouping. See outlier detection in action in this NerdBytes video (2:51 minutes). The NRQL alert outlier detection feature parses the data returned by your faceted NRQL query and: Looks for the number of expected groups that you specify Looks for outliers (values deviating from a group) based on the sensitivity and time range you set Additionally, for queries that have more than one group, you can choose to be notified when groups start behaving the same. This visual aid will help you understand the types of situations that will trigger a violation and those that won't. For more on the rules and logic behind this calculation, see Outlier detection rules. Tip Note: this feature does not take into account the past behavior of the monitored values; it looks for outliers only in the currently reported data. For an alert type that takes into account past behavior, see Baseline alerting. Example use cases These use cases will help you understand when to use the outlier threshold type. Note that the outlier feature requires a NRQL query with a FACET clause. Notify if load-balanced servers have uneven workload A load balancer divides web traffic approximately evenly across five different servers. You can set a notification to be sent if any server starts getting significantly more or less traffic than the other servers. Example query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Notify if load-balanced application has misbehaving instances Application instances behind a load balancer should have similar throughput, error rates, and response times. If an instance is in a bad state, or a load balancer is misconfigured, this will not be the case. Detecting one or two bad app instances using aggregate metrics may be difficult if there is not a significant rise in the overall error rate of the application. You can set a notification for when an app instance’s throughput, error rate, or response time deviates too far from the rest of the group. Example query: SELECT average(duration) FROM Transaction WHERE appName = 'MY-APP-NAME' FACET host Copy Notify of changes in different environments An application is deployed in two different environments, with ten application instances in each. One environment is experimental and gets more errors than the other. But the instances that are in the same environment should get approximately the same number of errors. You can set a notification for when an instance starts getting more errors than the other instances in the same environment. Also, you can set a notification for when the two environments start to have the same number of errors as each other. Notify for timezone-related changes The number of logged in users for a company is about the same for each of four applications, but varies significantly by each of the three time zones the company operates in. You can set a notification for when any application starts getting more or less traffic from a certain timezone than the other applications. Sometimes the traffic from the different time zones are the same, so you would set up the alert condition to not be notified if the time zone groups overlap. For more details on how this feature works, see Outlier rules and logic. Create an outlier alert condition To create a NRQL alert that uses outlier detection: When creating a condition, under Select a product, select NRQL. For Threshold type, select Outlier. Create a NRQL query with a FACET clause that returns the values you want to alert on. Depending on how the returned values group together, set the Number of expected groups. Adjust the deviation from the center of the group(s) and the duration that will trigger a violation. Optional: Add a warning threshold and set its deviation. Set any remaining available options and save. Rules and logic Here are the rules and logic behind how outlier detection works: Details about alert condition logic After the condition is created, the query is run once every harvest cycle and the condition is applied. Unlike baseline alerts, outlier detection uses no historical data in its calculation; it's calculated using the currently collected data. Alerts will attempt to divide the data returned from the query into the number of groups selected during condition creation. For each group, the approximate average value is calculated. The allowable deviation you have chosen when creating the condition is centered around that average value. If a member of the group is outside the allowed deviation, it produces a violation. If Trigger when groups overlap has been selected, Alerts detects a convergence of groups. If the condition is looking for two or more groups, and the returned values cannot be separated into that number of distinct groups, then that will produce a violation. This type of “overlap” event is represented on a chart by group bands touching. Because this feature does not take past behavior into account, data is never considered to \"belong\" to a certain group. For example, a value that switches places with another value wouldn't trigger a violation. Additionally, an entire group that moves together also wouldn't trigger a violation. NRQL query rules and limits The NRQL query must be a faceted query. The number of unique values returned must be 500 or less. If the query returns more than this number of values, the condition won't be created. If the query later returns more than this number after being created, the alert will fail. Zero values for unreturned data When a query returns a set of values, only values that are actually returned are taken into account. If a value is not available for calculation (including if it goes from being collected one harvest cycle to not being collected), it is rendered as a zero and is not considered. In other words, the behavior of unreturned zero values will never trigger violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.84206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Outlier detection (NRQL <em>alert</em>)",
        "sections": "Outlier detection (NRQL <em>alert</em>)",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for a Synthetic monitor. For example, muting a NRQL <em>alert</em> will not mute a Synthetic monitor&#x27;s <em>alerts</em>. What is outlier detection? In software development and operations, it is common to have a group consisting of members you expect to behave approximately the same. For example: for servers using a load"
      },
      "id": "6130be72196a6793654948e7"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-12-08T01:43:24Z",
      "updated_at": "2021-11-24T14:48:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Ready to get started? Make sure you have a New Relic account. It's free, forever! Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.90927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " about. The threshold determines when you’ll be notified. Follow these steps to write your first <em>alerts</em> condition using a NRQL query and a threshold. Once you&#x27;re done, you&#x27;ll have a working <em>alert</em> condition. Ready to get started? Make sure you have a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever! Step 1: Write"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/condition-recommendations": [
    {
      "image": "https://docs.newrelic.com/static/2ddf926e6e8fbdbcd9ee04a60e75c38b/ae694/add-alert.png",
      "url": "https://docs.newrelic.com/whats-new/2021/07/alert-conditions/",
      "sections": [
        "Recommended alert conditions",
        "Using recommended conditions"
      ],
      "published_at": "2021-12-05T09:00:34Z",
      "title": "Recommended alert conditions",
      "updated_at": "2021-10-30T17:13:56Z",
      "type": "docs",
      "external_id": "3a955d434afd832f8115e0274596f78045c9e6ea",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Configuring incident detection consistently across your entire estate helps you track the overall health of your systems, avoid blindspots, and reduce the time it takes to identify and resolve issues. We know that creating accurate alert conditions is anything but simple. Knowing which metrics to monitor, and setting the thresholds accordingly, is a task that few have the necessary knowledge of both their systems and of New Relic to feel confident executing. This results in teams only applying incident detection practices to a subset of critical services. Good news: New Relic One now has an alert condition recommendation service that uses AI and machine learning (ML) to recommend specific metrics and signals to monitor for your specific entities. You can use the provided recommendations or modify them to fit your specific needs. Here’s how you can add recommended alerts to APM entities that do not currently have alert coverage. Using recommended conditions Go to Services - APM in New Relic Navigator and you’ll see a high-density view of the health of your system. With the traffic-light visual, it’s easy to view which entities are healthy, which entities have violations, and which entities do not have any alerts coverage. If an entity does not have alert coverage, its hexagon will be gray. Recommended conditions helps you automatically add alerts to entities that do not have alerts coverage, those gray hexagons. Select an entity: Click an uncovered entity (gray hexagon). A new option will appear on the right-hand side of the screen. Click Create alert condition as shown in the image below. Choose a number of recommended conditions. The recommendations will depend on the quality of the tags associated with an entity. The more accurate and informative the tags are, the more precise the recommendations will be. The image below shows a few possible recommendations based on error percentage, Apdex, and response time. Learn more about recent innovations in alerting with our PM Brian Goleno here!.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.355675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Recommended</em> alert <em>conditions</em>",
        "sections": "<em>Recommended</em> alert <em>conditions</em>",
        "body": " an alert <em>condition</em> recommendation service that uses AI and machine learning (ML) to <em>recommend</em> specific metrics and signals to monitor for your specific entities. You can use the provided <em>recommendations</em> or modify them to fit your specific needs. Here’s how you can add recommended alerts to APM entities"
      },
      "id": "60febacb64441f990447ac4f"
    },
    {
      "sections": [
        "Alerts best practices",
        "Recommended alerts",
        "Organize your policies",
        "Set your condition thresholds and violations",
        "Important",
        "Decide what happens when there's no signal",
        "Use non-null values when there's no signal",
        "Define your incident preferences",
        "Select your notification channels",
        "Understand muting rules",
        "What's next?"
      ],
      "title": "Alerts best practices",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Alerts and Applied Intelligence"
      ],
      "external_id": "44a12c229fe5c2f17fcaca2bc9d6ff87b4554b8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices/",
      "published_at": "2021-12-04T23:14:07Z",
      "updated_at": "2021-11-26T04:49:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Improve your Alerts coverage by implementing the following recommendations and get the most out of your alerts configuration. And check out this video on finding the root cause for an alert (5:01 minutes): Read on to learn the best practices for: Policies Notification channels Incident preferences Thresholds and violations Muting rules Recommended alerts Use recommended alerts conditions conditions if you are new to Alerts or if you want suggestions that optimize your alert coverage. Organize your policies A policy is a container for similar conditions. If you’re new to Alerts, learn how to create, edit, or find policies. Organize your policy's scope to a single entity when possible. Assign your policy to the essential team or teams that need to be notified when an incident occurs. This way, you keep policies centralized and focused. If a team is monitoring several groups of the same entity type, combine those entity clusters (like servers) together into one policy. This way, your team can be notified from one policy rather than navigating several policies at once. You can use Alerts to monitor all of your entities. Consider your role and priorities when assigning yourself to a policy. For example: Software developers may need notifications for both front-end and back-end performance, such as webpage response time and page load JavaScript errors. Operations personnel may need notifications for poor back-end performance, such as server memory and load averages. The product owner may need notifications for positive front-end performance, such as improved end user Apdex scores or sales being monitored in dashboards. Set your condition thresholds and violations Set meaningful threshold levels to optimize Alerts for your business. Here are some suggested guidelines: Action Recommendations Set threshold levels Avoid setting thresholds too low. For example, if you set a CPU condition threshold of 75% for 5 minutes on your production servers, and it routinely goes over that level, this will increase the likelihood of un-actionable alerts or false positives. Experimenting with settings You do not need to edit files or restart software, so feel free to make quick changes to your threshold levels and adjust as necessary. Adjust settings Adjust your conditions over time. As you use our products to help you optimize your entity's performance, tighten your thresholds to keep pace with your improved performance. If you are rolling out something that you know will negatively impact your performance for a period of time, loosen your thresholds to allow for this. Disable settings You can disable any condition in a policy. This is useful, for example, if you want to continue using other conditions in the policy while you experiment with other metrics or thresholds. In most of our products (except Infrastructure), the color-coded health status indicator in the user interface changes as the alerting threshold escalates or returns to normal. This allows you to monitor a situation through our UI before a critical threshold passes, without needing to receive specific notifications about it. There are two violation thresholds: critical (red) and warning (yellow). Define these thresholds with different criteria, keeping in mind the suggestions above. Important Warning violations do not open incidents. A critical violation can open incidents, but you must define that decision through your incident preferences. Decide what happens when there's no signal Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. You can configure loss of signal settings by condition in the UI or configure loss of signal via the NerdGraph API. Use non-null values when there's no signal By default, gaps in data signals are filled with null values. In cases where you need to be able to create conditions based on those data gaps, you can fill gaps with a custom value or the last known value. You can configure this setting by condition in the UI or configure gap filling values via NerdGraph Define your incident preferences Decide when you get incident notifications so you can respond to incidents when they happen. If you’re new to Alerts, learn more about your incident preferences options. The default incident preference setting combines all conditions within a policy into one incident. Change your default incident preference setting to increase or decrease the number of incidents and incident notifications you receive. Each team within your organization will have different needs. Ask your team two important questions when deciding your incident preferences: Do we want to be notified every time something goes wrong? Do we want to group all similar notifications together and be notified once? When a policy and its conditions have a broader scope (like managing the performance of several entities), increase the amount of incidents you receive. You will need more notifications because two incidents will not necessarily relate to each other. When a policy and its conditions have a focused scope (like managing the performance of one entity), opt for the default incident preference. You will need less notifications when two incidents are related to each other or when the team is already notified and fixing an existing problem. Decide how you get incident notifications by using our notification channel best practices. Select your notification channels Tailor notifications to the most useful channel and policy so you can avoid alert fatigue and help the right personnel receive and respond to incidents they care about in a systematic way. If you’re new to Alerts, learn how to set up notification channels. Notify teams and individuals who needs to stay updated on or resolve a problem when an incident arises. To stay updated, select a notification channel that is less intrusive, like email. For vital notifications and incident responses, select a notification channel that is more intrusive, like PagerDuty or Slack. Do not rely on email for quick notifications in case of delays. Understand muting rules Mute alerts during routine events, such as maintenance or planned downtime. You can also silence a policy, a specific entity, and a condition when needed. Incidents can still be opened, but you won't be notified. If you're new to Alerts, learn how to create and manage muting rules. What's next? To learn more about using alerts: Learn about the API. Read technical details about min/max limits and rules. Read more about about when you might want to use loss-of-signal and gap-filling settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.95888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Recommended</em> alerts",
        "body": "Improve your Alerts coverage by implementing the following <em>recommendations</em> and <em>get</em> the most out of your alerts configuration. And check out this video on finding the root cause for an alert (5:01 minutes): Read on to learn the best practices for: Policies Notification channels Incident preferences"
      },
      "id": "603ed04a28ccbc3ddeeba7b4"
    },
    {
      "sections": [
        "Set proactive alerts and align teams, tools, and processes for incident response",
        "Prerequisites",
        "1. Define policies",
        "Example questions and KPI solutions",
        "2. Set specific alerts",
        "3. Identify groups",
        "4. Determine thresholds",
        "5. Set notification channels",
        "6. Automate resolution",
        "7. Establish reviews",
        "Example post mortem report",
        "8. Fine-tune process",
        "Expert tip"
      ],
      "title": "Set proactive alerts and align teams, tools, and processes for incident response ",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Optimize your cloud native environment"
      ],
      "external_id": "454d902dd8ff1ace1070b7ad42489dda5405845c",
      "image": "https://docs.newrelic.com/static/ecb7124a85903b58a0fbb042ddb29cc6/c483d/proactive-baseline-alerts-devops_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/optimize-your-cloud-native-environment/set-proactive-alerts-align-teams-tools-processes-incident-response/",
      "published_at": "2021-12-04T22:41:14Z",
      "updated_at": "2021-12-04T22:41:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The term alerting often carries some negative connotations: many developers correlate alerting with errors, mistakes, and ongoing issues. However, developers who are proactive about alerting, know they don't have to stare at dashboards all day because effective alerts tell them when to check in. Well-defined alerts help you understand the health of your systems, so you can respond to performance problems before they affect your customers. Further, a focused alerts policy helps you pinpoint any degradation that could impact performance in your application or environment. With proactive alerting, you'll decrease user-reported incidents, and your teams will spend less time firefighting and more time deploying significant changes to your product. After you define the right alerts, proper incident orchestration aligns your teams, tools, and processes to prepare for incidents and outages in your software. The goal is to provide your teams a predictable framework and process to: Maximize efficiency in communication and effort. Minimize the overall impact to your business. Prerequisites This tutorial assumes you have: Instrumented your applications in New Relic. Reviewed the Establish objectives and baselines tutorial. Optionally added custom attributes and events. 1. Define policies Define required alerting policies based on SLOs. A service level objective (SLO) is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI). Examples of service level indicators could be average response time, response time percentile, and application availability. SLOs would then clarify a target value for those SLIs such as: Average response time should be less than 200 ms. 95% of requests should be completed within 250 ms. Availability of the service should be 99.99%. These SLOs can also be logically grouped together to provide an overall boolean indicator of whether the service is meeting expectations or not (for example, 95% of requests completed within 250 ms AND availability is 99.99%), which can be helpful for alerting purposes. Use these SLIs as key performance indicators (KPIs) so your team and organization can measure your service and ensure it's meeting customer expectations. By breaking down the quantitative performance metrics that are required of your services, you can then identify what kinds of alerts you should set for each. For instance, you could set an alert to notify you if web transaction times go above half a millisecond, or if the error rate goes higher than 0.20%. However, not every SLO needs to become an alert. A strong alerting strategy takes SLOs and creates a set of simple, actionable alerts. New Relic often finds that our most mature customers set fewer alerts in general and focus those alerts on a core set of metrics that indicate when their customer experience is truly degraded. As a result, New Relic customers often use Apdex as part of their alerting strategy to align alerts with signs of degraded user satisfaction. As you design your alerting strategy, keep this question in mind: “If the customer isn’t impacted, is it worth waking someone up?” Example questions and KPI solutions For a simple framework of areas to set alerts for, use the following questions and advised metrics and KPIs: Questions Metrics and KPIs Are we open for business? Use browser monitoring and APM to alert on site availability. How's our underlying infrastructure? Set KPIs for key hardware, network, and storage components. How's the health of our application? Track metrics for JVM performance, queuing, caching, and similar dependencies. How’s the overall quality of our application? Use an Apdex score to quickly access an application’s quality. How are our customers doing? Consider real end-user metrics (browser or APM), synthetic users (Synthetics), and Apdex scores. How's our overall business doing? Focus on key transactions within an application, and tie them to expected business outcomes to illustrate correlation between your application and business performance. 2. Set specific alerts Set specific alerts for performance, correctness, throughput, availability, and dependencies With New Relic you can set alerts on your instrumented applications, end-user experience, infrastructure, databases, and more. New Relic will alert you if your site's availability dips or if your error rate spikes above acceptable levels, as defined by your SLOs. You can set warning thresholds to monitor issues that may be approaching a critical severity but don't yet warrant a pager notification. Setting thresholds for when alerts should notify teams can be challenging. Thresholds that are too tight will create alert fatigue while thresholds that are too loose will lead to unhappy customers. Baseline alerts allow you to set dynamic thresholds for alerts based on historical performance. Use baselines to tune your alert to the right threshold. For example, an alert in APM can notify incident response teams if web transaction times deviate from historical performance for an allotted amount of time. alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we've set both a warning and a violation for throughput: alerts.newrelic.com > (selected alert policy) > (selected alert condition) > Define thresholds As you develop smaller, independent services running on increasingly ephemeral architectures, your environments become significantly more complex. Visibility into outliers can be an important tool for understanding likely performance issues. You should set alerts to automatically fire when you have an outlier, which can indicate misbehaving hosts, load balancers, or apps. For example, a load balancer divides web traffic across five different servers. You can set an alert based on a NRQL query and receive a notification if any server starts getting significantly more or less traffic than the other servers. Here is an example chart: And here's a sample NRQL query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Now you have set static, baseline, and outlier alerts. This can provide a comprehensive awareness of your ecosystem. Refer to the New Relic Alerts documentation for more details about optimizing your alerts. 3. Identify groups Identify groups to alert, set broadcasting methods, and assign first responders to team dashboards Alerting without the proper broadcasting methods leaves you vulnerable. Your alerting strategy should include a notification channel to ensure the appropriate teams are notified if your application or architecture encounters issues. New Relic has many notification integrations, but we recommend that you start simple and add more complexity later. We recommend that you first send alerts to a group chat channel (for example, using Slack or PagerDuty). Evaluate these alerts in real time for several weeks to understand which alerts are indicative of important or problematic issues. These are the types of alerts that warrant waking someone up. Recommendation: For each team dashboard, make sure: It has an owner who assumes responsibility for the health of the applications and features it monitors. There is no ambiguity about who is responsible for attending to and resolving an alert condition. This policy will vary between organizations depending on size, structure, and culture. For example, some teams may prefer to assign dashboards and alerts based on de-facto features or application ownership. Other teams may prefer to adopt an on-call rotation (often referred to as pager duty). In on-call rotations, designated team members handle all first-line incident responses, and they resolve or delegate responsibilities based on predetermined incident thresholds. 4. Determine thresholds Determine incident thresholds for alert conditions For each of your applications: Identify the thresholds for what is officially considered an incident. Make sure each set of threshold criteria is context-dependent. Document incident evaluation and known remediation procedures in runbooks. Include links to your runbooks when you define conditions and thresholds for your alert policies. For instance, a certain alert condition may be dismissable during low-traffic periods but require active remediation during peak hours. 5. Set notification channels Ensure alerts have auditable notification channels Make sure that communications during critical incidents take place in easily accessible and highly visible channels. A group chat room dedicated to incident communication is usually a great choice. This allows all stakeholders to participate or observe and provides a chronology of notifications, key decisions, and actions for postmortem analysis. Use any of the available notification channels in New Relic Alerts. For example, to set up a notification channel in Slack: Make sure your organization has completed New Relic's integration requirements with Slack. In the Slack app, select the dropdown in the top-left corner of the app, and select Customize Slack. Click Configure apps. From the list of app integrations, select New Relic. Expand the instructions for New Relic Alerts, and follow the steps to configure notifications from New Relic. 6. Automate resolution Automate triage and resolution steps Automation of simple or repeatable incident response tasks will increase efficiency and minimize the impact of incidents. With proper automation in place, you can disable or isolate faulty application components as soon as an alert threshold is reached, rather than after a notification has been issued. For example, a team managing an application for a digital media company wants to be able to remove commenting abilities from the website if the system has errors. In this case, they could: Add an endpoint to their front-end web application that will toggle a feature flag enabling or disabling the UI components associated with posting comments on an article. Create an alert policy with a threshold set on the sustained error rate in the commenting service. Assign a webhook notification channel that will send a POST request to this endpoint, as well as to the standard team notification channels. In this scenario, errors in the commenting system will trigger the webhook and remove the commenting UI from the website. Users can still use core functionality of the site without seeing errors generated by the commenting service. The application will maintain a stable but degraded state, allowing the team to focus on recovery without the pressure of preventing users from accessing the site. You can also use webhooks to create issues and action items in ticketing systems that have REST APIs, such as Zendesk. Use New Relic Alerts to create a webhook notification channel, and customize the webhook payload as needed. 7. Establish reviews Establish a post mortem process After the incident has been resolved, key stakeholders and participants must capture accurate and thorough documentation of the incident. At a minimum, we recommend that the retro documentation includes: A root cause analysis A chronology and summary of remediation steps and their result, whether they were successful or not A measure of the impact to the business in terms of user experience and financial losses, if possible Recommendations for system or feature improvements to prevent a recurrence Recommendations for process and communication improvements Store post mortem reports in a highly visible, searchable repository, such as a shared drive folder or wiki. Culturally, it's essential that this process focuses on constructive learning and improvement rather than punishment or blame. Example post mortem report Here is a brief example of a post mortem report: Post mortem Comments Date March 1, 2018 Executive summary From approximately 1:45PM until 2:30PM, users could not add items to their carts, which prevented any checkouts from occurring during the incident period. Root cause We determined that a change was made to the CSS rules on the product detail page that effectively disabled the Add to cart button. Timeline 1:50PM: Successful checkouts < 10 for 5 minutes alert triggered; assigned to Alice. 1:55PM: After reviewing the ecommerce team dashboard, Alice determined that the threshold was breached immediately following a deploy by Bob. She notified him of the incident. 2:00PM: Alice and Bob began troubleshooting. Attempts at recreating the issue in production were successful. 2:20PM: Bob determined that his change to the CSS on the product detail page disabled the Add to cart button. He deployed a hotfix. 2:30PM: Functionality was restored and the incident was resolved. Impact No checkouts were completed during the duration of the incident. Our typical revenue for a Thursday during this timeframe is $30,000. Recommendations We have been discussing implementing New Relic Synthetics for awhile now. If we had a Synthetic check on the checkout process, this issue would have been detected immediately. We should also implement more thorough unit tests in the front-end web app. 8. Fine-tune process Fine-tune alerts and thresholds As you use New Relic to optimize your application and infrastructure performance, tighten your New Relic Alerts policy conditions to keep pace with your improved performance. When rolling out new code or modifications that could negatively impact performance over a period of time, loosen your threshold conditions to allow for these short-term changes. For instance, we recommend using pre-established baselines and thresholds to increase efficiency during high-impact times for your business, such as annual events and major releases. Fine-tuning gives you the flexibility you need to increase efficiencies and extend your notification channels. As noted earlier, we recommend you start with a group chat service when you first establish notifications. Once you've identified other tools you'd like to integrate with, set up a notification channel to maintain your momentum. Tools such as xMatters and PagerDuty provide popular integrations, but don't overlook simple methods, such as webhooks. The goal is to continuously improve your alerting scheme. Be sure to check your alerts and confirm that they're firing regularly and are still relevant for your customer satisfaction metrics. Use the New Relic platform to create dashboards centered around alerts and incidents for the most common policy conditions and violations. insights.newrelic.com > All dashboards > (selected dashboard) Use the New Relic query language and the Insights query API to create your dashboards. The dashboard above was created using the following NRQL queries. It's recommended you recreate them as needed for your alerting dashboards. Incidents by condition: SELECT count(*) FROM ALERT_NAME WHERE current_state = 'open' FACET condition_name SINCE 1 week ago Copy Incidents by policy: SELECT count(*) FROM ALERT_NAME where current_state = 'open' FACET policy_name SINCE 60 MINUTES AGO TIMESERIES Copy Alert trends over time: SELECT count(*) FROM ALERT_NAME WHERE current_state IS NOT NULL FACET policy_name SINCE 1 week ago TIMESERIES Copy Incident details: SELECT timestamp, incident_id, policy_name, condition_name, details, severity FROM ALERT_NAME SINCE 1 week ago LIMIT 40 Copy Visualizing this data provides a resource you can share with others to refine the alerts and thresholds you're using. Expert tip In addition to instrumenting and measuring application and infrastructure metrics, mature DevOps organizations often measure and optimize the efficiency of incident response processes. For example, you can use webhooks to send alert events to New Relic Insights. This allows you to supplement your team dashboards with New Relic Alerts data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.00617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " times deviate from historical performance for an allotted amount of time. alerts.newrelic.com &gt; (selected alert policy) &gt; (selected alert <em>condition</em>) &gt; Define thresholds You can set this same kind of alert in browser to catch sub-optimal performance. In the following example, we&#x27;ve set both a warning"
      },
      "id": "603ebf0be7b9d2b3982a07a9"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-12-08T01:43:24Z",
      "updated_at": "2021-11-24T14:48:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Ready to get started? Make sure you have a New Relic account. It's free, forever! Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.44891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " about. The threshold determines when you’ll be notified. Follow these steps to write your first <em>alerts</em> condition using a NRQL query and a threshold. Once you&#x27;re done, you&#x27;ll have a working <em>alert</em> condition. Ready to <em>get</em> <em>started</em>? Make sure you have a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever! Step 1: Write"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 327.52863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>NRQL</em> <em>alert</em> <em>conditions</em>",
        "sections": "Create <em>NRQL</em> <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use <em>NRQL</em> queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Outlier detection (NRQL alert)",
        "Important",
        "What is outlier detection?",
        "Tip",
        "Example use cases",
        "Notify if load-balanced servers have uneven workload",
        "Notify if load-balanced application has misbehaving instances",
        "Notify of changes in different environments",
        "Notify for timezone-related changes",
        "Create an outlier alert condition",
        "Rules and logic",
        "Details about alert condition logic",
        "NRQL query rules and limits",
        "Zero values for unreturned data"
      ],
      "title": "Outlier detection (NRQL alert)",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "499fa55abd48a0ccdd897fbdf64ccea2d9f98d11",
      "image": "https://docs.newrelic.com/static/f235d0630576bc2010ff07adc7a69621/f73a1/NRQL_outlier_violations.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert/",
      "published_at": "2021-12-05T05:06:51Z",
      "updated_at": "2021-11-25T19:50:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts offers NRQL conditions in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and NRQL queries, and explains how to create an outlier condition. Important NRQL alerts do not affect Alerts policies for a Synthetic monitor. For example, muting a NRQL alert will not mute a Synthetic monitor's alerts. What is outlier detection? In software development and operations, it is common to have a group consisting of members you expect to behave approximately the same. For example: for servers using a load balancer, the traffic to the servers may go up or down, but the traffic for all the servers should remain in a fairly tight grouping. See outlier detection in action in this NerdBytes video (2:51 minutes). The NRQL alert outlier detection feature parses the data returned by your faceted NRQL query and: Looks for the number of expected groups that you specify Looks for outliers (values deviating from a group) based on the sensitivity and time range you set Additionally, for queries that have more than one group, you can choose to be notified when groups start behaving the same. This visual aid will help you understand the types of situations that will trigger a violation and those that won't. For more on the rules and logic behind this calculation, see Outlier detection rules. Tip Note: this feature does not take into account the past behavior of the monitored values; it looks for outliers only in the currently reported data. For an alert type that takes into account past behavior, see Baseline alerting. Example use cases These use cases will help you understand when to use the outlier threshold type. Note that the outlier feature requires a NRQL query with a FACET clause. Notify if load-balanced servers have uneven workload A load balancer divides web traffic approximately evenly across five different servers. You can set a notification to be sent if any server starts getting significantly more or less traffic than the other servers. Example query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Notify if load-balanced application has misbehaving instances Application instances behind a load balancer should have similar throughput, error rates, and response times. If an instance is in a bad state, or a load balancer is misconfigured, this will not be the case. Detecting one or two bad app instances using aggregate metrics may be difficult if there is not a significant rise in the overall error rate of the application. You can set a notification for when an app instance’s throughput, error rate, or response time deviates too far from the rest of the group. Example query: SELECT average(duration) FROM Transaction WHERE appName = 'MY-APP-NAME' FACET host Copy Notify of changes in different environments An application is deployed in two different environments, with ten application instances in each. One environment is experimental and gets more errors than the other. But the instances that are in the same environment should get approximately the same number of errors. You can set a notification for when an instance starts getting more errors than the other instances in the same environment. Also, you can set a notification for when the two environments start to have the same number of errors as each other. Notify for timezone-related changes The number of logged in users for a company is about the same for each of four applications, but varies significantly by each of the three time zones the company operates in. You can set a notification for when any application starts getting more or less traffic from a certain timezone than the other applications. Sometimes the traffic from the different time zones are the same, so you would set up the alert condition to not be notified if the time zone groups overlap. For more details on how this feature works, see Outlier rules and logic. Create an outlier alert condition To create a NRQL alert that uses outlier detection: When creating a condition, under Select a product, select NRQL. For Threshold type, select Outlier. Create a NRQL query with a FACET clause that returns the values you want to alert on. Depending on how the returned values group together, set the Number of expected groups. Adjust the deviation from the center of the group(s) and the duration that will trigger a violation. Optional: Add a warning threshold and set its deviation. Set any remaining available options and save. Rules and logic Here are the rules and logic behind how outlier detection works: Details about alert condition logic After the condition is created, the query is run once every harvest cycle and the condition is applied. Unlike baseline alerts, outlier detection uses no historical data in its calculation; it's calculated using the currently collected data. Alerts will attempt to divide the data returned from the query into the number of groups selected during condition creation. For each group, the approximate average value is calculated. The allowable deviation you have chosen when creating the condition is centered around that average value. If a member of the group is outside the allowed deviation, it produces a violation. If Trigger when groups overlap has been selected, Alerts detects a convergence of groups. If the condition is looking for two or more groups, and the returned values cannot be separated into that number of distinct groups, then that will produce a violation. This type of “overlap” event is represented on a chart by group bands touching. Because this feature does not take past behavior into account, data is never considered to \"belong\" to a certain group. For example, a value that switches places with another value wouldn't trigger a violation. Additionally, an entire group that moves together also wouldn't trigger a violation. NRQL query rules and limits The NRQL query must be a faceted query. The number of unique values returned must be 500 or less. If the query returns more than this number of values, the condition won't be created. If the query later returns more than this number after being created, the alert will fail. Zero values for unreturned data When a query returns a set of values, only values that are actually returned are taken into account. If a value is not available for calculation (including if it goes from being collected one harvest cycle to not being collected), it is rendered as a zero and is not considered. In other words, the behavior of unreturned zero values will never trigger violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.68106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Outlier detection (<em>NRQL</em> <em>alert</em>)",
        "sections": "Outlier detection (<em>NRQL</em> <em>alert</em>)",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> offers <em>NRQL</em> <em>conditions</em> in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and <em>NRQL</em> queries, and explains how to create an outlier condition. Important <em>NRQL</em> <em>alerts</em> do not affect <em>Alerts</em> policies"
      },
      "id": "6130be72196a6793654948e7"
    },
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.71391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/alerts-concepts-workflow": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.16861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-11-24T04:37:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. Ready to get started? Make sure you have a New Relic account. It's free, forever! After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.69063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " are surfaced in the <em>Applied</em> <em>Intelligence</em> anomalies feed, <em>New</em> <em>Relic</em> One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and&#x2F;or added as a source for Incident <em>Intelligence</em> correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and <em>alerts</em> via the analysis page. To <em>get</em> <em>started</em>, see Proactive Detection."
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/introduction-alerts": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.1685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-11-24T04:37:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. Ready to get started? Make sure you have a New Relic account. It's free, forever! After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.6906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " are surfaced in the <em>Applied</em> <em>Intelligence</em> anomalies feed, <em>New</em> <em>Relic</em> One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and&#x2F;or added as a source for Incident <em>Intelligence</em> correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and <em>alerts</em> via the analysis page. To <em>get</em> <em>started</em>, see Proactive Detection."
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts": [
    {
      "sections": [
        "Choose your aggregation method",
        "What's aggregation?",
        "Why it matters",
        "When to use event flow",
        "How event flow works",
        "Caution",
        "Event flow use cases",
        "When to use event timer",
        "How event timer works",
        "Event timer use cases",
        "Cadence",
        "Aggregation and loss of signal"
      ],
      "title": "Choose your aggregation method",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts"
      ],
      "external_id": "9bdcf28f192d61c2348909803e1c75876168936d",
      "image": "https://docs.newrelic.com/static/64df85a9f5694079b9ad1557de7fe5b5/c1b63/signal-consistency.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/",
      "published_at": "2021-12-04T15:31:22Z",
      "updated_at": "2021-12-04T15:31:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts conditions provide a sophisticated set of tools for describing when you want to be notified about something that's happened or failed to happen on something you're monitoring. For best results, choose the aggregation method that best matches the way your data arrives. The three aggregation methods are event flow, event timer, and cadence. If you're interested in a conceptual overview, see our doc on streaming alerts, key terms and concepts. What's aggregation? When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels. Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your NRQL query using methods like sum, average, min, and max, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive. Why it matters With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive? When data arrives frequently and consistently in a linear way, we recommend using event flow. When data arrives sporadically, inconsistently, and out of order, we recommend using event timer aggregation. When to use event flow With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases. How event flow works Event flow uses data point timestamps to determine when to open and close an aggregation window. For example, if you're using event flow with a 2 minute delay window, then an aggregation window will close when a timestamp arrives that's two minutes later than the last timestamp that was received. A data point with a 12:00pm timestamp arrives. An aggregation window opens. At some point, a 12:03pm data point arrives. Event flow closes the window, excluding the 12:03 data point, and evaluates that closed window against your thresholds. The event flow aggregation window will continue collecting data points until that later timestamp. The later timestamps are what moves the system forward, not the data points themselves. Event flow will wait as long as necessary for the next data point later than your delay setting to arrive, before aggregating the data. Event flow works best for data that arrives frequently and consistently. Caution If you expect your data points to arrive more than 30 minutes apart, please use the event timer method described below. Event flow use cases Here are some typical event flow use cases: APM agent data. Infrastructure agent data. Any data coming from a 3rd party that comes in frequently and reliably. Most AWS Cloudwatch metrics coming from the AWS Metric Stream (NOT polling). The main exception is that some AWS Cloudwatch data is very infrequent (like S3 volume data) regardless of whether it's streaming or polling and, in that case, you'd use Event timer. When to use event timer Event timer aggregation is based on a timer that counts down when a data point arrives. The timer resets every time a new data point arrives. If the timer counts down before a new data point arrives, event timer aggregates all of the data points received during that time. Event timer is best for alerting on events that happen sporadically and with large gaps of time. How event timer works Errors are a type of event that happens sporadically, unpredictably, and often with large gaps of time. For example, you might have a condition with a query that returns a count of errors. Many minutes may go by without any errors at all, and then suddenly 5 errors arrive within a minute. In this example, event timer would do nothing until the first of the 5 errors arrive. Then it would start the timer, resetting it each time a new error arrives. If the timer countdown reaches 0 without a new error, event timer aggregates the data, and evaluates it against your threshold. Event timer use cases Here are some typical event timer use cases: New Relic usage data. Cloud integration data that is being polled (such as with GCP, Azure, or AWS polling methods). Queries that deliver sparse or infrequent data, such as error counts. Cadence Cadence is our original aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. We recommend that you use one of our other aggregation methods instead. If you're currently using cadence, choose one of the other aggregation methods. Event flow is best for consistent, predictable data points. Event timer is best for inconsistent, sporadic data points. Aggregation and loss of signal Our loss of signal system runs separately from these aggregation methods and settings. If you set your alert condition to open a new violation when your signal is lost for 10 minutes, a loss of signal service watches for data points to arrive. If a new data point fails to arrive within 10 minutes, loss of signal causes a violation to open. For more information on when to use gap filling and loss single, see our forum post on when to use gap filling and loss of signal.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.1685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Aggregation <em>and</em> loss of signal",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " methods are event flow, event timer, and cadence. If you&#x27;re interested in a conceptual overview, see our doc on streaming <em>alerts</em>, key terms and concepts. What&#x27;s aggregation? When an application or service is monitored by <em>New</em> <em>Relic</em>, data can arrive in different ways. Some data arrives consistently"
      },
      "id": "61853bba28ccbc5a1b7fe94c"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Condition edits can reset condition evaluation",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-12-04T22:17:52Z",
      "updated_at": "2021-12-04T22:17:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Note that editing an existing condition can result in resetting its evaluation. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Condition edits can reset condition evaluation When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are: For \"for at least x minutes\" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported. For baseline conditions: the condition starts over again and all baseline learning is lost. The following actions cause an evaluation reset for NRQL conditions: Changing the query Changing the aggregation window, aggregation method, or aggregation delay/timer setting Changing the \"close violations on signal loss\" setting Changing any gap fill settings Changing the baseline direction (if applicable) – higher, lower, or higher/lower Change the threshold value, threshold window, or threshold operator The following actions (along with any other actions not covered in the above list) will not reset the evaluation: Changing the loss of signal time window (expiration duration) Changing the time function (switching \"for at least\" to \"at least once in,\" or vice-versa) Toggling the \"open violation on signal loss\" setting Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type, including the optional FACET clause. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.87883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Outlier detection (NRQL alert)",
        "Important",
        "What is outlier detection?",
        "Tip",
        "Example use cases",
        "Notify if load-balanced servers have uneven workload",
        "Notify if load-balanced application has misbehaving instances",
        "Notify of changes in different environments",
        "Notify for timezone-related changes",
        "Create an outlier alert condition",
        "Rules and logic",
        "Details about alert condition logic",
        "NRQL query rules and limits",
        "Zero values for unreturned data"
      ],
      "title": "Outlier detection (NRQL alert)",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "499fa55abd48a0ccdd897fbdf64ccea2d9f98d11",
      "image": "https://docs.newrelic.com/static/f235d0630576bc2010ff07adc7a69621/f73a1/NRQL_outlier_violations.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert/",
      "published_at": "2021-12-05T05:06:51Z",
      "updated_at": "2021-11-25T19:50:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts offers NRQL conditions in three threshold types: static, baseline, and outlier. This document explains how the outlier threshold type works, gives some example use cases and NRQL queries, and explains how to create an outlier condition. Important NRQL alerts do not affect Alerts policies for a Synthetic monitor. For example, muting a NRQL alert will not mute a Synthetic monitor's alerts. What is outlier detection? In software development and operations, it is common to have a group consisting of members you expect to behave approximately the same. For example: for servers using a load balancer, the traffic to the servers may go up or down, but the traffic for all the servers should remain in a fairly tight grouping. See outlier detection in action in this NerdBytes video (2:51 minutes). The NRQL alert outlier detection feature parses the data returned by your faceted NRQL query and: Looks for the number of expected groups that you specify Looks for outliers (values deviating from a group) based on the sensitivity and time range you set Additionally, for queries that have more than one group, you can choose to be notified when groups start behaving the same. This visual aid will help you understand the types of situations that will trigger a violation and those that won't. For more on the rules and logic behind this calculation, see Outlier detection rules. Tip Note: this feature does not take into account the past behavior of the monitored values; it looks for outliers only in the currently reported data. For an alert type that takes into account past behavior, see Baseline alerting. Example use cases These use cases will help you understand when to use the outlier threshold type. Note that the outlier feature requires a NRQL query with a FACET clause. Notify if load-balanced servers have uneven workload A load balancer divides web traffic approximately evenly across five different servers. You can set a notification to be sent if any server starts getting significantly more or less traffic than the other servers. Example query: SELECT average(cpuPercent) FROM SystemSample WHERE apmApplicationNames = 'MY-APP-NAME' FACET hostname Copy Notify if load-balanced application has misbehaving instances Application instances behind a load balancer should have similar throughput, error rates, and response times. If an instance is in a bad state, or a load balancer is misconfigured, this will not be the case. Detecting one or two bad app instances using aggregate metrics may be difficult if there is not a significant rise in the overall error rate of the application. You can set a notification for when an app instance’s throughput, error rate, or response time deviates too far from the rest of the group. Example query: SELECT average(duration) FROM Transaction WHERE appName = 'MY-APP-NAME' FACET host Copy Notify of changes in different environments An application is deployed in two different environments, with ten application instances in each. One environment is experimental and gets more errors than the other. But the instances that are in the same environment should get approximately the same number of errors. You can set a notification for when an instance starts getting more errors than the other instances in the same environment. Also, you can set a notification for when the two environments start to have the same number of errors as each other. Notify for timezone-related changes The number of logged in users for a company is about the same for each of four applications, but varies significantly by each of the three time zones the company operates in. You can set a notification for when any application starts getting more or less traffic from a certain timezone than the other applications. Sometimes the traffic from the different time zones are the same, so you would set up the alert condition to not be notified if the time zone groups overlap. For more details on how this feature works, see Outlier rules and logic. Create an outlier alert condition To create a NRQL alert that uses outlier detection: When creating a condition, under Select a product, select NRQL. For Threshold type, select Outlier. Create a NRQL query with a FACET clause that returns the values you want to alert on. Depending on how the returned values group together, set the Number of expected groups. Adjust the deviation from the center of the group(s) and the duration that will trigger a violation. Optional: Add a warning threshold and set its deviation. Set any remaining available options and save. Rules and logic Here are the rules and logic behind how outlier detection works: Details about alert condition logic After the condition is created, the query is run once every harvest cycle and the condition is applied. Unlike baseline alerts, outlier detection uses no historical data in its calculation; it's calculated using the currently collected data. Alerts will attempt to divide the data returned from the query into the number of groups selected during condition creation. For each group, the approximate average value is calculated. The allowable deviation you have chosen when creating the condition is centered around that average value. If a member of the group is outside the allowed deviation, it produces a violation. If Trigger when groups overlap has been selected, Alerts detects a convergence of groups. If the condition is looking for two or more groups, and the returned values cannot be separated into that number of distinct groups, then that will produce a violation. This type of “overlap” event is represented on a chart by group bands touching. Because this feature does not take past behavior into account, data is never considered to \"belong\" to a certain group. For example, a value that switches places with another value wouldn't trigger a violation. Additionally, an entire group that moves together also wouldn't trigger a violation. NRQL query rules and limits The NRQL query must be a faceted query. The number of unique values returned must be 500 or less. If the query returns more than this number of values, the condition won't be created. If the query later returns more than this number after being created, the alert will fail. Zero values for unreturned data When a query returns a set of values, only values that are actually returned are taken into account. If a value is not available for calculation (including if it goes from being collected one harvest cycle to not being collected), it is rendered as a zero and is not considered. In other words, the behavior of unreturned zero values will never trigger violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Outlier detection (NRQL <em>alert</em>)",
        "sections": "NRQL query <em>rules</em> <em>and</em> <em>limits</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " deviation. Set any remaining available options and save. <em>Rules</em> and logic Here are the <em>rules</em> and logic behind how outlier detection works: Details about <em>alert</em> condition logic After the condition is created, the query is run once every harvest cycle and the condition is <em>applied</em>. Unlike baseline"
      },
      "id": "6130be72196a6793654948e7"
    }
  ],
  "/docs/alerts-applied-intelligence/notifications/destinations": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Requirements",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-12-04T15:27:15Z",
      "updated_at": "2021-11-24T14:43:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Requirements If you haven't already, sign up for a New Relic account to get started. To use most Applied Intelligence features, you must be a full platform user. For more information, see user type capabilities. Set up Incident Intelligence To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.10022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Integrations",
        "Early access",
        "Integration details",
        "Atlassian Jira",
        "Permissions",
        "Set up a Jira destination",
        "Important",
        "Two-way sync",
        "Configure the message template",
        "Send a test notification",
        "ServiceNow (Incident-Management)",
        "Roles",
        "Set up a destination",
        "Slack",
        "Prerequisites",
        "Set up a Slack destination",
        "Configure the Slack message settings",
        "Webhook",
        "Set up a webhook destination",
        "Configure the webhook event template",
        "Customize the webhook payload"
      ],
      "title": "Integrations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "7220c630fc187bb61784ff2cc2213e588b269b00",
      "image": "https://docs.newrelic.com/static/d4e9baecc3a76dd1a5945f8ec0aeca66/c1b63/webhook-notification-template.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/notification-integrations/",
      "published_at": "2021-12-04T21:33:21Z",
      "updated_at": "2021-11-25T00:05:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Alerts and Applied Intelligence notification integrations are specific services and platforms you can use to send notifications from New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud) and automatically create and update Jira issues. Permissions The required permissions from the Jira API-Token are create, edit, and close tickets. To enable the two-way sync toggle, the provided Jira API-Key should have an Admin role. Set up a Jira destination Create Jira issues, then enable Jira and New Relic to share updates and stay synced. To create a Jira destination, enter the following information: Destination name: Custom name to identify the destination Jira account endpoint: the URL of the destination User-name: this will be the email address of the user making the connection API token: generated from your Atlassian account Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. Before saving the destination, we recommend you test the connection via the test connection button. Jira destination configuration. We recommand to test the connection before saving. Two-way sync You can enable a two-way integration with Jira to keep the issues' state synced with the corresponding state in New Relic. To enable two-way sync, turn on the ‘two-way integration’ toggle. When turned on, a Jira Webhook would be created in your Jira account at a later stage, for the selected project (see ‘customize a message template’). The webhook would contain access details to Newrelic (URL and Newrelic-API-KEY) Configure the message template To configure a template for a Jira issue, you first need to choose a destination. You will be able to create a new destination at this stage. Upon successful connection to the destination, you will need to choose a project, and then select the Jira issue type you would like to be used. Once the issue-type is selected, the configured project's fields are fetched from your account and automatically mapped to your Jira instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Jira message template. Send a test notification You can see how the JIRA issue will appear by clicking a test notification with default field values. If successful, a JIRA issue will be created and a link will appear. ServiceNow (Incident-Management) Integrate New Relic with ServiceNow Incident-Management and automatically create and update incidents. Roles As part of the integrations, we fetch fields from the your serviceNow incident table and optional values. For this, the provided ServiceNow user details required read permissions for the tables: sys_dictionary, sys_choice, sys_user and task. A read/write permission to incident To be able to fetch users for the caller column, we required read permissions for the sys_users table. The above permissions can be achieved with the roles personalize_choices, personalize_dictionary, rest_service, itil. Read/Write permissions to the api_key_credentials table is required to enable two-way integration. This can be covered with the roles credentials_admin and discovery_admin. Set up a destination To create a ServiceNow destination, enter the following information: Destination Name: custom name to identify the destination Domain: the URL of the destination User-name: the name of the user Password: the user name’s password Before saving the destination, we recommend testing the connection by clicking the test connection button. Two-way sync You can configure a two-way integration with ServiceNow Incidents Management to keep the incidents' state synced with the corresponding state in New Relic. Here are some required steps to remember when configuring the two-way integration: Turn on the two-way integration toggle. Open and download this XML file, which includes the business rule triggering events back to New Relic One. In the ServiceNow sidebar menu, go to System Definition > Business Rules. Click the menu icon in one of the column headers, select Import XML and upload the XML file you downloaded. Once the Destination is saved, a New-Relic API-Key will be kept in the api_key_credentials. The key would sent in a header as part of the callback REST call to New-Relic Configure the message template Upon a successful connection, ServiceNow incident table columns are fetched from your account and automatically mapped to your ServiceNow instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Select, edit or remove fields for the ServiceNow-Incident template. Send a test notification You can see how the ServiceNow incident will appear by clicking a test notification with default field values. If successful, an incident will be created and a link will appear. Slack Send notifications-messages to your Slack channels. Prerequisites Your Slack workspace needs to have the New Relic application installed. The application must be approved by a workspace admin before it can be individually installed by users Set up a Slack destination Click on the `one-click Slack authentication' will lead you to the Slack landing page to continue the OAuth2 authentication process. On the Slack landing page, if you're not signed into the required workspace, you're redirected to Slack to sign in. Add your workspace name or select the relevant workspace and click Continue. When signed in to the selected workspace, you are requested to allow New Relic to perform the specified actions. Clicking `Allow' will redirect you back to the Destination page. Configure the Slack message settings Select a Destination(Workspace) and select a Slack-channel where the messages will be sent. You can create a new destination if there is no pre-defined destination for the required workspace. Note that, for privacy reasons, users need to be authenticated to select private channels (one-time process) Send a test notification You can send a test notification with a pre-defined example payload to the channel. This creates a message in the selected Slack-channel. Webhook Use the webhook notifier to send the notification messages to any endpoint you like. Set up a webhook destination To create a webhook destination, you need the following: Destination Name: A unique destination name URL: the endpoint of the target application, authentication and custom headers if needed. Authorization mechanism (Optional):. Can be basic authentication or a bearer token Configure the webhook event template Pick a webhook destination from the list and configure the HTTP-POST request. The request configuration requires you to: Set a name for the template. Select a pre-configured destination from the destinations list or create a new one. Add custom headers (optional). Configure the request’s payload. Customize the webhook payload You can use the default payload or customize it to contain the required data. Pick Variables from the variables menu and apply handlebars syntax to enrich your webhook. Note that the request’s content-type is JSON by default. Hence, the payload needs to keep the JSON form. See Usage examples The ‘preview’ section on the right hand-side shows an expected payload after the template is rendered. If the eventual payload would not form a valid Json, an error will be shown and it won’t be possible to save the template. If the webhook payload conforms a valid Json, you can send a test notification to your defined webhook destination We recommend sending a test notification to make sure that everything's connected correctly.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.92798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Set up a Jira <em>destination</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Early access The features described here are early access. You won&#x27;t be able to use these features if you&#x27;re not part of the early access program. For more information on related features, see our docs on <em>Alerts</em> notification channels, <em>Incident</em> <em>Intelligence</em> <em>destinations</em>, and Proactive Detection"
      },
      "id": "618ff71628ccbc60710321e4"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-12-04T15:29:57Z",
      "updated_at": "2021-12-04T15:29:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: Full platform user access. If you haven't already, sign up for a New Relic account to get started. An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example, uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 viewChartImageUrl string Image showing a chart of the anomalous data. anomalyzerUrl string URL that can be opened to analyze the anomaly in New Relic One. JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}], \"viewChartImageUrl\": \"{{viewChartImageUrl}}\", \"anomalyzerUrl\": \"{{anomalyzerUrl}}\" } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"data\": [ { \"value\": \"100\", \"unit\": \"count\", \"timestamp\": 1637260259819 }, { \"value\": \"99\", \"unit\": \"count\", \"timestamp\": 1637260319819 }, { \"value\": \"0\", \"unit\": \"count\", \"timestamp\": 1637260379819 } ], \"viewChartImageUrl\": \"https://www.example.com/image/8353cf2c-945c-48e8-99de-e903f033a881?height=200&width=400&show_timezone=true\", \"anomalyzerUrl\": \"https://www.example.com/anomalyzerUrlExample\" } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.1069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Applied</em> <em>Intelligence</em>&#x27;s Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/alerts-applied-intelligence/notifications/intro-notifications": [
    {
      "sections": [
        "Workflows variables",
        "Variables",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview"
      ],
      "title": "Workflows variables",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "workflows",
        "Enrichments",
        "Issues"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-12-04T21:25:55Z",
      "updated_at": "2021-12-04T21:25:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of the variables used for incident workflows. Variables Use the variables from the issue entity to select the kind of issues you would like to send as well as the message template which appear on the notifications. Here's a comprehensive list of variables: Key (First word will be used for grouping) Display Name (First word will be used for grouping) accumulations.conditionName Alert Condition Names accumulations.origin Issue Origin accumulations.policyName Alert Policy Names accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID issue.pageUrl Issue Page URL labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Workflow data enrichment examples To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName in {{entities.names}} Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entities.names is a list of identifiers for the entities. You can use any other entity properties in the same way. You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entities.names}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName in {{entitiesData.names}} since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName in {{entitiesData.names}} Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = {{entitiesData.names}} since 1 hour ago. Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 343.3911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workflows</em> variables",
        "sections": "<em>Workflows</em> variables",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "An explanation of the variables used for incident <em>workflows</em>. Variables Use the variables from the issue entity to select the kind of issues you would like to send as well as the message template which appear on the <em>notifications</em>. Here&#x27;s a comprehensive list of variables: Key (First word"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-12-04T15:29:57Z",
      "updated_at": "2021-12-04T15:29:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: Full platform user access. If you haven't already, sign up for a New Relic account to get started. An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example, uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 viewChartImageUrl string Image showing a chart of the anomalous data. anomalyzerUrl string URL that can be opened to analyze the anomaly in New Relic One. JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}], \"viewChartImageUrl\": \"{{viewChartImageUrl}}\", \"anomalyzerUrl\": \"{{anomalyzerUrl}}\" } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"data\": [ { \"value\": \"100\", \"unit\": \"count\", \"timestamp\": 1637260259819 }, { \"value\": \"99\", \"unit\": \"count\", \"timestamp\": 1637260319819 }, { \"value\": \"0\", \"unit\": \"count\", \"timestamp\": 1637260379819 } ], \"viewChartImageUrl\": \"https://www.example.com/image/8353cf2c-945c-48e8-99de-e903f033a881?height=200&width=400&show_timezone=true\", \"anomalyzerUrl\": \"https://www.example.com/anomalyzerUrlExample\" } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 334.26416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " is detected, it&#x27;s automatically surfaced in various activity streams, the <em>Applied</em> <em>Intelligence</em> anomalies feed and is available for querying via NRQL. Receiving <em>notifications</em>: We send <em>notifications</em> when we detect anomalous changes in throughput, <em>error</em> rate, or response time. The <em>notifications</em> are sent"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Workflows",
        "What is an issue",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier"
      ],
      "title": "Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Workflows",
        "Notifications"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-12-08T01:49:33Z",
      "updated_at": "2021-11-24T04:31:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With workflows you control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. What is an issue Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. For more information see Use Incident Inteligence. Add a Workflow The workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Notify click Workflow, then click Add a workflow. Tip The maximum number of workflows that can be added is 100 per environment and 50 per account Name your workflow. This field is mandatory and needs to be unique. Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enriched Data (available to full platform users). Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: The query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important At this stage, visual representation of enrichments are sent to Slack and email. For Servicenow and JIRA destinations we recommend to limit to NRDB queries with single value results (for example: count, min, max, etc.). The maximum number of enrichments per workflow is 5. The maximum number of variables an enrichment can contain is 1. Notify - Choose one or more destinations and add an optional message Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. To learn how to set up destinations and configure message templates, check the documentation on notifications. Click “update message” once completing the notifier requirements Optional : Test your workflow We'll use existing data from your account to test what you've configured and send a sample notification Complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.9921,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workflows</em>",
        "sections": "<em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " problem of your symptoms. When a new incident is created, Incident <em>Intelligence</em> opens an issue and evaluates other open issues for correlations. For more information see Use Incident Inteligence. Add a <em>Workflow</em> The <em>workflows</em> feature is located under the <em>Alerts</em> &amp; AI menu. Go to one.newrelic.com, click"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/notifications/message-templates": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-12-04T15:29:57Z",
      "updated_at": "2021-12-04T15:29:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: Full platform user access. If you haven't already, sign up for a New Relic account to get started. An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example, uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 viewChartImageUrl string Image showing a chart of the anomalous data. anomalyzerUrl string URL that can be opened to analyze the anomaly in New Relic One. JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}], \"viewChartImageUrl\": \"{{viewChartImageUrl}}\", \"anomalyzerUrl\": \"{{anomalyzerUrl}}\" } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"data\": [ { \"value\": \"100\", \"unit\": \"count\", \"timestamp\": 1637260259819 }, { \"value\": \"99\", \"unit\": \"count\", \"timestamp\": 1637260319819 }, { \"value\": \"0\", \"unit\": \"count\", \"timestamp\": 1637260379819 } ], \"viewChartImageUrl\": \"https://www.example.com/image/8353cf2c-945c-48e8-99de-e903f033a881?height=200&width=400&show_timezone=true\", \"anomalyzerUrl\": \"https://www.example.com/anomalyzerUrlExample\" } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.10675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Applied</em> <em>Intelligence</em>&#x27;s Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Requirements",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-12-04T15:27:15Z",
      "updated_at": "2021-11-24T14:43:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Requirements If you haven't already, sign up for a New Relic account to get started. To use most Applied Intelligence features, you must be a full platform user. For more information, see user type capabilities. Set up Incident Intelligence To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.46213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Destinations",
        "Early access",
        "Tip",
        "Required capabilities",
        "Manage destinations",
        "Destination status",
        "Notifications log"
      ],
      "title": "Destinations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "6a4550f053d167b43178996347fc6a51d2953e59",
      "image": "https://docs.newrelic.com/static/a4a0201ffecf01f56e314de250eeee71/c1b63/destinations-overview.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/destinations/",
      "published_at": "2021-12-04T21:32:52Z",
      "updated_at": "2021-11-25T00:15:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Destinations are where we send notifications about your New Relic One data. A destination is a unique identifier for a third-party system that you use. Destination settings contain the connection details to integrate with third-party systems and can be used across a variety of tools in New Relic One. The supported destination platforms include: Atlassian Jira ServiceNow Slack Webhook Coming soon: Email For more on these and other destinations, see notification integrations. Tip It's also possible to configure destinations using the aiNotifications NerdGraph API. Required capabilities Destination settings require specific capabilities: To access your settings: you need View capabilities for Applied Intelligence:Destinations or Alerts. To modify or delete your settings: you need Modify capabilities for Applied Intelligence:Destinations or Alerts. Manage destinations Go to one.newrelic.com, click Alerts & AI, and in the left nav under Enrich and Respond, click Destinations. The destinations table shows information about the existing destinations and allows users to enable, disable, and modify. To add a destination, click the appropriate platform tile. To modify destination settings, click the destination row in the destinations table. one.newrelic.com > Alerts & AI > Destinations. Destination status Destinations have a 'status' value that indicates if we encountered issues while processing and sending events to them (see the destinations table in the above image). Some errors, like Authentication or Authorization issues, require an update to the destination's connection details. After the update, the destination status value will be changed to \"Default\". Notifications log To view past notification events details, go to the Destination menu, and click the Notifications log tab. Notifications log enable you to view the history and status of all your past notifications. Here you can view the status of any notification along with related error details and destination ticket numbers. Filter your destination logs by destination type, sent by, and status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.70013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Notifications</em> log",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Early access The features described here are early access. You won&#x27;t be able to use these features if you&#x27;re not part of the early access program. For more information on related features, see our docs on <em>Alerts</em> <em>notification</em> channels, <em>Incident</em> <em>Intelligence</em> destinations, and Proactive Detection"
      },
      "id": "618f3a3ee7b9d2bd07388279"
    }
  ],
  "/docs/alerts-applied-intelligence/notifications/notification-integrations": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Requirements",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Aporia (MLOps)",
        "Superwise (MLOps)",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "EOL NOTICE",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-12-04T15:27:15Z",
      "updated_at": "2021-11-24T14:43:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Requirements If you haven't already, sign up for a New Relic account to get started. To use most Applied Intelligence features, you must be a full platform user. For more information, see user type capabilities. Set up Incident Intelligence To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. To configure Algorithmia for Incident Intelligence, see our integration docs. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. To configure our Aporia integration, see our docs. Superwise (MLOps) By integrating Incident Intelligence with your Superwise machine-learning models, you can monitor your machine learning model performance. To configure our Superwise integration, see our docs. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can set other destinations: Send data to PagerDuty EOL NOTICE As of October 2021, we've discontinued support for several capabilities with PagerDuty, including suggested responders, golden signals, and component enrichment. For more details, including how you can easily make this transition, see our Explorers Hub post. Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.10016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources, then <em>Alerts</em>. Tip Adding anomalies"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Destinations",
        "Early access",
        "Tip",
        "Required capabilities",
        "Manage destinations",
        "Destination status",
        "Notifications log"
      ],
      "title": "Destinations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "6a4550f053d167b43178996347fc6a51d2953e59",
      "image": "https://docs.newrelic.com/static/a4a0201ffecf01f56e314de250eeee71/c1b63/destinations-overview.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/destinations/",
      "published_at": "2021-12-04T21:32:52Z",
      "updated_at": "2021-11-25T00:15:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Destinations are where we send notifications about your New Relic One data. A destination is a unique identifier for a third-party system that you use. Destination settings contain the connection details to integrate with third-party systems and can be used across a variety of tools in New Relic One. The supported destination platforms include: Atlassian Jira ServiceNow Slack Webhook Coming soon: Email For more on these and other destinations, see notification integrations. Tip It's also possible to configure destinations using the aiNotifications NerdGraph API. Required capabilities Destination settings require specific capabilities: To access your settings: you need View capabilities for Applied Intelligence:Destinations or Alerts. To modify or delete your settings: you need Modify capabilities for Applied Intelligence:Destinations or Alerts. Manage destinations Go to one.newrelic.com, click Alerts & AI, and in the left nav under Enrich and Respond, click Destinations. The destinations table shows information about the existing destinations and allows users to enable, disable, and modify. To add a destination, click the appropriate platform tile. To modify destination settings, click the destination row in the destinations table. one.newrelic.com > Alerts & AI > Destinations. Destination status Destinations have a 'status' value that indicates if we encountered issues while processing and sending events to them (see the destinations table in the above image). Some errors, like Authentication or Authorization issues, require an update to the destination's connection details. After the update, the destination status value will be changed to \"Default\". Notifications log To view past notification events details, go to the Destination menu, and click the Notifications log tab. Notifications log enable you to view the history and status of all your past notifications. Here you can view the status of any notification along with related error details and destination ticket numbers. Filter your destination logs by destination type, sent by, and status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.20105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Destinations</em>",
        "sections": "<em>Destinations</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Early access The features described here are early access. You won&#x27;t be able to use these features if you&#x27;re not part of the early access program. For more information on related features, see our docs on <em>Alerts</em> notification channels, <em>Incident</em> <em>Intelligence</em> <em>destinations</em>, and Proactive Detection"
      },
      "id": "618f3a3ee7b9d2bd07388279"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-12-04T15:29:57Z",
      "updated_at": "2021-12-04T15:29:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: Full platform user access. If you haven't already, sign up for a New Relic account to get started. An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the New Relic application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example, uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 viewChartImageUrl string Image showing a chart of the anomalous data. anomalyzerUrl string URL that can be opened to analyze the anomaly in New Relic One. JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}], \"viewChartImageUrl\": \"{{viewChartImageUrl}}\", \"anomalyzerUrl\": \"{{anomalyzerUrl}}\" } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"data\": [ { \"value\": \"100\", \"unit\": \"count\", \"timestamp\": 1637260259819 }, { \"value\": \"99\", \"unit\": \"count\", \"timestamp\": 1637260319819 }, { \"value\": \"0\", \"unit\": \"count\", \"timestamp\": 1637260379819 } ], \"viewChartImageUrl\": \"https://www.example.com/image/8353cf2c-945c-48e8-99de-e903f033a881?height=200&width=400&show_timezone=true\", \"anomalyzerUrl\": \"https://www.example.com/anomalyzerUrlExample\" } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.10675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Applied</em> <em>Intelligence</em>&#x27;s Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/apis/index": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.6614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Through our opensource agents or <em>APIs</em>, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "ebc829a1c1b74c866f5326f90a6d5119fdcfae10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T22:00:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata For PHP, logs in context is only supported from the distributed tracing UI, not in the Logs tab of the APM UI. Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension PHP: Monolog extension Python: Streamhandler example Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 66.52542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent <em>APIs</em> with logs in context",
        "sections": "Use APM agent <em>APIs</em> with logs in context",
        "tags": "Logs in context with agent <em>APIs</em>",
        "body": " your logs. APM agent trace metadata and linking metadata <em>APIs</em> To get properly annotated logs for logs in context, use the following <em>API</em> calls for your APM agent. These <em>APIs</em> pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent <em>APIs</em>: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.787083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    }
  ],
  "/docs/apis/insights-apis/insights-dashboard-api": [
    {
      "sections": [
        "Insights query API",
        "Tip",
        "Requirements and recommendations",
        "1. Register an API key",
        "2. Create the API query request",
        "Linux",
        "Microsoft Windows",
        "3. Process the returned JSON",
        "Example",
        "Query, query API request, returned data",
        "Rate limiting guidelines"
      ],
      "title": "Insights query API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "fa0e72f1345a7adde2418c08dc8950c970140a74",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/query-insights-event-data-api/",
      "published_at": "2021-12-04T21:33:42Z",
      "updated_at": "2021-07-08T23:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Insights query API is a REST API for making NRQL queries. Tip This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. Requirements and recommendations This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. Use of this API may be restricted by role-related user permissions. To add custom data to New Relic, you'd use our data ingest APIs. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. 1. Register an API key To use the Insights query API, you need a query key. You can have multiple query keys, and any query key can be used to initiate any Insights API query. If you have multiple systems querying Insights or different data destinations, New Relic recommends you use multiple query keys to enhance data security. For security reasons, query keys cannot be altered or read using the API. To change or read a query key, use the New Relic UI. Tip This API is no longer the preferred way to query New Relic data. Please use NerdGraph to do that. To create a new query key: Go to insights.newrelic.com > Manage data > API keys. Select the plus icon next to the Query keys heading. Enter a short description of the key. Select Save your notes. 2. Create the API query request When you create or edit a query key, you will see an example curl query that you can use as a template. The example query won't work unless you follow these query rules: The NRQL query string must be URL-encoded. The query string must be less than 4000 bytes. The URL must contain a valid account ID. The X-Query-Key must contain a valid query key. The Content-Type must be application/json. Linux Here is a curl example: curl -H \"Accept: application/json\" -H \"X-Query-Key: YOUR_QUERY_KEY\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=YOUR_URL_ENCODED_QUERY\" Copy Microsoft Windows You can use Powershell to query events via API: Invoke-WebRequest -Uri https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=YOUR_URL_ENCODED_QUERY -Headers @{\"X-Query-Key\"=\"YOUR_QUERY_KEY\"} -ContentType \"application/json\" -Method GET Copy 3. Process the returned JSON The query API returns results in JSON format. There is a limit of 2,000 results per request. The structure of the JSON data depends on the NRQL that you used in the request: Different combinations of SELECT statements, clauses, and functions each return an appropriate response. When writing your code to process the JSON, you should do a test run of your query and examine the resulting JSON. Example The Insights query API returns JSON data. Here's an example of a query, its query request format, and its returned data: Query, query API request, returned data Original NRQL query: SELECT count(appName) FROM PageView SINCE '2014-08-04 00:00:00+0500' Copy Query cURL request (with URL-encoded NRQL query): curl -H \"Accept: application/json\" -H \"X-Query-Key: YOUR_QUERY_KEY\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/query?nrql=SELECT+count%28appName%29+FROM+PageView+SINCE+%272014-08-04+00%3A00%3A00%2B0500%27\" Copy Returned JSON data: { \"results\": [ { \"count\": 80275388 } ], \"metadata\": { \"eventTypes\": [ \"PageView\" ], \"eventType\": \"PageView\", \"openEnded\": true, \"beginTime\": \"2014-08-03T19:00:00Z\", \"endTime\": \"2017-01-18T23:18:41Z\", \"beginTimeMillis=\": 1407092400000, \"endTimeMillis\": 1484781521198, \"rawSince\": \"'2014-08-04 00:00:00+0500'\", \"rawUntil\": \"`now`\", \"rawCompareWith\": \"\", \"clippedTimeWindows\": { \"Browser\": { \"beginTimeMillis\": 1483571921198, \"endTimeMillis\": 1484781521198, \"retentionMillis\": 1209600000 } }, \"messages\": [], \"contents\": [ { \"function\": \"count\", \"attribute\": \"appName\", \"simple\": true } ] } } Copy Rate limiting guidelines We have query rate limits. You likely won't encounter these limits, especially if you follow these general guidelines: Limit the amount of requests with complex queries (for example, queries with FACET or TIMESERIES clauses, or queries of over a million events) run at the same time. Limit the amount of requests run concurrently over extended periods of time to a maximum of 5, especially if they include complex queries. If New Relic applies rate limits on your account for the number of queries per minute, the query API returns a 429 error. If New Relic applies rate limits on your account for records inspected, the query API returns a 503 error and your charts may display timeout error messages.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.3386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Insights</em> query <em>API</em>",
        "sections": "<em>Insights</em> query <em>API</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "-Key: YOUR_QUERY_KEY&quot; &quot;https:&#x2F;&#x2F;<em>insights</em>-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCOUNT_ID&#x2F;query?nrql=SELECT+count%28appName%29+FROM+PageView+SINCE+%272014-08-04+00%3A00%3A00%2B0500%27&quot; Copy Returned JSON <em>data</em>: { &quot;results&quot;: [ { &quot;count&quot;: 80275388 } ], &quot;metadata&quot;: { &quot;<em>event</em>Types&quot;: [ &quot;PageView&quot; ], &quot;<em>event</em>"
      },
      "id": "609f9c86196a67e93722b170"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-06T01:41:15Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring custom <em>events</em> and attributes",
        "sections": "Report mobile monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " gathers the attributes and events for that session and sends them to <em>Insights</em>. (On iOS, this happens the next time the app is launched). You can then use <em>Insights</em> to query and analyze the <em>event</em> and attribute <em>data</em>. To set the maximum time (in seconds) that the agent will store events in memory, use"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-06T01:41:56Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring custom <em>events</em> and attributes",
        "sections": "Report browser monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " attribute to the PageView <em>event</em> via the browser agent, use the setCustomAttribute browser <em>API</em> call. This allows you to capture an attribute to be annotated on any PageAction <em>event</em>. Forward custom attributes from APM <em>data</em> If you added custom attributes to the APM Transaction <em>event</em> via an APM agent, you"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/apis/insights-apis/query-insights-event-data-api": [
    {
      "sections": [
        "Insights Dashboard API",
        "End of life notice",
        "Requirements",
        "Overview",
        "Example use cases",
        "Account and data security",
        "Use the API Explorer",
        "View Dashboard API video",
        "Use API endpoints",
        "Dashboard API schema",
        "Important",
        "Caution",
        "Example dashboard schema",
        "Dashboard data definitions",
        "Widget data definitions",
        "Supported visualizations"
      ],
      "title": "Insights Dashboard API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "71a0104d88a3a8859513802e853850d8b0456606",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/insights-dashboard-api/",
      "published_at": "2021-12-04T21:33:57Z",
      "updated_at": "2021-08-02T03:52:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do not use the Insights Dashboards API. Instead, use the New Relic One Dashboards API with NerdGraph, our GraphQL API. End of life notice The Insights Dashboard API reaches end of life in 2021. As of July 28, 2021, the CREATE and UPDATE endpoints are not available. As of August 30, 2021, the GET and DELETE endpoints are not available. To make the transition from the Insights Dashboard API to the New Relic One Dashboards API, see our migration guide. For more information, see the NerdGraph dashboards tutorial and Explorers Hub post. Requirements If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Overview The Insights Dashboard API allows you to list, create, read, update, and delete new or existing dashboards. New Relic's API Explorer includes the cURL request format, available parameters, response status codes, and JSON response structure for available API calls. Example use cases The Insights Dashboard API is a flexible solution for many different use cases. Here are a few examples of how you can leverage the Dashboard API to solve problems: Automatically create dashboards for new teams or services pre-populated with standard organization metrics and charts. Use the API to view dashboard schemas, and save them in a central repository for source control and backups. Create widget and dashboard templates to allow teams to self-service. Account and data security The Dashboard API includes safeguards to help ensure account and data security. Requirements Comments User key and permissions Required: This API requires a user key. You cannot use your account-level REST API key to manage dashboards. Cross-account widgets You can view cross-account widgets on a dashboard by using the Insights or New Relic One dashboards UI. However, the ability to view cross-account widgets when using the Dashboard API has these restrictions: To view the list of widgets on a specific dashboard with the Dashboard API, you must use the SHOW endpoint. To view a widget in the API payload, the widget's account ID must be the same as the account ID for the payload. If the account ID is not the same, the widget's details will not be listed. Instead, the widget's payload will show: \"visualization\": \"inaccessible\" Copy Use the API Explorer To view the Dashboard API options in the API Explorer: Log in to your New Relic account. Go to rpm.newrelic.com/api/explore. From the API Explorer's Select an account and key dropdown, select a user key. Select Dashboards, then select the API function. To use API functions with existing dashboards, include the dashboard id. To find the dashboard id, select the LIST endpoint, and apply filtering options. View Dashboard API video Follow along with this step-by-step tutorial to learn how to find your API keys, create new dashboards, view and update existing dashboards via the REST API. For a step-by-step guide to using the New Relic API Explorer to manage Insights dashboards, watch this video (approximately 6 minutes). Or, go directly to the full online course about New Relic APIs. Use API endpoints The API supports the following functions for Insights dashboards only. The API does not support these functions for data apps (collections of linked dashboards). API endpoints Comments CREATE POST /v2/dashboards Create a new dashboard. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to POST more than 300 widgets will produce an error. To add more widgets to the dashboard, use the Insights UI. UPDATE PUT /v2/dashboards/:id: Update an existing dashboard for the dashboard id. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to PUT more than 300 widgets will produce an error. To add more or edit existing widgets on the dashboard, use the Insights UI. SHOW GET /v2/dashboards/:id: View an existing dashboard and all accessible widgets for the dashboard id. To help ensure data security, the SHOW function returns only the dashboard widgets that the user has permission to view. If a dashboard includes widgets that the user is not authorized to view, the API will provide a placeholder with the visualization field set to inaccessible. LIST GET /v2/dashboards?page=:page:&per_page=:count: View a paginated list of dashboards. The list shows filterable dashboard metadata only; no widgets will appear in the list. Search options include: filter[title] as substring search filter[category] (all / favorites / mine} filter[created_after] as ISO date filter[created_before] as ISO date filter[updated_after] as ISO date filter[updated_before] as ISO date Sort options include: name recently_viewed last_edited If no sort option is provided, results will be ordered by id. Pagination options include the page and per_page fields. The per_page field controls the number of results per page with a default and maximum of 100 results. The response will include a pagination Link header, which provides next page and last page links. DELETE DELETE /v2/dashboards/:id: Delete an existing dashboard indicated by the dashboard id. Dashboard API schema JSON is the only supported format. When using API functions, be sure to add .json to the end of the request URL, as shown in the API Explorer. Important Widgets have a size limit of 3x3 (height and width may not exceed 3). Caution The Dashboard API 3-column restriction also applies to the dashboards you upload to New Relic One dashboards. If you update a dashboard with a different layout using the API, the uploaded dashboard will revert to the 3-column configuration. Example dashboard schema { \"dashboard\": { \"metadata\": { \"version\": 1 }, \"title\": \"API Widget Sample\", \"icon\":\"none|archive|bar-chart|line-chart|bullseye|user|usd|money|thumbs-up|thumbs-down|cloud|bell|bullhorn|comments-o|envelope|globe|shopping-cart|sitemap|clock-o|crosshairs|rocket|users|mobile|tablet|adjust|dashboard|flag|flask|road|bolt|cog|leaf|magic|puzzle-piece|bug|fire|legal|trophy|pie-chart|sliders|paper-plane|life-ring|heart\", \"grid_column_count\": 3|12, \"visibility\": \"owner|all\", \"editable\": \"read_only|editable_by_owner|editable_by_all\", \"filter\": { \"event_types\": [ \"Transaction\" ], \"attributes\": [ \"appName\" ] }, \"widgets\": [ { \"visualization\": \"billboard|gauge|billboard_comparison\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Threshold Event Chart\", \"notes\": null, \"threshold\": { \"red\": 18000000, \"yellow\": 8000000 } }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 1 } }, { \"visualization\": \"facet_bar_chart|faceted_line_chart|facet_pie_chart|facet_table|faceted_area_chart|heatmap\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago facet appName\" } ], \"presentation\": { \"title\": \"Facet Chart\", \"notes\": null, \"drilldown_dashboard_id\": 64 }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 2 } }, { \"visualization\": \"attribute_sheet|single_event|histogram|funnel|raw_json|event_feed|event_table|uniques_list|line_chart|comparison_line_chart\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT latest(appName), latest(duration) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Simple Event Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 3 } }, { \"visualization\": \"markdown\", \"account_id\": 12345, \"data\": [ { \"source\": \"# Dashboard Note\\n\\n[link goes here](https://www.newrelic.com)\" } ], \"presentation\": { \"title\": \"\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 1 } }, { \"visualization\": \"metric_line_chart\", \"account_id\": 12345, \"data\": [ { \"duration\": 1800000, \"end_time\": null, \"entity_ids\": [ 238575 ], \"metrics\": [ { \"name\": \"Apdex\", \"units\": null, \"scope\": \"\", \"values\": [ \"score\" ] } ], \"order_by\": \"score\", \"limit\": 10 } ], \"presentation\": { \"title\": \"Metric Line Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 2 } }, ] } } Copy Dashboard data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Dashboard data element Description metadata Object Specifies the version of the dashboard schema. The version must be 1. icon String Name of an icon from the Insights icon library. grid_column_count Integer Specifies the number of columns in the grid layout. title String User-supplied title of the dashboard. filter Object Specifies configuration of the smart filter on the dashboard. visibility String Specifies who can view the dashboard in the Insights UI and the API. editable String Specifies who can edit the dashboard in the Insights UI and the API. widgets Array Array of widget data element objects. Widget data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Widget data element Description visualization String What sort of visualization to place in the widget; for example, billboard, line_chart, area chart, etc. data Array Array of objects with chart-specific information needed to query necessary data. Currently only one data object is supported. account_id Long Source account to fetch data from, if not the current account. presentation Object Object with chart title and notes, plus chart-specific customization. layout Object Object with column, row, width, and height to determine chart layout in the dashboard. Supported visualizations The Dashboard API supports: event_table line_chart facet_table facet_bar_chart facet_pie_chart billboard faceted_area_chart faceted_line_chart event_table comparison_line_chart heatmap histogram billboard_comparison attribute_sheet funnel gauge json list Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.4609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Insights</em> Dashboard <em>API</em>",
        "sections": "<em>Insights</em> Dashboard <em>API</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " and DELETE endpoints are not available. To make the transition from the <em>Insights</em> Dashboard <em>API</em> to the New Relic One Dashboards <em>API</em>, see our migration guide. For more information, see the NerdGraph dashboards tutorial and Explorers Hub post. Requirements If your account hosts <em>data</em> in the EU <em>data</em> center"
      },
      "id": "609f9c8664441fc63fd2a1f9"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "65970eacbedb3360fd1c7394affc8cbc42f2ab0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-12-06T01:41:15Z",
      "updated_at": "2021-10-23T21:59:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring custom <em>events</em> and attributes",
        "sections": "Report mobile monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " gathers the attributes and events for that session and sends them to <em>Insights</em>. (On iOS, this happens the next time the app is launched). You can then use <em>Insights</em> to query and analyze the <em>event</em> and attribute <em>data</em>. To set the maximum time (in seconds) that the agent will store events in memory, use"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "17c97a462616f2b23ead796b62780a1ffeb3dfac",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-12-06T01:41:56Z",
      "updated_at": "2021-10-23T21:59:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring custom <em>events</em> and attributes",
        "sections": "Report browser monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " attribute to the PageView <em>event</em> via the browser agent, use the setCustomAttribute browser <em>API</em> call. This allows you to capture an attribute to be annotated on any PageAction <em>event</em>. Forward custom attributes from APM <em>data</em> If you added custom attributes to the APM Transaction <em>event</em> via an APM agent, you"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/apis/intro-apis/introduction-new-relic-apis": [
    {
      "sections": [
        "New Relic API keys",
        "API key UI",
        "Overview of keys",
        "Keys for data ingest",
        "Keys for querying and configuration",
        "License key",
        "View and manage license key",
        "User key",
        "Browser key",
        "Insights insert key",
        "Important",
        "REST API key",
        "Insights query key",
        "Admin key",
        "Account ID"
      ],
      "title": "New Relic API keys",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "b373cd68cf21daeb5d912ffb4b1ae3f14f500fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/",
      "published_at": "2021-12-04T21:34:15Z",
      "updated_at": "2021-11-24T02:46:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has several different APIs that use different API keys. This resource explains our keys, what they're used for, and how to access them. Ready to get started? Make sure you have a New Relic account. It's free, forever! API key UI Most of the keys can be viewed and managed via the API keys UI page: From the account dropdown, click API keys (get a direct link to the API keys page). If you're using NerdGraph, you can manage license keys and user keys from our GraphiQL explorer. Overview of keys If you're using a specific API, see the docs for that API to understand which keys are required and recommended. To learn about our APIs, see Introduction to APIs. Our keys can be broken down into two categories: Keys used for data ingest Keys used for querying and configuration Keys for data ingest There are many ways to get data into New Relic. Here are the API keys used for data ingest: License key: our primary ingest key, used for APM ingest, infrastructure monitoring ingest, and our ingest APIs and the integrations that use them. Browser key: used for browser monitoring ingest. Mobile app token: used for mobile monitoring ingest. Insights insert key: an older key that has been mostly deprecated, it has the same functionality as the license key. We recommend using the license key instead. Keys for querying and configuration Here are keys used for querying New Relic data or configuration of features: User key, also known as a \"personal API key\": used for NerdGraph (our GraphQL API) and for accessing REST API endpoints. REST API key: used for the REST API but we instead recommend using the user key because it has fewer restrictions. Insights query key: used with the Insights query API for querying New Relic data. We recommend using NerdGraph instead of this API. License key Our primary key used for data ingest is called the license key, also referenced in the UI and NerdGraph API as ingest - license. The license key is a 40-character hexadecimal string associated with a New Relic account. Each account in a New Relic organization has its own license key. When you first sign up for New Relic, that creates an organization with a single account, and that account has its own license key. If more accounts are added, each account will have its own license key. The types of data ingest the license key is used for include: APM agent data Infrastructure agent data Data sent via our core data ingest APIs (Metric API, Trace API, Event API, Log API), and the SDKs and integrations that use those APIs The license key is used for all data ingest except for browser monitoring data (which uses a browser key) and mobile monitoring data (which uses a mobile app token). Because the license key is used for data ingest, we recommend you treat your license key securely, like you would a password. This ensures no unwanted data is sent to your New Relic account. If your license key falls into the wrong hands, an attacker could send fake data to your account, which could trigger false alerts and contaminate your data so that detecting actual issues is more difficult. If you believe a license key has been exposed and has led to unwanted data, work with our Support team. View and manage license key To manage the license key: From the account dropdown, click API keys (get a direct link to the API keys page). You can't manage or delete the original license key that was created when an account was initially created. For that, contact New Relic support. You can also create additional license keys and manage them with our NerdGraph API. User key New Relic user keys, sometimes referred to as \"personal API keys\", are required for using NerdGraph and for the REST API. A user key is tied to both a specific New Relic user and a specific account, and they cannot be transferred. Our APIs that use this key let a user make queries for any accounts that user has been granted access to, not just the specific account the key was created under. If the key's user is deleted, all their user keys will be deactivated and will no longer be valid in API requests. To view and manage the user key and other API keys in the UI: From the account dropdown, click API keys (here's a direct link to the API keys page). To manage this key via API, see Manage keys with NerdGraph. You can also get or generate a user key from the NerdGraph GraphiQL explorer. Browser key One of the New Relic API keys that are used for data ingest is the browser key. The browser key allows the ingestion of data from New Relic browser monitoring. To view and manage this key: From the account dropdown, click API keys (here's a direct link to the API keys page). You can't manage or delete an original browser key that was created when your account was created. For that, contact New Relic support. Insights insert key Important This key is still in use but we highly recommend using the license key, which can be used for the same things and more. One of the New Relic API keys used for data ingest is the Insights insert key, also known as an \"insert key\"). Note that the license key is used for the same functionality and more, which is why we recommend the license key over this key. This key is used for the ingestion of data via our Event API, Log API, Metric API, and Trace API, or via tools that use those APIs. Tips on availability and access: Because these keys are associated with an account and not a specific user, anyone in the account with access to a key can use it. As a best practice for security purposes, we recommend you use different Insights insert keys for different applications or different data sources. To find and manage Insights insert keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click Insights insert keys. REST API key Important We highly recommend using a user key instead, because that key has fewer restrictions. The REST API key is for using our REST APIs for Alerts, APM, browser, infrastructure alerts, as well as mobile monitoring REST APIs and the API Explorer. Things to consider: We recommend using our newer NerdGraph API over the REST API, if possible. Requires admin-level user permissions. If you don't have access to the REST API key or the REST API explorer, it might be due to lack of permissions. Talk to your New Relic account manager, or use a user key instead. Each New Relic account can have only one REST API key. To find and manage REST API keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click REST API key. Before you configure or delete an API key, ensure you are doing so for the correct account. Insights query key The Insights query key is used for our Insights query API: we now recommend using NerdGraph for querying New Relic data. To find and manage Insights query keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click Insights query keys. Admin key Important As of December 4, 2020, all existing admin keys have been migrated to be user keys. You don’t need to do anything for existing admin keys to remain active. They will be automatically accessible via the API keys UI, labeled as user keys, and granted identical permissions. You can manage them as you would any user key via the same workflow. All migrated admin keys will have a note that says “Migrated from an admin user key” in the key table, so you’ll be able to find them easily. Account ID Looking for the account ID? See Account ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.13428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>API</em> keys",
        "sections": "New Relic <em>API</em> keys",
        "tags": "<em>Intro</em> <em>to</em> <em>APIs</em>",
        "body": "New Relic has several different <em>APIs</em> that use different <em>API</em> keys. This resource explains our keys, what they&#x27;re used for, and how to access them. Ready to <em>get</em> <em>started</em>? Make sure you have a New Relic account. It&#x27;s free, forever! <em>API</em> key UI Most of the keys can be viewed and managed via the <em>API</em> keys"
      },
      "id": "6043fa3464441f1358378f3b"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.47841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> New Relic NerdGraph, our GraphQL <em>API</em>",
        "sections": "<em>Introduction</em> <em>to</em> New Relic NerdGraph, our GraphQL <em>API</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several <em>APIs</em>. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "cd3792932153374adf5d942a09b66aa004e9f889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-12-04T16:44:41Z",
      "updated_at": "2021-12-04T16:44:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Types of integrations We have open source integrations that report data from OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. Find our open source telemetry integrations in New Relic Instant Observability. How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built quickstarts don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.305405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> New Relic&#x27;s open source telemetry integrations",
        "sections": "<em>Introduction</em> <em>to</em> New Relic&#x27;s open source telemetry integrations",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " telemetry data to New Relic. If our pre-built quickstarts don&#x27;t meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest <em>APIs</em>. For example, metrics reported by the DropWizard exporter are ingested via the Metric <em>API</em>, so to understand how to query and chart that type of data, you could read Query metric data."
      },
      "id": "617d5c6f64441f5529fbd550"
    }
  ],
  "/docs/apis/intro-apis/new-relic-api-keys": [
    {
      "sections": [
        "Introduction to New Relic APIs",
        "APIs for data ingest",
        "NerdGraph (GraphQL)",
        "REST API",
        "APIs by feature",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-12-04T21:34:16Z",
      "updated_at": "2021-11-12T01:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Send data to New Relic. Retrieve data from New Relic. View and configure settings. This document provides examples and reference information for our APIs. APIs for data ingest Our four primary data ingest APIs are some of the many solutions for reporting data to New Relic. These APIs can be used directly, but they're also the underlying ingest route for many of our more curated tools, such as our open source telemetry integrations and our Telemetry SDKs. Data type Description Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Event API Send custom event data to New Relic without the use of an agent or integration. Log API Send your log data to New Relic. Trace API Send distributed tracing data to New Relic without the use of an agent or integration. NerdGraph (GraphQL) NerdGraph is the API we recommend for querying New Relic data, querying account information, and making a range of feature configurations. To learn what you can do, check out the NerdGraph tutorials. NerdGraph is our newest API and is our attempt to bring together in one place some of our older APIs, like our REST API. Note that there is still some functionality you can do with REST APIs that can't yet be done with NerdGraph, and this is why some New Relic organizations still use the REST API. REST API Our REST API is our older API for querying and configuration, which NerdGraph is in the process of replacing. The REST API has some configuration abilities that NerdGraph doesn't yet have, but when possible you should use NerdGraph. The REST API can be used for a wide range of features: for detail, see APIs by feature. APIs by feature New Relic tools and features, like APM, infrastructure monitoring, browser monitoring, and alerts, are often used together, and sometimes can overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use NerdGraph. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The browser API resources include: Resource Details Browser agent API Use the browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To query New Relic data, use NerdGraph. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To query New Relic data, use NerdGraph. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To query New Relic data, use NerdGraph. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To query New Relic data, use NerdGraph. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage (original pricing model) For organizations on our original pricing model, you can use NerdGraph to query subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API If you're a New Relic partnership organization, you can use the Partner API to retrieve data and make configurations. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing models that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API Our Insights Query API is mostly deprecated. Instead, use NerdGraph for querying your New Relic data. Dashboard API Use the Dashboards API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.04265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> New Relic <em>APIs</em>",
        "sections": "<em>Introduction</em> <em>to</em> New Relic <em>APIs</em>",
        "tags": "<em>Intro</em> <em>to</em> <em>APIs</em>",
        "body": " solutions for reporting data to New Relic. These <em>APIs</em> can be used directly, but they&#x27;re also the underlying ingest route for many of our more curated tools, such as our open source telemetry integrations and our Telemetry SDKs. Data type Description Metric <em>API</em> Send metrics to New Relic from any source"
      },
      "id": "609fa5cf196a67066022b194"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.47841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> New Relic NerdGraph, our GraphQL <em>API</em>",
        "sections": "<em>Introduction</em> <em>to</em> New Relic NerdGraph, our GraphQL <em>API</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several <em>APIs</em>. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "cd3792932153374adf5d942a09b66aa004e9f889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-12-04T16:44:41Z",
      "updated_at": "2021-12-04T16:44:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Types of integrations We have open source integrations that report data from OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. Find our open source telemetry integrations in New Relic Instant Observability. How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built quickstarts don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.305405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> New Relic&#x27;s open source telemetry integrations",
        "sections": "<em>Introduction</em> <em>to</em> New Relic&#x27;s open source telemetry integrations",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " telemetry data to New Relic. If our pre-built quickstarts don&#x27;t meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest <em>APIs</em>. For example, metrics reported by the DropWizard exporter are ingested via the Metric <em>API</em>, so to understand how to query and chart that type of data, you could read Query metric data."
      },
      "id": "617d5c6f64441f5529fbd550"
    }
  ],
  "/docs/apis/nerdgraph/examples/configure-infinite-tracing-graphql": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/create-widgets-dashboards-api": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/export-dashboards-pdfpng-using-api": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/export-import-dashboards-using-api": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/golden-metrics-entities-nerdgraph-api-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/manage-live-chart-urls-via-api": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-cloud-integrations-api-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-data-partition-rules-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-distributed-trace-data-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-entities-api-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-log-parsing-rules-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-nrql-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-relationships-api-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.83694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.19,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-slm": [
    {
      "sections": [
        "Service Levels Management: Questions and next steps",
        "BETA FEATURE",
        "What permissions do I need to use New Relic's Service Levels?",
        "How do I get support from New Relic during the public beta?",
        "Why don’t I see any data right after I create an SLI?",
        "Can I configure an SLI on any entity type?",
        "Can I get alerts on SLI data?",
        "How does New Relic calculate the remaining error budget?"
      ],
      "title": "Service Levels Management: Questions and next steps",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Service Level Management"
      ],
      "external_id": "262058f4dc430fbaee0382261f79de147e348f53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/service-level-management/faqs-slm/",
      "published_at": "2021-12-04T20:54:32Z",
      "updated_at": "2021-12-04T09:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. What permissions do I need to use New Relic's Service Levels? To use New Relic's Service Levels and see SLO results, you need a full platform user. However, in order to create new SLIs and SLOs, you need the specific capability in your role to modify events to metric rules. If you get the following errors, check your user permissions: The UI has disabled the option to save an SLI/SLO. The API returns the error message “Cannot query field \\\"eventExportRegisterRule\\\" on type \\\"RootMutationType\\\".”. How do I get support from New Relic during the public beta? Service Levels Management is in public beta, and no official support is offered yet through the Support portal. If you have general questions and feedback, please post them on the Explorers Hub. New Relic’s community and the product team will be glad to help you there. If you have suggestions about documentation, please suggest an improvement or send your contribution using the Create issue or Edit page buttons on the top right corner in the docs UI. Why don’t I see any data right after I create an SLI? New Relic starts generating new SLI metrics from the moment that you create an SLI. This is why we need a few minutes before we can start showing the first meaningful SLI attainment results. The benefit of the new data is that it has 13 month retention by default, and it’s more efficient to query for long periods of time. Can I configure an SLI on any entity type? Yes, you can configure an SLI on any entity type, such as an APM service, a browser application, or a Lambda function. SLI queries support NRDB events. Support for dimensional metrics on SLI queries is on our roadmap. Can I get alerts on SLI data? Alerts on New Relic's Service Levels are on our roadmap. How does New Relic calculate the remaining error budget? The remaining error budget indicates what percentage of requests could still have a bad response over the SLO period without compromising the objective. Therefore, the total amount of tolerated bad responses will vary with the throughput of requests. Time-based error budgets are on our roadmap.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 715.56555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> <em>Levels</em> <em>Management</em>: Questions and <em>next</em> steps",
        "sections": "<em>Service</em> <em>Levels</em> <em>Management</em>: Questions and <em>next</em> steps",
        "tags": "<em>Service</em> <em>Level</em> <em>Management</em>",
        "body": "BETA FEATURE This feature is currently in beta. What permissions do I need to use New Relic&#x27;s <em>Service</em> Levels? To use New Relic&#x27;s <em>Service</em> Levels and see <em>SLO</em> results, you need a <em>full</em> platform user. However, in order to create new SLIs and SLOs, you need the specific capability in your role to modify"
      },
      "id": "61ab3a9d28ccbc492ac23ee2"
    },
    {
      "sections": [
        "Consume Service Levels",
        "BETA FEATURE",
        "Check your SLOs state",
        "Understand Service Levels details",
        "Good and bad responses",
        "SLI attainment over time (%)",
        "Compliance over the period",
        "Remaining error budget (Requests)",
        "SLI attainment over time and SLO target (%)",
        "Analyze bad responses"
      ],
      "title": "Consume Service Levels",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Service Level Management",
        "SLI/SLO",
        "Consume"
      ],
      "external_id": "2b1e77937fb81e4b43d6f81d660e53f1cbbb5f80",
      "image": "https://docs.newrelic.com/static/5ecaa57f52ed11c79de67ea6200443c8/c1b63/sli_card.png",
      "url": "https://docs.newrelic.com/docs/service-level-management/consume-slm/",
      "published_at": "2021-12-04T13:52:51Z",
      "updated_at": "2021-12-04T09:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. After you create your set of SLIs and SLOs, New Relic will start generating SLI data. The first results will take a few minutes to appear in the New Relic One UI. Find Service Levels: At the top nav bar, under Service Levels in the More menu (which you can customize). Here you can filter the SLIs by entity tags. At the previews of those entities that have an SLI defined. You can find them all around the UI. For instance, click on an entity from the Explorer's Navigator view. In APM services, at the reports section. In any workload that contains the SLI entity, such as an APM service or browser application. If you want to group SLIs under a certain workload, make sure to add the APM service or browser app to an existing workload, or create a new one. Click on any SLI to open the SLI card, which contains: The entity the SLI refers to, and the SLI name. Each row represents an SLO with: Target and time window. Compliance in the SLO period. Remaining requests error budget. Check your SLOs state Request-based SLOs are determined from SLIs defined as the ratio of the number of good responses to the total number of requests. This means a request-based SLO is met when that ratio meets or exceeds the goal for the SLO compliance period. If the SLO row has a green background, you’re doing good for the period. You may have not served successfully 100% of the requests, but you still have some remaining error budget to consume. If the SLO row has a yellow background, your error budget is closer to being totally consumed, and you should be more cautious for the rest of the period. If the SLO row has a red background, you’ve not reached the target SLO in this period, and you’ve consumed all of your error budget. Be careful if you need to deploy, and plan some work to improve your SLIs. You can click on the SLO to see more data about the entity, such as the golden metrics, the latest deployments, anomalies, and ongoing issues. This data can help you understand when and why you missed the SLO targets. You can define more than one SLO for the same SLI to check how fast you’re consuming the error budget. For instance, if you have an error budget of 0,1% requests for a whole week, you may not want to consume most of it in a single day, or the SLO will be at risk for the rest of the week. Understand Service Levels details We provide SLI details for two main purposes: For SLO analysis: See in which time ranges the SLO targets were missed. For SLI/SLO configuration and fine tuning: Learn how New Relic calculated SLO values. The SLI card contains the following charts: Good and bad responses These are the key concepts to analyze Service Levels: A valid request is any request that you want to count as meaningful for your SLIs. A good response is any response that you consider to provide a good experience (for example, the service responded in less than 2 seconds, providing a good navigation experience for the end user). A bad response is any response that you consider to provide a bad experience (like the service responded with a server error, interrupting the user's flow). This chart shows the total number of valid requests that your service received, broken down by good or bad. This chart shows the actual throughput of your service, which you can use to see if there’s any correlation between the increase of throughput and bad responses. SLI attainment over time (%) It's the proportion of what you consider good responses over time. The line should stay close to 100%, meaning that most requests were served successfully. Compliance over the period It's the ratio of good events (responses) to total events (requests), measured over the SLO compliance period. The closer to 100%, the closer your service is to meet the SLO target over the period. When this percentage goes below the SLO target, the chart will turn red: You need to put more effort in reliability. Remaining error budget (Requests) The error budget is an alternative way to read the SLO. It indicates what percentage of requests could still have a bad response over the SLO period, without compromising the objective. As the total amount of tolerated bad responses will vary with the request throughput, New Relic shows the percentage of remaining error budget: As long as the remaining error budget is above 25%, you'll see green, and your SLO is good. When the error budget goes below 25%, it will turn yellow. This means you’re close to burning the whole budget for the period. You may want to be more careful with new deployments and changes, and plan for some reliability work. Once the error budget is completely spent, it will show in red. SLI attainment over time and SLO target (%) The last chart shows two time series: the (SLI attainment over time) [#sli-over-time] , and the SLO target. When the SLI value is below the SLO target,your service is missing the SLO. Use this chart to learn in which time ranges your service missed the SLO target. Analyze bad responses When an SLO is not compliant, you need to analyze the original data to better understand what the impact is for your customer, with a special focus on what went wrong. At the Service Levels page, click the ... menu in any SLI and select Analyze. You'll access the query that represents the original NRDB events used to determine the bad responses which calculate the SLI attainment. You can then use the query builder to facet and filter down the unsuccessful responses by user account, client id, requesting source, etc. to better understand the cause and impact of missing your SLIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 664.84485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Consume</em> <em>Service</em> <em>Levels</em>",
        "sections": "<em>Consume</em> <em>Service</em> <em>Levels</em>",
        "tags": "<em>Service</em> <em>Level</em> <em>Management</em>",
        "body": " for the same <em>SLI</em> to check how fast you’re consuming the error budget. For instance, if you have an error budget of 0,1% requests for a whole week, you may not want to <em>consume</em> most of it in a single day, or the <em>SLO</em> will be at risk for the rest of the week. Understand <em>Service</em> Levels details We provide"
      },
      "id": "61ab3a9d28ccbc4b5fc23f44"
    },
    {
      "sections": [
        "Get started with New Relic's Service Levels Management",
        "BETA FEATURE",
        "What are SLIs and SLOs?",
        "Service Levels and APM SLA reports",
        "What's next?"
      ],
      "title": "Get started with New Relic's Service Levels Management",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Service Level Management"
      ],
      "external_id": "c3da65667ad9557562bd537c738309d80d3f31ee",
      "image": "https://docs.newrelic.com/static/a0a3554edde9777dc70c4ee8281fddd6/01e7c/slm1_1.png",
      "url": "https://docs.newrelic.com/docs/service-level-management/intro-slm/",
      "published_at": "2021-12-08T01:45:04Z",
      "updated_at": "2021-12-02T01:44:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With New Relic you can define and consume service level indicators and service level objectives for your applications. What are SLIs and SLOs? Service Levels are used to measure the performance of a service from the end user (or client application) point of view. For instance, a Service Level can represent whether a video loaded quickly enough, or whether a directions service returned at least one possible route between two points. Service level indicators (SLIs) are accurate quantitative measures of the user experience as described by a service level. They represent a proportion of successful outputs, and therefore they’re expressed as a percentage (%). For example, an SLI can measure the proportion of requests that were faster than some threshold, or the proportion of records coming into a pipeline that resulted in the correct value coming out. And while users understand that a video might take a few additional seconds to load, or that an application might return an error from time to time, this shouldn’t happen often if you don’t want to lose their trust. Therefore, once you’ve defined SLIs for the performance aspects that are most relevant for the end users of your services, you need to set SLOs to track that the service is meeting their expectations. Service level objectives (SLOs) are defined as a target value that an SLI must meet over a period of time. For example, videos must start playing in less than 2 seconds 99% of the time over a week period. Please refer to the Service Level management use case implementation guide to learn more about identifying service boundaries and deploying the instrumentation that your service levels will be based on. Service Levels and APM SLA reports New Relic has provided automatic SLA Reports for APM Services for a long time. The Apdex-based reports, which you can get on your email inbox on Mondays, are automatically generated for services that produce web transactions, and are useful to see trends over time. On top of the SLAs, our new SLM level capability is better aligned with modern service level best practices, such as those promoted by the Google SRE Handbook, and provides new, improved functionality: SLIs can be defined on any NRDB event that is reported to New Relic, not just APM transactions. Therefore you can also base SLIs on your own custom events. You can decide which service boundaries and which metrics are relevant for your service levels, and you can set your own objectives. You can view SLO results across your accounts, and within your workloads. What's next? Ready to get started? If you don't already have one, sign up for a free New Relic account. You can find Service Levels in several places in New Relic One: At the top nav bar, under the More menu (which you can customize). At the previews of those entities that have an SLI defined. In APM services, at the reports section. Within a workload, at the Service Levels tab. Carry on and read our docs on how to create and consume SLIs and SLOs. You can also check out how to manage SLMs with our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 631.4823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>New</em> Relic&#x27;s <em>Service</em> <em>Levels</em> <em>Management</em>",
        "sections": "Get started with <em>New</em> Relic&#x27;s <em>Service</em> <em>Levels</em> <em>Management</em>",
        "tags": "<em>Service</em> <em>Level</em> <em>Management</em>",
        "body": "BETA FEATURE This feature is currently in beta. With New Relic you can define and <em>consume</em> <em>service</em> <em>level</em> indicators and <em>service</em> <em>level</em> objectives for your applications. What are SLIs and SLOs? <em>Service</em> Levels are used to measure the performance of a <em>service</em> from the end user (or client application"
      },
      "id": "61a824fe28ccbcc5e3c22dc5"
    }
  ],
  "/docs/apis/nerdgraph/examples/nerdgraph-tagging-api-tutorial": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.14288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.18988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/examples/topology-nerdgraph-tutorial": [
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 494.45868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> API",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> API",
        "tags": "<em>NerdGraph</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several APIs. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "List notification channels with their associated policies",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-12-05T05:10:23Z",
      "updated_at": "2021-11-15T05:31:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example, passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy List notification channels with their associated policies This example returns the ID, name, and type for every notification channel on the supplied account ID, as well as a list of every policy that is associated with that channel. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type associatedPolicies { policies { id name } totalCount } } nextCursor totalCount } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the channel because it might be used by other policies. On the other hand, deleting a channel will cause all associated policies to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 351.36288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> <em>tutorial</em>: Notification channels",
        "sections": "<em>NerdGraph</em> <em>tutorial</em>: Notification channels",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your alert notification channels using our <em>Graph</em>QL <em>NerdGraph</em> API. Here are some queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. Get notification channels"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Manage drop filter rules via NerdGraph API",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "41ef69e9d8d23b2ab732b489bb5e0cb47b8c16b6",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-12-04T22:05:01Z",
      "updated_at": "2021-11-14T07:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph, our GraphQL-format API explorer. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Manage drop filter rules via NerdGraph API If you want to manage your drop filter rules programmatically, you can use NerdGraph, our graphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your drop filter rules. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 298.414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Manage drop filter rules via <em>NerdGraph</em> API",
        "body": " partitions where this drop rule applies. Save the drop filter rule. Manage drop filter rules via <em>NerdGraph</em> API If you want to manage your drop filter rules programmatically, you can use <em>NerdGraph</em>, our <em>graph</em>QL-format API, at api.newrelic.com&#x2F;graphiql. For more information, see the <em>NerdGraph</em> <em>tutorial</em>"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/apis/nerdgraph/examples/use-nerdgraph-manage-license-keys-user-keys": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.18973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    }
  ],
  "/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "New Relic API keys",
        "API key UI",
        "Overview of keys",
        "Keys for data ingest",
        "Keys for querying and configuration",
        "License key",
        "View and manage license key",
        "User key",
        "Browser key",
        "Insights insert key",
        "Important",
        "REST API key",
        "Insights query key",
        "Admin key",
        "Account ID"
      ],
      "title": "New Relic API keys",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "b373cd68cf21daeb5d912ffb4b1ae3f14f500fcc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/",
      "published_at": "2021-12-04T21:34:15Z",
      "updated_at": "2021-11-24T02:46:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has several different APIs that use different API keys. This resource explains our keys, what they're used for, and how to access them. Ready to get started? Make sure you have a New Relic account. It's free, forever! API key UI Most of the keys can be viewed and managed via the API keys UI page: From the account dropdown, click API keys (get a direct link to the API keys page). If you're using NerdGraph, you can manage license keys and user keys from our GraphiQL explorer. Overview of keys If you're using a specific API, see the docs for that API to understand which keys are required and recommended. To learn about our APIs, see Introduction to APIs. Our keys can be broken down into two categories: Keys used for data ingest Keys used for querying and configuration Keys for data ingest There are many ways to get data into New Relic. Here are the API keys used for data ingest: License key: our primary ingest key, used for APM ingest, infrastructure monitoring ingest, and our ingest APIs and the integrations that use them. Browser key: used for browser monitoring ingest. Mobile app token: used for mobile monitoring ingest. Insights insert key: an older key that has been mostly deprecated, it has the same functionality as the license key. We recommend using the license key instead. Keys for querying and configuration Here are keys used for querying New Relic data or configuration of features: User key, also known as a \"personal API key\": used for NerdGraph (our GraphQL API) and for accessing REST API endpoints. REST API key: used for the REST API but we instead recommend using the user key because it has fewer restrictions. Insights query key: used with the Insights query API for querying New Relic data. We recommend using NerdGraph instead of this API. License key Our primary key used for data ingest is called the license key, also referenced in the UI and NerdGraph API as ingest - license. The license key is a 40-character hexadecimal string associated with a New Relic account. Each account in a New Relic organization has its own license key. When you first sign up for New Relic, that creates an organization with a single account, and that account has its own license key. If more accounts are added, each account will have its own license key. The types of data ingest the license key is used for include: APM agent data Infrastructure agent data Data sent via our core data ingest APIs (Metric API, Trace API, Event API, Log API), and the SDKs and integrations that use those APIs The license key is used for all data ingest except for browser monitoring data (which uses a browser key) and mobile monitoring data (which uses a mobile app token). Because the license key is used for data ingest, we recommend you treat your license key securely, like you would a password. This ensures no unwanted data is sent to your New Relic account. If your license key falls into the wrong hands, an attacker could send fake data to your account, which could trigger false alerts and contaminate your data so that detecting actual issues is more difficult. If you believe a license key has been exposed and has led to unwanted data, work with our Support team. View and manage license key To manage the license key: From the account dropdown, click API keys (get a direct link to the API keys page). You can't manage or delete the original license key that was created when an account was initially created. For that, contact New Relic support. You can also create additional license keys and manage them with our NerdGraph API. User key New Relic user keys, sometimes referred to as \"personal API keys\", are required for using NerdGraph and for the REST API. A user key is tied to both a specific New Relic user and a specific account, and they cannot be transferred. Our APIs that use this key let a user make queries for any accounts that user has been granted access to, not just the specific account the key was created under. If the key's user is deleted, all their user keys will be deactivated and will no longer be valid in API requests. To view and manage the user key and other API keys in the UI: From the account dropdown, click API keys (here's a direct link to the API keys page). To manage this key via API, see Manage keys with NerdGraph. You can also get or generate a user key from the NerdGraph GraphiQL explorer. Browser key One of the New Relic API keys that are used for data ingest is the browser key. The browser key allows the ingestion of data from New Relic browser monitoring. To view and manage this key: From the account dropdown, click API keys (here's a direct link to the API keys page). You can't manage or delete an original browser key that was created when your account was created. For that, contact New Relic support. Insights insert key Important This key is still in use but we highly recommend using the license key, which can be used for the same things and more. One of the New Relic API keys used for data ingest is the Insights insert key, also known as an \"insert key\"). Note that the license key is used for the same functionality and more, which is why we recommend the license key over this key. This key is used for the ingestion of data via our Event API, Log API, Metric API, and Trace API, or via tools that use those APIs. Tips on availability and access: Because these keys are associated with an account and not a specific user, anyone in the account with access to a key can use it. As a best practice for security purposes, we recommend you use different Insights insert keys for different applications or different data sources. To find and manage Insights insert keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click Insights insert keys. REST API key Important We highly recommend using a user key instead, because that key has fewer restrictions. The REST API key is for using our REST APIs for Alerts, APM, browser, infrastructure alerts, as well as mobile monitoring REST APIs and the API Explorer. Things to consider: We recommend using our newer NerdGraph API over the REST API, if possible. Requires admin-level user permissions. If you don't have access to the REST API key or the REST API explorer, it might be due to lack of permissions. Talk to your New Relic account manager, or use a user key instead. Each New Relic account can have only one REST API key. To find and manage REST API keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click REST API key. Before you configure or delete an API key, ensure you are doing so for the correct account. Insights query key The Insights query key is used for our Insights query API: we now recommend using NerdGraph for querying New Relic data. To find and manage Insights query keys: From the account dropdown, click API keys (get a direct link to the API keys page). Then click Insights query keys. Admin key Important As of December 4, 2020, all existing admin keys have been migrated to be user keys. You don’t need to do anything for existing admin keys to remain active. They will be automatically accessible via the API keys UI, labeled as user keys, and granted identical permissions. You can manage them as you would any user key via the same workflow. All migrated admin keys will have a note that says “Migrated from an admin user key” in the key table, so you’ll be able to find them easily. Account ID Looking for the account ID? See Account ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.33002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>API</em> keys",
        "sections": "New Relic <em>API</em> keys",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " UI page: From the account dropdown, click <em>API</em> keys (<em>get</em> a direct link to the <em>API</em> keys page). If you&#x27;re using <em>NerdGraph</em>, you can manage license keys and user keys from our GraphiQL explorer. Overview of keys If you&#x27;re using a specific <em>API</em>, see the docs for that <em>API</em> to understand which keys"
      },
      "id": "6043fa3464441f1358378f3b"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.15546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "sections": "<em>NerdGraph</em> tutorial: View and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our <em>NerdGraph</em> <em>API</em> to do some workloads-related tasks: <em>Get</em> the workloads of an account <em>Get</em> the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    }
  ],
  "/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.1426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Build queries with <em>NerdGraph</em>",
        "body": " devices with New Relic 45 min Build queries with <em>NerdGraph</em> Try <em>NerdGraph</em> and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.18973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> <em>API</em>",
        "tags": "<em>APIs</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format <em>API</em> that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several <em>APIs</em>. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "Configure Service Levels via the NerdGraph API",
        "BETA FEATURE",
        "Important",
        "Create an SLI with an SLO",
        "Retrieve the configuration of an SLI for an APM service",
        "Update the SLOs of an SLI"
      ],
      "title": "Configure Service Levels via the NerdGraph API",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Service Level Management",
        "SLI/SLO",
        "Configure",
        "Consume",
        "NerdGraph"
      ],
      "external_id": "bbc11b33aca5f3cd12d3c6217d44ad9d5f7b5daa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-slm/",
      "published_at": "2021-12-04T21:03:00Z",
      "updated_at": "2021-12-04T09:46:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With New Relic you can implement Service Levels for your applications, consume the results easily from the UI during your planning sessions and incident response, and progressively iterate on the configuration to adjust your objectives to the desired user experience. Besides the UI, you can also use our NerdGraph API Explorer to create and edit of SLIs and their SLOs. Alternatively, you can automate this configuration using the Terraform Service Level resource. Important In order to create Service Levels, the API key needs a role with permissions to modify and delete metric rules. Create an SLI with an SLO Please refer to Create and edit SLIs and SLOs to learn the basic concepts in the SLI and SLO configuration, such as the entity that an SLI is associated with. Also, you can refer to that documentation to find examples of the most common indicators for APM services and browser applications. The following is an example NerdGraph call that creates an SLI using the serviceLevelCreate mutation query: mutation { serviceLevelCreate( entityGuid: \"entityGuid\", indicator: { name: \"Latency below 0.25 seconds\", description: \"The proportion of valid requests that were served faster than 0.25s, which is considered to correspond to a good experience.\", events: { validEvents: { from: \"Transaction\", where: \"entityGuid = 'entityGuid'\" }, goodEvents: { from: \"Transaction\", where: \"entityGuid = 'entityGuid' and duration < 0.25\" }, accountId: accountId}, objectives: { target: 99.5, timeWindow: { rolling: { count: 7, unit: DAY }}}}) { id description } } Copy It contains these fields: entityGuid: The GUID of the entity (for example, APM service, browser application, etc.) that you want to relate this SLI to. On the UI, you can find this GUID on the entity page, under See metadata and manage tags. description: Use detailed descriptions, including the selected threshold that determines good events. For example, for an availability SLI, include something like “The proportion of valid requests that were served without errors.” Or, for a latency SLI, include a description such as “The proportion of valid requests that were served faster than 0.25s, which is considered to correspond to a good experience”. accountId: The ID of the account where the APM service or browser application belongs to, which contains the NRDB data for the SLI/SLO calculations. badEvents.from, badEvents.where The NRQL query that defines bad events, SELECT count(*) FROM badEvents.from WHERE badEvents.where, requires these FROM and WHERE clauses. If you defined an SLI from valid and bad events, leave the goodEvents object empty. goodEvents.from, goodEvents.where The NRQL query that defines good events, SELECT count(*) FROM goodEvents.from WHERE goodEvents.where, requires these FROM and WHERE clauses. If you defined an SLI from valid and good events, leave the badEvents object empty. validEvents.from, validEvents.where These are the FROM and WHERE clauses for the NRQL query that defines valid events, which will result in SELECT count(*) FROM validEvents.from WHERE validEvents.where. name: A short category name for your SLI to help understand what the Service Level is about. We suggest including any specific parameters and filters involved in the SLI definition. Examples: Availability Latency below 4 seconds CLS for desktops below 0.1 objectives: An array of objectives (SLOs) for the SLI. target: The target for your SLO, up to 100.00. The field supports up to 5 decimals. If your users are happy with the current experience, set the SLO percentage to match the current baseline. For instance, the percentile used to determine the SLI's good events. timeWindow.rolling.count: The length of the period taken into consideration to calculate the SLO. The supported values are 1, 7, 14, 28, and 30. timeWindow.rolling.unit: DAYis the supported value. Retrieve the configuration of an SLI for an APM service Use this query to retrieve the configuration of an SLI, including its id. { actor { entity(guid: \"entityGuid\") { guid name serviceLevel { indicators { createdAt createdBy { email } description entityGuid id name objectives { target timeWindow { rolling { count unit } } } } } } } } Copy Update the SLOs of an SLI Use the serviceLevelUpdate mutation to define one or more SLOs for each one of the SLIs. To obtain the SLI's id, use the query above. mutation { serviceLevelUpdate( id: \"indicators.id\", indicator: { objectives: { target: 99.00, timeWindow: { rolling: { count: 7, unit: DAY }}}}) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.53265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure Service Levels via the <em>NerdGraph</em> <em>API</em>",
        "sections": "Configure Service Levels via the <em>NerdGraph</em> <em>API</em>",
        "tags": "<em>NerdGraph</em>",
        "body": " user experience. Besides the UI, you can also use our <em>NerdGraph</em> <em>API</em> Explorer to create and edit of SLIs and their SLOs. Alternatively, you can automate this configuration using the Terraform Service Level resource. Important In order to create Service Levels, the <em>API</em> key needs a role"
      },
      "id": "61ab38e028ccbcf9dbc25413"
    }
  ],
  "/docs/apis/nerdgraph/tutorials/provisions-your-subscriptions-nerdgraph": [
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-06T01:39:39Z",
      "updated_at": "2021-12-04T15:31:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 487.64902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> API",
        "sections": "Introduction to New Relic <em>NerdGraph</em>, our <em>GraphQL</em> API",
        "tags": "<em>NerdGraph</em>",
        "body": "<em>NerdGraph</em> is our <em>Graph</em>QL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with <em>NerdGraph</em>. What is <em>NerdGraph</em>? New Relic has several APIs. <em>NerdGraph</em>"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "NerdGraph tutorial: View entity data",
        "Important",
        "Entity definition",
        "Requirements",
        "Search for entities",
        "Search by attribute",
        "Search by entity GUID",
        "Example queries",
        "Get entity data using the queryBuilder",
        "Get data for infrastructure integration entities in search results",
        "Get alert information on alertable entities in search results",
        "Get summary data on APM entities in search results",
        "Get data specific to each entity type in search results",
        "Get all tags for each entity in search results",
        "Get the nextCursor for paginated search results",
        "Delete entities"
      ],
      "title": "NerdGraph tutorial: View entity data",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "82cba56e3512473f842550da49290068828ede3f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-entities-api-tutorial/",
      "published_at": "2021-12-04T17:05:05Z",
      "updated_at": "2021-11-14T10:30:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With NerdGraph, you can query details about your monitored entities. Important To work with an entity's golden metrics and tags, see the golden metrics API tutorial. Entity definition Entities are an important New Relic concept. Basically, an entity is anything we monitor, including but not limited to: Applications monitored by APM. Cloud integrations, services, and hosts monitored by our infrastructure monitoring. Learn more about how we define \"entity.\" To view entity details in the UI, you can use the Explorer. When working with entities in NerdGraph, it can help to understand some important traits they have: A unique entity GUID identifies an entity. An entity exists over a span of time, even if it's a short period. An entity provides a useful entry point for exploring data about specific metrics and events, or for contextualizing data related to other entities. Requirements You need a user key. Search for entities New Relic searches for entities by their attributes, primarily their name, but also by type of entity and other values. The search returns basic data about entities matching the search criteria. Then, from the basic query results, you can query a specific entity by its GUID. You can craft a query in one of two ways: Use the queryBuilder argument to help you craft a query. OR Use the freeform query argument to provide your own search. To use NerdGraph to query one or more entities, you can search by attribute or GUID. In addition to these examples, we highly recommend exploring the API using the NerdGraph GraphiQL explorer and searching its inline documentation. Search by attribute Go to the NerdGraph GraphiQL explorer. Run a basic query to find entities that match your search criteria. For example: query($query: String! ) { actor { entitySearch(query: $query) { count results { entities { name entityType guid } } } } } Copy Add the following variables to the Query variables section in NerdGraph: {\"query\": \"name LIKE 'nerd-graph' AND type IN ('APPLICATION')\"} Copy Search by entity GUID Use a specific entity's GUID to query deeper into its related data. For example: query($guids: EntityGuid! ) { actor { entities(guids: $guids) { entityType name } } } Copy Add the following variables to the Query variables section: {\"guids\": \"entity-guid-here\"} Copy Example queries Queries are requests that are intended to only fetch data (no side effects). NerdGraph queries are not static, meaning that you can ask for more or less data depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Entities in NerdGraph rely on GraphQL interfaces, a concept that allows objects to share common fields. Interfaces are used to provide data for specific entity types, as you will see in many of these NerdGraph query examples. Get entity data using the queryBuilder If you aren't sure how to start crafting an entity search query, you can rely on NerdGraph to help you build one, and then retrieve entity data and the query string that was built. Request the query field in your results to see the query string built by the queryBuilder argument. You cannot use the query and queryBuilder arguments at the same time. We highly recommend exploring the API using the NerdGraph GraphiQL explorer and searching its inline documentation to see the query options available to you. { actor { entitySearch( queryBuilder : {type: APPLICATION}) { query results { entities { reporting ... on AlertableEntityOutline { alertSeverity } } } } } } Copy Get data for infrastructure integration entities in search results There are many different types of Infrastructure integration entities and they are listed separately from other entity types. Use the infrastructureIntegrationType input argument to explore them. You cannot use the query and queryBuilder arguments at the same time. Use infrastructureIntegrationType in place of the type input argument. We highly recommend exploring the API using the NerdGraph GraphiQL explorer and searching its inline documentation to see the query options available to you. { actor { entitySearch(queryBuilder: { infrastructureIntegrationType : F5_NODE}) { query results { entities { entityType domain } } } } } Copy Get alert information on alertable entities in search results Fetch the alert severity of any entity that can be monitored by New Relic's Alerts. This NerdGraph query will tell you if we are currently receiving data from your application (using the reporting field). If the entity is an alertable type, results will include the alert severity of the entity. If the results include entities that are not alertable, they will not include the AlertableEntityOutline fields. { actor { entitySearch(query: \"name like 'nerdgraph'\") { results { entities { reporting ... on AlertableEntityOutline { alertSeverity } } } } } } Copy Get summary data on APM entities in search results Different entity types have specific data associated with them. The following NerdGraph query example shows a selection of fields available for APM application entities: More summary data can be requested in your query. If entities of other types are returned in your search results, they will not include these fields. { actor { entitySearch(query: \"name like 'nerdgraph'\") { results { entities { name ... on ApmApplicationEntityOutline { apmSummary { errorRate apdexScore webResponseTimeAverage responseTimeAverage } } } } } } } Copy Get data specific to each entity type in search results Different entity types have specific data associated with them. This NerdGraph query example requests the name for all entities regardless of which entity type they are, as well as the error rate for APM, browser monitoring, and mobile entities. If entities of other types are returned in your search results, they will not include an error rate field. { actor { entitySearch(query: \"name like 'nerdgraph'\") { results { entities { name ... on ApmApplicationEntityOutline { apmSummary { errorRate } } ... on BrowserApplicationEntityOutline { browserSummary { jsErrorRate } } ... on MobileApplicationEntityOutline { mobileSummary { httpErrorRate } } } } } } } Copy Get all tags for each entity in search results This NerdGraph query example fetches tags for every entity returned in the search results. For more information, see the NerdGraph GraphiQL tagging tutorial. { actor { entitySearch(query: \"name like 'nerdgraph'\") { results { entities { name tags { key values } } } } } } Copy Get the nextCursor for paginated search results The NerdGraph GraphiQL explorer paginates results from an entity search. If your search criteria yields more than the API limit and you want to view the rest of the results, you can request nextCursor in your initial request and use its value in another query to retrieve the following \"page\" of results. If there are no more results, nextCursor will be null. { actor { entitySearch(query: \"name like 'nerd-graph'\") { results { nextCursor entities { name } } } } } Copy Use the value of nextCursor in your next search: { actor { entitySearch(query: \"name like 'nerd-graph'\") { results(cursor: \"next_cursor_value\") { nextCursor entities { name } } } } } Copy Delete entities You can manually delete any entity in your account by using the NerdGraph API. To do so, run this query with the entity's GUID in the NerdGraph GraphiQL explorer: mutation { entityDelete(guids: [\"EntityGuid\"]) { deletedEntities failures } } Copy Important Currently, you can only remove the following entity types using the Nerdgraph API: APM-APPLICATION, EXT-SERVICE, and REF-REPOSITORY. You may see a deleted entity in your UI if a New Relic agent reindexes it again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.0795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> <em>tutorial</em>: View entity data",
        "sections": "<em>NerdGraph</em> <em>tutorial</em>: View entity data",
        "tags": "<em>NerdGraph</em>",
        "body": "With <em>NerdGraph</em>, you can query details about your monitored entities. Important To work with an entity&#x27;s golden metrics and tags, see the golden metrics API <em>tutorial</em>. Entity definition Entities are an important New Relic concept. Basically, an entity is anything we monitor, including but not limited"
      },
      "id": "6044058c64441f2d4f378ed9"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Manage drop filter rules via NerdGraph API",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "41ef69e9d8d23b2ab732b489bb5e0cb47b8c16b6",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-12-04T22:05:01Z",
      "updated_at": "2021-11-14T07:15:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph, our GraphQL-format API explorer. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Insights > NRQL Drop Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Manage drop filter rules via NerdGraph API If you want to manage your drop filter rules programmatically, you can use NerdGraph, our graphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your drop filter rules. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.98376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Manage drop filter rules via <em>NerdGraph</em> API",
        "tags": "UI <em>and</em> data",
        "body": " partitions where this drop rule applies. Save the drop filter rule. Manage drop filter rules via <em>NerdGraph</em> API If you want to manage your drop filter rules programmatically, you can use <em>NerdGraph</em>, our <em>graph</em>QL-format API, at api.newrelic.com&#x2F;graphiql. For more information, see the <em>NerdGraph</em> <em>tutorial</em>"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/apis/rest-api-v1-deprecated/new-relic-rest-api-v1/working-new-relic-rest-api-v1-deprecated": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Create custom events",
        "Collect data - any source",
        "Monitor your network devices with New Relic",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-12-08T01:39:00Z",
      "title": "Collect data",
      "updated_at": "2021-12-08T01:39:00Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes Use custom attributes for deeper analysis Create custom events Define, visualize, and get alerts on the data you want using custom events 5 min Collect data - any source APIs, agents, OS emitters - get any data 15 min Monitor your network devices with New Relic Monitor your network devices with New Relic 45 min Build queries with NerdGraph Try NerdGraph and build the queries you need 25 min Query data with NRQL Query default data, custom events, and attributes 10 min",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.66082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Monitor your network devices with <em>New</em> <em>Relic</em>",
        "body": "Through our opensource agents or <em>APIs</em>, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "ebc829a1c1b74c866f5326f90a6d5119fdcfae10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T22:00:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata For PHP, logs in context is only supported from the distributed tracing UI, not in the Logs tab of the APM UI. Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension PHP: Monolog extension Python: Streamhandler example Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 66.525085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent <em>APIs</em> with logs in context",
        "sections": "Use APM agent <em>APIs</em> with logs in context",
        "tags": "Enable log management in <em>New</em> <em>Relic</em>",
        "body": " your logs. APM agent trace metadata and linking metadata <em>APIs</em> To get properly annotated logs for logs in context, use the following <em>API</em> calls for your APM agent. These <em>APIs</em> pass the required trace metadata and linking metadata to link your log data to other <em>New</em> <em>Relic</em> data. APM agent <em>APIs</em>: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "NerdGraph tutorial: View and manage workloads",
        "Important",
        "Get the workloads of an account",
        "Get the list of entities in a workload",
        "Get the status of a workload",
        "Create a workload",
        "Modify a workload",
        "Set a static status for a workload",
        "Modify the automatic status rules for a workload",
        "Duplicate a workload",
        "Delete a workload"
      ],
      "title": "NerdGraph tutorial: View and manage workloads",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "ffa158d197dbb207d50d48b813198842752d4b62",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/tutorials/nerdgraph-workloads-api-tutorials/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T15:32:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph API to do some workloads-related tasks: Get the workloads of an account Get the list of entities in a workload Get the status of a workload Create a workload Modify a workload Set a static status for a workload Modify the automatic status rules for a workload Duplicate a workload Delete a workload See also our post on how to customize the charts you see in your workload. Important You can also use the CLI and Terraform resource to automate these tasks. Get the workloads of an account To get all workloads of an account, use the following GraphQL query and pass the account ID via the id field. In this example, we retrieve three basic fields: guid: the workload GUID. name: the workload name. permalink: the permanent URLs on the New Relic One UI. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collections { guid name permalink } } } } } Copy The response includes this type of data for each workload: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collections\": [ ..., { \"guid\": \"MTY...NTY\", \"name\": \"Acme Telco - Fulfillment Chain\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTY...NTY\" }, ... ] } } } }, \"extensions\": { ... } } Copy Get the list of entities in a workload You can get the entities that belong to a workload with the following query, just by passing the workload GUID (guid) as an argument. In this example we also retrieve some workload metadata: accountId: the workload account. name: the workload name. permalink: the workload permanent URL on the New Relic One UI. alertSeverity: the status of the workload. This value can have up to 10 minutes of delay; if you want to force the calculation of the workload status in query time, please use the Get the status of a workload example. The nested collection, members and results objects, which contain the actual list of entities: The name argument in the collection object takes the value WORKLOAD. count: Number of entities in the workload. { actor { entity(guid: \"YOUR_WORKLOAD_GUID\") { accountId name permalink ... on AlertableEntity { alertSeverity } ... on CollectionEntity { collection(name: \"WORKLOAD\") { members { count results { entities { accountId entityType name guid ... on AlertableEntityOutline { alertSeverity } } } } } } } } } Copy The query returns a list of entities that looks like this: { \"data\": { \"actor\": { \"entity\": { \"accountId\": 1606862, \"name\": \"Acme Telco - Ecommerce\", \"permalink\": \"https://one.newrelic.com/redirect/entity/MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"alertSeverity\": \"CRITICAL\", \"collection\": { \"members\": { \"count\": 201, \"results\": { \"entities\": [ { \"accountId\": 1606862, \"alertSeverity\": \"CRITICAL\", \"entityType\": \"APM_APPLICATION_ENTITY\", \"guid\": \"MTYwNjg2MnxBUE18QVBQTElDQVRJT058NDMxOTIwNTg\", \"name\": \"Fulfillment Service\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_HOST_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw3MDQzMzA2NzIyMjk2NDg4Mzc\", \"name\": \"ip-172-31-16-222\" }, { \"accountId\": 1606862, \"alertSeverity\": \"NOT_ALERTING\", \"entityType\": \"INFRASTRUCTURE_AWS_LAMBDA_FUNCTION_ENTITY\", \"guid\": \"MTYwNjg2MnxJTkZSQXxOQXw1MjMyNzM2ODgzNjAwNjYyMjE1\", \"name\": \"TelcoDT-purchase-log-lambda\" }, ... ] } } } } } } } Copy Get the status of a workload If you want to force the calculation of the status of a workload, you can use the following query, passing the account id (id) as the argument for the account field, and the workload GUID (guid) as the argument for the collection field. { actor { account(id: YOUR_ACCOUNT_ID) { workload { collection(guid: \"YOUR_WORKLOAD_GUID\") { guid status { value } } } } } } Copy And this is what you'll get in the response: { \"data\": { \"actor\": { \"account\": { \"workload\": { \"collection\": { \"guid\": \"MTYwNjg2MnxOUjF8V09SS0xPQUR8MTIyMzQ\", \"status\": { \"value\": \"OPERATIONAL\" } } } } } } } Copy Note that the DISRUPTED status value is a synonym for CRITICAL status. Create a workload The following is an example NerdGraph call that creates a workload using the workloadCreate mutation query: mutation { workloadCreate( accountId: NEW_WORKLOAD_ACCOUNT_ID, workload: { name: \"NAME_OF_WORKLOAD\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(type = 'SERVICE') and tags.label.environment = 'production'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Some details on parts of this query: account: The workload account ID. Workloads can't be moved between accounts, so it's not possible to change this value later. name: A string with a user-friendly name for the workload. scopeAccounts: Scope accounts are the accounts where the entity data is fetched from. Scope accounts must belong to a group under the same parent account or enterprise partnership as the workload account. To define the entities in the workload, you can use one or both of these options: entitySearchQueries: This allows you to dynamically generate an array of entities. A name for each query is not needed. Here's an example dynamic query: (domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'production' Copy entityGuids: This is for choosing specific entity GUIDs for inclusion in the workload. guid: This returns the workload guid. Because NerdGraph provides schema stitching, you can get other details about the workload, like the permalink. Modify a workload To modify a workload, use the workloadUpdate mutation. You must know the workload's guid. The workload account can't be changed. For the fields you can modify, see Create workloads. These additional rules apply: entitySearchQueries: This field must contain all the queries as you expect them to be stored. If you want to add a new query, include it in the query field and don't provide any query id. If you want to modify an existing query, include it in the query field and provide its existing id. If you want to delete an existing query, just don't add any query with that id anymore. Here's an example of the workloadUpdate query: mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { name: \"A new name for the workload\", entityGuids: [\"ENTITY_GUID_1\", \"ENTITY_GUID_2\", ...], entitySearchQueries: [ { query: \"(domain = 'INFRA' and type = 'HOST') and tags.label.environment = 'staging'\" }, { id: AN_EXISTING_QUERY_ID, query: \"(type = 'SERVICE') and tags.label.environment = 'staging'\" }, ... ], scopeAccounts: { accountIds: [NEW_RELIC_ACCOUNT_ID_1, NEW_RELIC_ACCOUNT_ID_2, ...] } } ) { guid } } Copy Set a static status for a workload You can set up a static status for a workload, which overrides any automatic status calculation. To set a static status, you must know the workload's guid and use the following fields: enabled: Remember to set this field to true to propagate the status value. status: The status value you want to set for this workload. Supported values are OPERATIONAL, DEGRADED or DISRUPTED. description: A text field to provide additional details. mutation { workloadUpdate( guid: \"YOUR_WORKLOAD_GUID\", workload: { statusConfig: { static: { enabled: true, status: DEGRADED, description: \"Game day. Expect some turbulence today between 8 and 9am PST.\" } } } ) { guid updatedAt status { value } } } Copy Modify the automatic status rules for a workload When you create a workload, you can use the statusConfig object to define which automatic rules you want to use to calculate the status of the workload. If you leave the rules array empty, no rules will be set up for your workload. However, if you just don't use the statusConfig object when you create a workload, the following rules will be added by default: \"statusConfig\": { \"automatic\": { \"enabled\": true, \"rules\": [ { \"entitySearchQueries\": [{\"query\": \"(domain = 'APM' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'MOBILE' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'BROWSER' and type = 'APPLICATION')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } }, { \"entitySearchQueries\": [{\"query\": \"(domain = 'SYNTH' and type = 'MONITOR')\"}], \"rollup\": { \"strategy\": \"WORST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } ], \"remainingEntitiesRule\": { \"rollup\": { \"groupBy\": \"ENTITY_TYPE\", \"strategy\": \"BEST_STATUS_WINS\", \"thresholdType\": null, \"thresholdValue\": null } } } } Copy This is how you read the configuration: enabled: The automatic status calculation is enabled when this field is set to true. rules: An array of rules. In the default configuration, four rules are set for those entity types that are closer to the digital experience (that is, synthetic monitors, browser applications, mobile applications, and services). For each of these groups, the status of the unhealthiest rolls up. remainingEntitiesRule: This is the rule that will apply to all entities that haven't been evaluated in any other rule. In the default configuration, the remaining entities are grouped by entity type, and we make the status of each group to match that of its healthiest entity. If you want to modify these rules, you must use the workloadUpdate mutation, and send the complete new statusConfig object that you want to use. You can disable the automatic status calculation while keeping the configuration, by setting the statucConfig.automatic.enabled to false. Alternatively, you can delete all automatic regular rules by sending an empty array. And you can delete the rule for the remaining entities by just not adding the remainingEntitiesRule object. Duplicate a workload To duplicate a workload you first need to know its guid. In the workloadDuplicate mutation, you must pass as parameters: accountId: The account where you want to create the new workload. sourceGuid: the guid of the workload you want to duplicate. workload.name: Optional. You can specify a name for the new workload. If you don't specify one, the new workload will get the name of the original workload appended with - Copy. After duplicating a workload, you can modify it. mutation { workloadDuplicate( accountId: NEW_WORKLOAD_ACCOUNT_ID, sourceGuid: \"ORIGINAL_WORKLOAD_GUID\", workload: { name: \"New workload\" } ) { guid } } Copy Delete a workload To delete a workload, use the workloadDelete mutation and specify the workload GUID. When you delete a workload, all history and metadata is also deleted.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.78681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: <em>View</em> and manage workloads",
        "sections": "NerdGraph tutorial: <em>View</em> and manage workloads",
        "tags": "<em>APIs</em>",
        "body": "<em>New</em> <em>Relic</em> allows you to group entities together in groupings called workloads. This enables better monitoring of the full stack used by a team or project. Here we show you how to use our NerdGraph <em>API</em> to do some workloads-related tasks: Get the workloads of an account Get the list of entities"
      },
      "id": "603e9eb7e7b9d22a5f2f37b1"
    }
  ],
  "/docs/apis/rest-api-v2/account-examples-v2/listing-users-your-account": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic partnership <em>account</em> authentication",
        "sections": "New Relic partnership <em>account</em> authentication",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " <em>API</em> key, partner ID, and your <em>account</em> ID: X-<em>Api</em>-Key:YOUR_PARTNER_<em>ACCOUNT_API</em>_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-<em>Account</em>-Id:YOUR_CUSTOMERS_<em>ACCOUNT</em>_ID Providing authentication to the <em>REST</em> <em>API</em> (<em>v2</em>) in this form allows you to complete any <em>API</em> operation on your customer’s accounts"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.17778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Mobile crash count and crash rate example (v2)",
        "Tip",
        "Prerequisites",
        "Mobile app: Get crash data",
        "Mobile app version: Get crash count data",
        "Mobile app version: Get crash rate data",
        "Find the mobile app version ID",
        "Important"
      ],
      "title": "Mobile crash count and crash rate example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Mobile examples (v2)"
      ],
      "external_id": "151eef499250bd2a444ed8c49b610772d7c7e56e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/mobile-examples-v2/mobile-crash-count-crash-rate-example-v2/",
      "published_at": "2021-12-04T15:39:40Z",
      "updated_at": "2021-07-09T14:37:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes how to use the New Relic REST API (v2) to get your mobile application's overall and version-specific crash count and crash rate, which appear on the Summary page in the upper right corner. These examples use the default time period of the last 30 minutes. To obtain crash data for a different time range, add the time period to the commands. Tip You can also use the New Relic API Explorer to retrieve mobile metric data. Prerequisites To use the API in these examples, you need: Your New Relic REST API key Your New Relic mobile monitoring app ID or your mobile monitoring app version ID. To find the mobile monitoring app ID, see Finding the product ID: mobile monitoring. To find the mobile monitoring app version ID, see Find the mobile app version ID below. Mobile app: Get crash data To obtain crash count and crash rate data for the overall mobile application, use the mobile application ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_ID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy The crash_summary output data contains both the crash_count and crash_rate. \"crash_summary\": { \"supports_crash_data\": true, \"unresolved_crash_count\": 14, \"crash_rate\": 28.155339805825243 } Copy To obtain crash summary data for all the mobile applications in the account, use this REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy Mobile app version: Get crash count data To obtain the crash count metric data for a specific version of the mobile application, include the mobile application version ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'name=Mobile/Crash/All&values[]=call_count&summarize=true' Copy Mobile app version: Get crash rate data To calculate a specific version's crash rate, use the following equation: Crash Rate = (Mobile/Crash/All:call_count) / (Session/Start:call_count) Copy To get the two metric values needed in the equation, use the following REST API command with the mobile application version ID . curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=Mobile/Crash/All&names[]=Session/Start&values[]=call_count&summarize=true' Copy Find the mobile app version ID Important You must provide the version ID only when you want to obtain crash data for a specific version. To find the version ID of your mobile application, run the following NRQL query: SELECT count(*) from Mobile where appName='YOUR_APP_NAME' facet appVersionId since 1 day ago export const _frontmatter = {\"title\":\"Mobile crash count and crash rate example (v2)\",\"tags\":[\"APIs\",\"REST API v2\",\"Mobile examples (v2)\"],\"metaDescription\":\"How to use New Relic's REST API (v2) to get crash count and crash rate data for the overall mobile app or a specific version.\",\"redirects\":[\"/docs/apis/rest-api-v2/application-examples-v2/mobile-crash-count-crash-rate-example-v2\"]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile crash count <em>and</em> crash rate example (<em>v2</em>)",
        "sections": "Mobile crash count <em>and</em> crash rate example (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ", &quot;unresolved_crash_count&quot;: 14, &quot;crash_rate&quot;: 28.155339805825243 } Copy To obtain crash summary data for all the mobile applications in the <em>account</em>, use this <em>REST</em> <em>API</em> command: curl -X GET &quot;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;mobile_applications.json&quot; \\ -H &quot;X-<em>Api</em>-Key:${<em>API</em>_KEY}&quot; -i Copy Mobile app version: Get crash"
      },
      "id": "60440c9628ccbc04a23021ec"
    }
  ],
  "/docs/apis/rest-api-v2/api-explorer-v2/introduction-new-relics-rest-api-explorer": [
    {
      "sections": [
        "Retrieve metric timeslice data for your app (Explorer)",
        "View your app's ID",
        "View metric names for your app",
        "Get metric timeslice data for your app",
        "View other REST API data"
      ],
      "title": "Retrieve metric timeslice data for your app (Explorer)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "3553a434fa75f931ca76da34d5696329801070d9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/retrieve-metric-timeslice-data-your-app-explorer/",
      "published_at": "2021-12-04T15:34:57Z",
      "updated_at": "2021-10-31T03:54:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using New Relic's REST API Explorer (v2) to get metric timeslice data for your application, you need: An API key The app's ID The type of metric timeslice data available for your app, including the metric names and values View your app's ID To view your app's ID: From the New Relic REST API Explorer, select Applications > GET List. If you are not signed in to New Relic, provide an API key for your app. Optional: From Applications > List, fill in values for the name, ids, or language filters. Select Send Request. From the Response section, copy the app's id. Continue with the procedure to view metric names. View metric names for your app To view the metric timeslice data available for your app: From the New Relic REST API Explorer, select Applications > GET Metric Names. From Applications > Metric Names, type or paste your application ID. Fill in a specific or partial metric name, or leave blank to view the list of available metric names and values. Select Send Request. From the Response section, review the app's available metrics. Continue with the procedure to get metric timeslice data. Get metric timeslice data for your app To get the metric values for your app, copy the values from the Metric Names results, and paste them in the Metric Timeslice Data fields: From the New Relic REST API Explorer, select Applications > GET Metric Data. From Applications > Metric Data, type or paste your application ID. Type or paste one or more names (from GET Metric Names) for your app. Start each name on a new line. Select Send Request. From the Response section, review the app's available metric_data. After reviewing the Response section, you can continue making adjustments, and select Send Request again. For example: To specify a time range for the metric timeslice data, fill the from and to values, or use the diamond . To create an average of the data over the time range, set summarize to true. Or, to keep the data for each time period for the range you have specified, leave summarize blank. View other REST API data To use the API Explorer with other New Relic capabilities, select the corresponding API key. This may include: Synthetic monitoring Partners",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.28741,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Retrieve metric timeslice data for your app (<em>Explorer</em>)",
        "sections": "<em>View</em> other <em>REST</em> <em>API</em> data",
        "tags": "<em>API</em> <em>Explorer</em> <em>v2</em>",
        "body": "When using New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em> (<em>v2</em>) to get metric timeslice data for your application, you need: An <em>API</em> key The app&#x27;s ID The type of metric timeslice data available for your app, including the metric names and values View your app&#x27;s ID To view your app&#x27;s ID: From the New Relic <em>REST</em> <em>API</em>"
      },
      "id": "6043ffe628ccbcbb0b2c60a9"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.89545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time examples (<em>v2</em>)",
        "sections": "Average response time examples (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "Here is an example of how to use the New Relic <em>API</em> <em>Explorer</em> (<em>v2</em>) to get your application&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    },
    {
      "sections": [
        "Get host memory used for an application",
        "Get memory usage for a host",
        "Get memory usage for the entire app"
      ],
      "title": "Get host memory used for an application",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "cbc8fbdc5012ba202ff02eea52a6b62e91f30596",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-host-memory-used-application/",
      "published_at": "2021-12-04T15:36:18Z",
      "updated_at": "2021-03-13T04:02:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average memory usage for your application on a single host. This value appears on the APM Summary page in the Hosts table, in the column labeled Memory, or in the corresponding chart. Get memory usage for a host To obtain the average Memory usage for one of your app's hosts, use the following command to obtain the metric names[]=Memory/Physical with values[]=percent. curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/hosts/$HOST_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Memory/Physical&values[]=used_mb_by_host&summarize=true' Copy Replace $APP_ID and $API_KEY with your app ID and your API key. Replace $HOST_ID with the host id of your target host. This example shows the time range for the default time period (last 30 minutes). For additional detail: Remove the summarize=true to obtain detailed time series data. Specify a different time range. To obtain the same information from the New Relic API Explorer (v2): Select Application Hosts > GET Metric Data, and include your API key. Add your application ID, host id, and the names[]=Memory/Physical and values[]=used_mb_by_host metrics in the appropriate fields. Get memory usage for the entire app To obtain the average Memory usage for your application, use a command similar to the one in the previous example, but remove the reference to hosts and $HOST_ID. Replace $APP_ID and $API_KEY with your app ID and your API key. curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Memory/Physical&values[]=total_used_mb&summarize=true' Copy For additional detail: Remove the summarize=true to obtain detailed time series data. Specify a different time range. To obtain the same information from the New Relic API Explorer (v2): Select Applications > GET Metric Data, and include your API key. Add your application ID and the names[]=Memory/Physical and values[]=total_used_mb metrics in the appropriate fields.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.75493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average memory usage for your application on a single host. This value appears on the APM Summary page in the Hosts table, in the column labeled Memory, or in the corresponding chart. Get memory usage for a host To obtain the average Memory"
      },
      "id": "604405fe28ccbc10d72c60bc"
    }
  ],
  "/docs/apis/rest-api-v2/api-explorer-v2/retrieve-metric-timeslice-data-your-app-explorer": [
    {
      "sections": [
        "Introduction to New Relic's REST API Explorer",
        "Features",
        "Differences from API version 1",
        "Tip"
      ],
      "title": "Introduction to New Relic's REST API Explorer",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "457d31007ab690d5e6f3679e150814c280b49441",
      "image": "https://docs.newrelic.com/static/c506cb08149178347d12b6cbb236c855/23592/API_explorer_main_page.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/introduction-new-relics-rest-api-explorer/",
      "published_at": "2021-12-04T21:03:41Z",
      "updated_at": "2021-10-31T03:53:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers several APIs, including the New Relic REST API. This document introduces you to the REST API Explorer, which allows admin users and those with the API Key to: Browse the available REST API endpoints. Interact with the REST API within a user interface (the API Explorer). View a live source of documentation. Obtain curl commands for API actions. Share configured API calls with colleagues by copy and pasting API Explorer's URLs. This helps you to quickly search for solutions and test your API calls before adding them to your own software components. Features New Relic's API Explorer includes an interactive user interface for your selected account. The API Explorer UI lists the types of API calls (Applications, Users, etc.) and their available functions, such as GET metric data, PUT (update) applications, DELETE applications, etc. As you type values for Parameters, they automatically appear in the Request so that you can test and verify your syntax before sending the request. The UI indicates required fields, field descriptions, their type (integer, float, Boolean, etc.), and their location (path, query, etc.). For information on API key requirements, see REST API keys. rpm.newrelic.com/api/explore: The New Relic API Explorer makes it easy to test and send requests for any API endpoint. After you select your account and your choice of functions for the type of API call (applications, browsers, users, etc.), the UI provides an interactive form to view requirements and test your parameter values. Differences from API version 1 This API Explorer applies only to the New Relic REST API version 2, which focuses on data in and data out of New Relic. Version 2 replaces New Relic's deprecated REST API version 1. Be aware there are some differences between version 2 and 1: Names for data may be different. Some cURL commands for v2 are different than v1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.94153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em>",
        "sections": "Introduction to New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em>",
        "tags": "<em>API</em> <em>Explorer</em> <em>v2</em>",
        "body": " and 1: Names for data may be different. Some cURL commands for <em>v2</em> are different than <em>v</em>1. Tip The New Relic agents use different <em>APIs</em> and are not accessible via the <em>API</em> <em>Explorer</em>."
      },
      "id": "6043ff97196a67c2f2960f65"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.89545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time examples (<em>v2</em>)",
        "sections": "Average response time examples (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "Here is an example of how to use the New Relic <em>API</em> <em>Explorer</em> (<em>v2</em>) to get your application&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    },
    {
      "sections": [
        "Get host memory used for an application",
        "Get memory usage for a host",
        "Get memory usage for the entire app"
      ],
      "title": "Get host memory used for an application",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "cbc8fbdc5012ba202ff02eea52a6b62e91f30596",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-host-memory-used-application/",
      "published_at": "2021-12-04T15:36:18Z",
      "updated_at": "2021-03-13T04:02:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average memory usage for your application on a single host. This value appears on the APM Summary page in the Hosts table, in the column labeled Memory, or in the corresponding chart. Get memory usage for a host To obtain the average Memory usage for one of your app's hosts, use the following command to obtain the metric names[]=Memory/Physical with values[]=percent. curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/hosts/$HOST_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Memory/Physical&values[]=used_mb_by_host&summarize=true' Copy Replace $APP_ID and $API_KEY with your app ID and your API key. Replace $HOST_ID with the host id of your target host. This example shows the time range for the default time period (last 30 minutes). For additional detail: Remove the summarize=true to obtain detailed time series data. Specify a different time range. To obtain the same information from the New Relic API Explorer (v2): Select Application Hosts > GET Metric Data, and include your API key. Add your application ID, host id, and the names[]=Memory/Physical and values[]=used_mb_by_host metrics in the appropriate fields. Get memory usage for the entire app To obtain the average Memory usage for your application, use a command similar to the one in the previous example, but remove the reference to hosts and $HOST_ID. Replace $APP_ID and $API_KEY with your app ID and your API key. curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Memory/Physical&values[]=total_used_mb&summarize=true' Copy For additional detail: Remove the summarize=true to obtain detailed time series data. Specify a different time range. To obtain the same information from the New Relic API Explorer (v2): Select Applications > GET Metric Data, and include your API key. Add your application ID and the names[]=Memory/Physical and values[]=total_used_mb metrics in the appropriate fields.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.75493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average memory usage for your application on a single host. This value appears on the APM Summary page in the Hosts table, in the column labeled Memory, or in the corresponding chart. Get memory usage for a host To obtain the average Memory"
      },
      "id": "604405fe28ccbc10d72c60bc"
    }
  ],
  "/docs/apis/rest-api-v2/api-explorer-v2/use-api-explorer": [
    {
      "sections": [
        "Introduction to New Relic's REST API Explorer",
        "Features",
        "Differences from API version 1",
        "Tip"
      ],
      "title": "Introduction to New Relic's REST API Explorer",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "457d31007ab690d5e6f3679e150814c280b49441",
      "image": "https://docs.newrelic.com/static/c506cb08149178347d12b6cbb236c855/23592/API_explorer_main_page.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/introduction-new-relics-rest-api-explorer/",
      "published_at": "2021-12-04T21:03:41Z",
      "updated_at": "2021-10-31T03:53:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers several APIs, including the New Relic REST API. This document introduces you to the REST API Explorer, which allows admin users and those with the API Key to: Browse the available REST API endpoints. Interact with the REST API within a user interface (the API Explorer). View a live source of documentation. Obtain curl commands for API actions. Share configured API calls with colleagues by copy and pasting API Explorer's URLs. This helps you to quickly search for solutions and test your API calls before adding them to your own software components. Features New Relic's API Explorer includes an interactive user interface for your selected account. The API Explorer UI lists the types of API calls (Applications, Users, etc.) and their available functions, such as GET metric data, PUT (update) applications, DELETE applications, etc. As you type values for Parameters, they automatically appear in the Request so that you can test and verify your syntax before sending the request. The UI indicates required fields, field descriptions, their type (integer, float, Boolean, etc.), and their location (path, query, etc.). For information on API key requirements, see REST API keys. rpm.newrelic.com/api/explore: The New Relic API Explorer makes it easy to test and send requests for any API endpoint. After you select your account and your choice of functions for the type of API call (applications, browsers, users, etc.), the UI provides an interactive form to view requirements and test your parameter values. Differences from API version 1 This API Explorer applies only to the New Relic REST API version 2, which focuses on data in and data out of New Relic. Version 2 replaces New Relic's deprecated REST API version 1. Be aware there are some differences between version 2 and 1: Names for data may be different. Some cURL commands for v2 are different than v1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.94151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em>",
        "sections": "Introduction to New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em>",
        "tags": "<em>API</em> <em>Explorer</em> <em>v2</em>",
        "body": " and 1: Names for data may be different. Some cURL commands for <em>v2</em> are different than <em>v</em>1. Tip The New Relic agents use different <em>APIs</em> and are not accessible via the <em>API</em> <em>Explorer</em>."
      },
      "id": "6043ff97196a67c2f2960f65"
    },
    {
      "sections": [
        "Retrieve metric timeslice data for your app (Explorer)",
        "View your app's ID",
        "View metric names for your app",
        "Get metric timeslice data for your app",
        "View other REST API data"
      ],
      "title": "Retrieve metric timeslice data for your app (Explorer)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "3553a434fa75f931ca76da34d5696329801070d9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/retrieve-metric-timeslice-data-your-app-explorer/",
      "published_at": "2021-12-04T15:34:57Z",
      "updated_at": "2021-10-31T03:54:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using New Relic's REST API Explorer (v2) to get metric timeslice data for your application, you need: An API key The app's ID The type of metric timeslice data available for your app, including the metric names and values View your app's ID To view your app's ID: From the New Relic REST API Explorer, select Applications > GET List. If you are not signed in to New Relic, provide an API key for your app. Optional: From Applications > List, fill in values for the name, ids, or language filters. Select Send Request. From the Response section, copy the app's id. Continue with the procedure to view metric names. View metric names for your app To view the metric timeslice data available for your app: From the New Relic REST API Explorer, select Applications > GET Metric Names. From Applications > Metric Names, type or paste your application ID. Fill in a specific or partial metric name, or leave blank to view the list of available metric names and values. Select Send Request. From the Response section, review the app's available metrics. Continue with the procedure to get metric timeslice data. Get metric timeslice data for your app To get the metric values for your app, copy the values from the Metric Names results, and paste them in the Metric Timeslice Data fields: From the New Relic REST API Explorer, select Applications > GET Metric Data. From Applications > Metric Data, type or paste your application ID. Type or paste one or more names (from GET Metric Names) for your app. Start each name on a new line. Select Send Request. From the Response section, review the app's available metric_data. After reviewing the Response section, you can continue making adjustments, and select Send Request again. For example: To specify a time range for the metric timeslice data, fill the from and to values, or use the diamond . To create an average of the data over the time range, set summarize to true. Or, to keep the data for each time period for the range you have specified, leave summarize blank. View other REST API data To use the API Explorer with other New Relic capabilities, select the corresponding API key. This may include: Synthetic monitoring Partners",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.2874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Retrieve metric timeslice data for your app (<em>Explorer</em>)",
        "sections": "<em>View</em> other <em>REST</em> <em>API</em> data",
        "tags": "<em>API</em> <em>Explorer</em> <em>v2</em>",
        "body": "When using New Relic&#x27;s <em>REST</em> <em>API</em> <em>Explorer</em> (<em>v2</em>) to get metric timeslice data for your application, you need: An <em>API</em> key The app&#x27;s ID The type of metric timeslice data available for your app, including the metric names and values View your app&#x27;s ID To view your app&#x27;s ID: From the New Relic <em>REST</em> <em>API</em>"
      },
      "id": "6043ffe628ccbcbb0b2c60a9"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.89543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time examples (<em>v2</em>)",
        "sections": "Average response time examples (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "Here is an example of how to use the New Relic <em>API</em> <em>Explorer</em> (<em>v2</em>) to get your application&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/application-error-rate-example-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/application-reporting-health-status-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.2887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.2887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.3828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time <em>examples</em> (<em>v2</em>)",
        "sections": "Average response time <em>examples</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here is an example of how to use the New Relic <em>API</em> Explorer (<em>v2</em>) to get your <em>application</em>&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/get-average-cpu-usage-host-app": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28868,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.3828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2": [
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.3813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time <em>examples</em> (<em>v2</em>)",
        "sections": "Average response time <em>examples</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here is an example of how to use the New Relic <em>API</em> Explorer (<em>v2</em>) to get your <em>application</em>&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/get-host-memory-used-application": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/get-web-transaction-time-data-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.84332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.8433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Average response time examples (v2)",
        "Contents",
        "Average response time",
        "Tip",
        "Response time"
      ],
      "title": "Average response time examples (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "8adf5a9e8fbbf50b8eca64eb2471eb9a06a3cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/average-response-time-examples-v2/",
      "published_at": "2021-12-04T15:35:38Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is an example of how to use the New Relic API Explorer (v2) to get your application's average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page. New Relic uses this formula to calculate response time: Response time = HttpDispatcher:average_call_time + ((WebFrontend/Queue:call_count * WebFrontend/Queue:average_response_time)/ HttpDispatcher:call_count) Copy To obtain the metric values, use the following two commands. In these examples, the same time period has been used for each, and they are both summarized (averaged). curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=WebFrontend/QueueTime&values[]=call_count&values[]=average_response_time&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Your application may have zero queuing time for the time period in question. In that case, the WebFrontend/QueueTime metric will have a zero value. Tip If your app has never reported a queuing time, the metric WebFrontend/QueueTime will not exist. Response time On the APM Summary page, Response time is the overlaid line within the main chart for your app. To obtain the metric values shown by this line, use the same formula and two commands described above, but remove summarize=true from the commands.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38129,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average response time <em>examples</em> (<em>v2</em>)",
        "sections": "Average response time <em>examples</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here is an example of how to use the New Relic <em>API</em> Explorer (<em>v2</em>) to get your <em>application</em>&#x27;s average response time over a specified time period. Contents Average response time The average response time (milliseconds) is the value that appears on the main chart for your app on the APM Summary page"
      },
      "id": "604405bc196a673e3d960f46"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/list-apps-host-ids-instance-ids": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.8433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/list-your-app-id-metric-timeslice-data-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.8433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/application-examples-v2/summary-data-examples-v2": [
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.8433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web <em>application</em> and non-web <em>application</em> throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Change the alias for your application (v2)",
        "Set application alias and modify Apdex thresholds"
      ],
      "title": "Change the alias for your application (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "e5f896b364a0e6a0f4809fafafa877ac2dc61c7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/change-alias-your-application-v2/",
      "published_at": "2021-12-04T20:55:39Z",
      "updated_at": "2021-10-31T03:56:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The application name you see in the New Relic's user interface is a human-readable alias for the primary name assigned in your configuration settings. If you change it, the name of your app is updated everywhere in New Relic One, including APM, browser monitoring, etc. By default, the alias is the same as the name used in the agent configuration file. Changing the alias does not affect the agent's configured name, and data still reports using that name. Set application alias and modify Apdex thresholds To change the alias for the app name from the New Relic REST API (v2), use this command. You can also change the app alias from New Relic's API Explorer by selecting Applications > Update. You will need to supply the ${APPID}, ${API_KEY}, and the alias name you want the application to be displayed as in the New Relic UI. You must also provide APP_APDEX_THRESHOLD, BROWSER_APDEX_THRESHOLD, and the monitoring enabled BOOLEAN (true or false) even if they are not being modified. curl -X PUT \"https://api.newrelic.com/v2/applications/${APPID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"application\": { \"name\": \"name\", \"settings\": { \"app_apdex_threshold\": APP_APDEX_THRESHOLD, \"end_user_apdex_threshold\": BROWSER_APDEX_THRESHOLD, \"enable_real_user_monitoring\": BOOLEAN } } }' Copy This is the equivalent of using the APM UI to change the displayed app name. This will not change the app identifier name under which your data will be collected. It will only change the app name that appears in the New Relic user interface.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.28865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "sections": "Change the alias for your <em>application</em> (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": " is the same as the name used in the agent configuration file. Changing the alias does not affect the agent&#x27;s configured name, and data still reports using that name. Set <em>application</em> alias and modify Apdex thresholds To change the alias for the app name from the New Relic <em>REST</em> <em>API</em> (<em>v2</em>), use this command"
      },
      "id": "603ed66c28ccbc230feba7a9"
    },
    {
      "sections": [
        "Getting Apdex data for apps or browsers (v2)",
        "Metric names and values for Apdex",
        "Average Apdex score",
        "Average Apdex metric values",
        "All average Apdex values",
        "Tip"
      ],
      "title": "Getting Apdex data for apps or browsers (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "02654775837fc3b3dc3c062720c3d4b05fbe32d2",
      "image": "https://docs.newrelic.com/static/5dd43a481520de96231ec55ce1c0676c/8c557/Apdex_average.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/getting-apdex-data-apps-or-browsers-v2/",
      "published_at": "2021-12-04T15:37:04Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of how to use the New Relic REST API (v2) to get Apdex data for your application and browser, for a specific application ID and API key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values returned may be affected by the time period you specify and the way the data is stored. For more information, see Extracting metric data. Metric names and values for Apdex To specify Apdex metric names and values with REST API calls, use these codes as needed. Metric name Metric value Apdex score: Application's Apdex score s: Application's satisfied count t: Application's tolerating count f: Application's frustrated count count: Application's request count EndUserApdex score: Browser's Apdex score s: Browser's satisfied count t: Browser's tolerating count f: Browser's frustrated count count: Browser's request count The calculation used to determine the score is explained in Apdex: Measuring user satisfaction. The following sections describe how to obtain the score and the s, t, and f values used to arrive at it. Average Apdex score To obtain the average Apdex score (both app and browser) for a specific time period, use this command. This example shows 24 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-01-01T00:00:00+00:00&to=2014-01-02T00:00:00+00:00&summarize=true' Copy This will return the same Apdex scores shown in your APM Overview page. APM > (selected app) > Monitoring > Overview: You can use API v2 to return the same Apdex scores shown in the APM Overview page. Average Apdex metric values To obtain the average Apdex metric values for a specific time range, use this command. This example shows 12 hours in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&values[]=score&from=2014-06-09T00:00:00+00:00&to=2014-06-09T12:00:00+00:00&summarize=true' Copy Tip: To return a series of Apdex scores instead of an average, omit &summarize=true. All average Apdex values To obtain the complete set of average scores, s, t, f, count, and threshold values for a specific time range, use this command. This example shows 24 hours (adjusted to the time zone 6 hours west of UTC by using %2B06:00) in XML format for your application ID and its corresponding API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00%2B06:00&to=2014-06-10T00:00:00%2B06:00&summarize=true' Copy Tip Even though this example adjusts the time zone, the output still returns as UTC time.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.38275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "sections": "Getting Apdex data for apps or browsers (<em>v2</em>)",
        "tags": "<em>Application</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are some <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to get Apdex data for your <em>application</em> and browser, for a specific <em>application</em> ID and <em>API</em> key. By default, this will provide a list of values every minute for the last 30 minutes in JSON format. When acquiring data, the values"
      },
      "id": "604405fe196a674cd9960f1f"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/api-overload-protection-handling-429-errors": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Set a custom user agent",
        "Prerequisites",
        "User agents",
        "Set a user agent",
        "Tip",
        "Set custom user-agent for your integration",
        "User agent strings and New Relic"
      ],
      "title": "Set a custom user agent",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "9135fbe2a8dc7c5b4ccbfb20c28af858ef81cdf8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent/",
      "published_at": "2021-12-04T15:37:39Z",
      "updated_at": "2021-03-13T05:48:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure that New Relic correctly identifies API integration publishers, each integration needs a unique custom user agent string. If you are only using your integration internally, and don't plan on sharing it with anyone outside your organization, you don't need to set a unique custom agent string. Prerequisites This document assumes you plan to publicly distribute an integration that makes use of any of New Relic's public RESTful APIs. Examples of public distribution include: Publicizing your integration code on Github. Packaging your integration into a plugin, extension, or other package, and distributing it via a directory like WordPress Plugins. Offering an \"as a service\" integration between your product and New Relic, without actually distributing your integration code, like Runscope's integration. User agents When writing applications to work with New Relic's RESTful APIs (referred to as an integration in this document), you are creating an HTTP agent to manage information exchange between your application and New Relic. An integration identifies itself by submitting a standard identification string. In HTTP this string is included in the header field User-Agent. When using New Relic's RESTful APIs, set a User-Agent header that identifies your integration in API calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic's APIs. By setting a custom user agent, New Relic can track: Usage statistics for your integration. Potentially buggy or abusive API usage. Set a user agent To set a custom user agent, include an agent string in the HTTP header User-Agent. Examples: Language Example cURL curl -H 'User-Agent: my-integration/1.2.3' Copy Java (using GET) get.setHeader(\"User-Agent\", \"my-integration/1.2.3\"); Copy PHP header('User-Agent: my-integration/1.2.3'); Copy The minimum user agent string is the integration name and version: name/version. You can string together multiple values in a space-separated list. The full syntax is: name/version [(comments)] [name/version [(comments)]] [...]​ Copy For the integration name, use a string that clearly and meaningfully identifies your integration. Ambiguous name: New Relic Integration Clear and meaningful name: SaaS XYZTools Integration with New Relic For the integration version, use a build ID, commit hash, or other identifier that is updated when you release new integration versions. Wrap comments in parentheses () as a semi-colon separated list; Helpful comments to include: The publicly-accessible URL of your integration. For instance, a Github URL, or a page in your docs site that describes the integration. Contact information so that New Relic can easily reach the integration publisher. Tip Information from the user agent string will never be shared, nor used by New Relic for any purpose other than discussing the integration with its publisher. Set custom user-agent for your integration You have an integration with the following identifying information: Name: MetricMeter Version: 3.2 URL: meter.me/info Contact: help@meter.me The custom user agent string would be: MetricMeter for New Relic/3.2 (meter.me/info; help​@​meter.me) Copy User agent strings and New Relic New Relic captures user agent strings from API calls to identify their source. Using custom user agent strings for publicly-available integration is a recommended best practice. Depending on your business relationship with New Relic, it may be required. Labeling your integration with a custom user agent string does not affect its interaction with New Relic's APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " using New Relic&#x27;s RESTful <em>APIs</em>, set a User-Agent header that identifies your integration in <em>API</em> calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic&#x27;s <em>APIs</em>. By setting a custom user agent, New Relic can track: Usage statistics for your"
      },
      "id": "6044070d196a67ce36960f5c"
    },
    {
      "sections": [
        "Pagination for API output",
        "Requirements and limitations",
        "Important",
        "Request a specific page",
        "Link header examples showing page count",
        "Tip",
        "Example: Return 3 pages"
      ],
      "title": "Pagination for API output",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "e53248f738396172abad2740144738488b9f1c1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/pagination-api-output/",
      "published_at": "2021-12-04T15:37:40Z",
      "updated_at": "2021-03-13T05:36:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic REST API (v2) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination is no longer available for metrics output for some customers (deprecation beginning December 2020). Returns up to 3000 results per cell. For large outputs, we recommend narrowing the query using application ID or another attribute. The sort order for returned data is indeterminate. Do not assume or rely on a particular order. The data returned per page depends on what data is requested. The number of pages depends on the number of JSON objects necessary to complete the list. Important Before listing metric names, see Metric name listing guidelines. Request a specific page To specify a page, add the page= parameter to the query. Here's an example: curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json?page=3' \\ -H 'Api-Key:$API_KEY' -i Copy In the REST API Explorer, you can quickly change the page being viewed. Link header examples showing page count The API call returns the Link header if the data is paginated. This indicates the number of pages and the page being viewed. This line also appears at the top of the Response in the REST API Explorer. Important The Link header will only appear if the output data is paginated. Tip The rel=\"last\" reference will not be shown when making calls to the Violations endpoint (https://api.newrelic.com/v2/alerts_violations.json). To determine the final page when making calls to this endpoint, look for the absence of a rel=\"next\" reference. To obtain this line using some implementations of curl, you may need to include the -v option. curl -v -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/...' Copy New Relic uses the RFC 5988 standard format for links. Example: Return 3 pages The API output will contain a Link line similar to this. Lines are wrapped to improve readability. Link: <https://api.newrelic.com/v2/alert_policies.xml?page=2>;rel=\"next\", <https://api.newrelic.com/v2/alert_policies.xml?page=3>;rel=\"last\" Copy This indicates there are three pages and you are viewing the first one. Parameter Description ...page=2>;rel=\"next\" Page 2 is the next page ...page=3>;rel=\"last\" Page 3 is the last page",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pagination for <em>API</em> output",
        "sections": "Pagination for <em>API</em> output",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "The New Relic <em>REST</em> <em>API</em> (<em>v2</em>) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination"
      },
      "id": "604406cf28ccbce7b02c60ab"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/calculate-average-metric-values-summarize": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Set a custom user agent",
        "Prerequisites",
        "User agents",
        "Set a user agent",
        "Tip",
        "Set custom user-agent for your integration",
        "User agent strings and New Relic"
      ],
      "title": "Set a custom user agent",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "9135fbe2a8dc7c5b4ccbfb20c28af858ef81cdf8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent/",
      "published_at": "2021-12-04T15:37:39Z",
      "updated_at": "2021-03-13T05:48:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure that New Relic correctly identifies API integration publishers, each integration needs a unique custom user agent string. If you are only using your integration internally, and don't plan on sharing it with anyone outside your organization, you don't need to set a unique custom agent string. Prerequisites This document assumes you plan to publicly distribute an integration that makes use of any of New Relic's public RESTful APIs. Examples of public distribution include: Publicizing your integration code on Github. Packaging your integration into a plugin, extension, or other package, and distributing it via a directory like WordPress Plugins. Offering an \"as a service\" integration between your product and New Relic, without actually distributing your integration code, like Runscope's integration. User agents When writing applications to work with New Relic's RESTful APIs (referred to as an integration in this document), you are creating an HTTP agent to manage information exchange between your application and New Relic. An integration identifies itself by submitting a standard identification string. In HTTP this string is included in the header field User-Agent. When using New Relic's RESTful APIs, set a User-Agent header that identifies your integration in API calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic's APIs. By setting a custom user agent, New Relic can track: Usage statistics for your integration. Potentially buggy or abusive API usage. Set a user agent To set a custom user agent, include an agent string in the HTTP header User-Agent. Examples: Language Example cURL curl -H 'User-Agent: my-integration/1.2.3' Copy Java (using GET) get.setHeader(\"User-Agent\", \"my-integration/1.2.3\"); Copy PHP header('User-Agent: my-integration/1.2.3'); Copy The minimum user agent string is the integration name and version: name/version. You can string together multiple values in a space-separated list. The full syntax is: name/version [(comments)] [name/version [(comments)]] [...]​ Copy For the integration name, use a string that clearly and meaningfully identifies your integration. Ambiguous name: New Relic Integration Clear and meaningful name: SaaS XYZTools Integration with New Relic For the integration version, use a build ID, commit hash, or other identifier that is updated when you release new integration versions. Wrap comments in parentheses () as a semi-colon separated list; Helpful comments to include: The publicly-accessible URL of your integration. For instance, a Github URL, or a page in your docs site that describes the integration. Contact information so that New Relic can easily reach the integration publisher. Tip Information from the user agent string will never be shared, nor used by New Relic for any purpose other than discussing the integration with its publisher. Set custom user-agent for your integration You have an integration with the following identifying information: Name: MetricMeter Version: 3.2 URL: meter.me/info Contact: help@meter.me The custom user agent string would be: MetricMeter for New Relic/3.2 (meter.me/info; help​@​meter.me) Copy User agent strings and New Relic New Relic captures user agent strings from API calls to identify their source. Using custom user agent strings for publicly-available integration is a recommended best practice. Depending on your business relationship with New Relic, it may be required. Labeling your integration with a custom user agent string does not affect its interaction with New Relic's APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " using New Relic&#x27;s RESTful <em>APIs</em>, set a User-Agent header that identifies your integration in <em>API</em> calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic&#x27;s <em>APIs</em>. By setting a custom user agent, New Relic can track: Usage statistics for your"
      },
      "id": "6044070d196a67ce36960f5c"
    },
    {
      "sections": [
        "Pagination for API output",
        "Requirements and limitations",
        "Important",
        "Request a specific page",
        "Link header examples showing page count",
        "Tip",
        "Example: Return 3 pages"
      ],
      "title": "Pagination for API output",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "e53248f738396172abad2740144738488b9f1c1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/pagination-api-output/",
      "published_at": "2021-12-04T15:37:40Z",
      "updated_at": "2021-03-13T05:36:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic REST API (v2) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination is no longer available for metrics output for some customers (deprecation beginning December 2020). Returns up to 3000 results per cell. For large outputs, we recommend narrowing the query using application ID or another attribute. The sort order for returned data is indeterminate. Do not assume or rely on a particular order. The data returned per page depends on what data is requested. The number of pages depends on the number of JSON objects necessary to complete the list. Important Before listing metric names, see Metric name listing guidelines. Request a specific page To specify a page, add the page= parameter to the query. Here's an example: curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json?page=3' \\ -H 'Api-Key:$API_KEY' -i Copy In the REST API Explorer, you can quickly change the page being viewed. Link header examples showing page count The API call returns the Link header if the data is paginated. This indicates the number of pages and the page being viewed. This line also appears at the top of the Response in the REST API Explorer. Important The Link header will only appear if the output data is paginated. Tip The rel=\"last\" reference will not be shown when making calls to the Violations endpoint (https://api.newrelic.com/v2/alerts_violations.json). To determine the final page when making calls to this endpoint, look for the absence of a rel=\"next\" reference. To obtain this line using some implementations of curl, you may need to include the -v option. curl -v -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/...' Copy New Relic uses the RFC 5988 standard format for links. Example: Return 3 pages The API output will contain a Link line similar to this. Lines are wrapped to improve readability. Link: <https://api.newrelic.com/v2/alert_policies.xml?page=2>;rel=\"next\", <https://api.newrelic.com/v2/alert_policies.xml?page=3>;rel=\"last\" Copy This indicates there are three pages and you are viewing the first one. Parameter Description ...page=2>;rel=\"next\" Page 2 is the next page ...page=3>;rel=\"last\" Page 3 is the last page",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pagination for <em>API</em> output",
        "sections": "Pagination for <em>API</em> output",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "The New Relic <em>REST</em> <em>API</em> (<em>v2</em>) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination"
      },
      "id": "604406cf28ccbce7b02c60ab"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/extract-metric-timeslice-data": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Set a custom user agent",
        "Prerequisites",
        "User agents",
        "Set a user agent",
        "Tip",
        "Set custom user-agent for your integration",
        "User agent strings and New Relic"
      ],
      "title": "Set a custom user agent",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "9135fbe2a8dc7c5b4ccbfb20c28af858ef81cdf8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent/",
      "published_at": "2021-12-04T15:37:39Z",
      "updated_at": "2021-03-13T05:48:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure that New Relic correctly identifies API integration publishers, each integration needs a unique custom user agent string. If you are only using your integration internally, and don't plan on sharing it with anyone outside your organization, you don't need to set a unique custom agent string. Prerequisites This document assumes you plan to publicly distribute an integration that makes use of any of New Relic's public RESTful APIs. Examples of public distribution include: Publicizing your integration code on Github. Packaging your integration into a plugin, extension, or other package, and distributing it via a directory like WordPress Plugins. Offering an \"as a service\" integration between your product and New Relic, without actually distributing your integration code, like Runscope's integration. User agents When writing applications to work with New Relic's RESTful APIs (referred to as an integration in this document), you are creating an HTTP agent to manage information exchange between your application and New Relic. An integration identifies itself by submitting a standard identification string. In HTTP this string is included in the header field User-Agent. When using New Relic's RESTful APIs, set a User-Agent header that identifies your integration in API calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic's APIs. By setting a custom user agent, New Relic can track: Usage statistics for your integration. Potentially buggy or abusive API usage. Set a user agent To set a custom user agent, include an agent string in the HTTP header User-Agent. Examples: Language Example cURL curl -H 'User-Agent: my-integration/1.2.3' Copy Java (using GET) get.setHeader(\"User-Agent\", \"my-integration/1.2.3\"); Copy PHP header('User-Agent: my-integration/1.2.3'); Copy The minimum user agent string is the integration name and version: name/version. You can string together multiple values in a space-separated list. The full syntax is: name/version [(comments)] [name/version [(comments)]] [...]​ Copy For the integration name, use a string that clearly and meaningfully identifies your integration. Ambiguous name: New Relic Integration Clear and meaningful name: SaaS XYZTools Integration with New Relic For the integration version, use a build ID, commit hash, or other identifier that is updated when you release new integration versions. Wrap comments in parentheses () as a semi-colon separated list; Helpful comments to include: The publicly-accessible URL of your integration. For instance, a Github URL, or a page in your docs site that describes the integration. Contact information so that New Relic can easily reach the integration publisher. Tip Information from the user agent string will never be shared, nor used by New Relic for any purpose other than discussing the integration with its publisher. Set custom user-agent for your integration You have an integration with the following identifying information: Name: MetricMeter Version: 3.2 URL: meter.me/info Contact: help@meter.me The custom user agent string would be: MetricMeter for New Relic/3.2 (meter.me/info; help​@​meter.me) Copy User agent strings and New Relic New Relic captures user agent strings from API calls to identify their source. Using custom user agent strings for publicly-available integration is a recommended best practice. Depending on your business relationship with New Relic, it may be required. Labeling your integration with a custom user agent string does not affect its interaction with New Relic's APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " using New Relic&#x27;s RESTful <em>APIs</em>, set a User-Agent header that identifies your integration in <em>API</em> calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic&#x27;s <em>APIs</em>. By setting a custom user agent, New Relic can track: Usage statistics for your"
      },
      "id": "6044070d196a67ce36960f5c"
    },
    {
      "sections": [
        "Pagination for API output",
        "Requirements and limitations",
        "Important",
        "Request a specific page",
        "Link header examples showing page count",
        "Tip",
        "Example: Return 3 pages"
      ],
      "title": "Pagination for API output",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "e53248f738396172abad2740144738488b9f1c1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/pagination-api-output/",
      "published_at": "2021-12-04T15:37:40Z",
      "updated_at": "2021-03-13T05:36:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic REST API (v2) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination is no longer available for metrics output for some customers (deprecation beginning December 2020). Returns up to 3000 results per cell. For large outputs, we recommend narrowing the query using application ID or another attribute. The sort order for returned data is indeterminate. Do not assume or rely on a particular order. The data returned per page depends on what data is requested. The number of pages depends on the number of JSON objects necessary to complete the list. Important Before listing metric names, see Metric name listing guidelines. Request a specific page To specify a page, add the page= parameter to the query. Here's an example: curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json?page=3' \\ -H 'Api-Key:$API_KEY' -i Copy In the REST API Explorer, you can quickly change the page being viewed. Link header examples showing page count The API call returns the Link header if the data is paginated. This indicates the number of pages and the page being viewed. This line also appears at the top of the Response in the REST API Explorer. Important The Link header will only appear if the output data is paginated. Tip The rel=\"last\" reference will not be shown when making calls to the Violations endpoint (https://api.newrelic.com/v2/alerts_violations.json). To determine the final page when making calls to this endpoint, look for the absence of a rel=\"next\" reference. To obtain this line using some implementations of curl, you may need to include the -v option. curl -v -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/...' Copy New Relic uses the RFC 5988 standard format for links. Example: Return 3 pages The API output will contain a Link line similar to this. Lines are wrapped to improve readability. Link: <https://api.newrelic.com/v2/alert_policies.xml?page=2>;rel=\"next\", <https://api.newrelic.com/v2/alert_policies.xml?page=3>;rel=\"last\" Copy This indicates there are three pages and you are viewing the first one. Parameter Description ...page=2>;rel=\"next\" Page 2 is the next page ...page=3>;rel=\"last\" Page 3 is the last page",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pagination for <em>API</em> output",
        "sections": "Pagination for <em>API</em> output",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "The New Relic <em>REST</em> <em>API</em> (<em>v2</em>) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination"
      },
      "id": "604406cf28ccbce7b02c60ab"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/pagination-api-output": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Set a custom user agent",
        "Prerequisites",
        "User agents",
        "Set a user agent",
        "Tip",
        "Set custom user-agent for your integration",
        "User agent strings and New Relic"
      ],
      "title": "Set a custom user agent",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "9135fbe2a8dc7c5b4ccbfb20c28af858ef81cdf8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent/",
      "published_at": "2021-12-04T15:37:39Z",
      "updated_at": "2021-03-13T05:48:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure that New Relic correctly identifies API integration publishers, each integration needs a unique custom user agent string. If you are only using your integration internally, and don't plan on sharing it with anyone outside your organization, you don't need to set a unique custom agent string. Prerequisites This document assumes you plan to publicly distribute an integration that makes use of any of New Relic's public RESTful APIs. Examples of public distribution include: Publicizing your integration code on Github. Packaging your integration into a plugin, extension, or other package, and distributing it via a directory like WordPress Plugins. Offering an \"as a service\" integration between your product and New Relic, without actually distributing your integration code, like Runscope's integration. User agents When writing applications to work with New Relic's RESTful APIs (referred to as an integration in this document), you are creating an HTTP agent to manage information exchange between your application and New Relic. An integration identifies itself by submitting a standard identification string. In HTTP this string is included in the header field User-Agent. When using New Relic's RESTful APIs, set a User-Agent header that identifies your integration in API calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic's APIs. By setting a custom user agent, New Relic can track: Usage statistics for your integration. Potentially buggy or abusive API usage. Set a user agent To set a custom user agent, include an agent string in the HTTP header User-Agent. Examples: Language Example cURL curl -H 'User-Agent: my-integration/1.2.3' Copy Java (using GET) get.setHeader(\"User-Agent\", \"my-integration/1.2.3\"); Copy PHP header('User-Agent: my-integration/1.2.3'); Copy The minimum user agent string is the integration name and version: name/version. You can string together multiple values in a space-separated list. The full syntax is: name/version [(comments)] [name/version [(comments)]] [...]​ Copy For the integration name, use a string that clearly and meaningfully identifies your integration. Ambiguous name: New Relic Integration Clear and meaningful name: SaaS XYZTools Integration with New Relic For the integration version, use a build ID, commit hash, or other identifier that is updated when you release new integration versions. Wrap comments in parentheses () as a semi-colon separated list; Helpful comments to include: The publicly-accessible URL of your integration. For instance, a Github URL, or a page in your docs site that describes the integration. Contact information so that New Relic can easily reach the integration publisher. Tip Information from the user agent string will never be shared, nor used by New Relic for any purpose other than discussing the integration with its publisher. Set custom user-agent for your integration You have an integration with the following identifying information: Name: MetricMeter Version: 3.2 URL: meter.me/info Contact: help@meter.me The custom user agent string would be: MetricMeter for New Relic/3.2 (meter.me/info; help​@​meter.me) Copy User agent strings and New Relic New Relic captures user agent strings from API calls to identify their source. Using custom user agent strings for publicly-available integration is a recommended best practice. Depending on your business relationship with New Relic, it may be required. Labeling your integration with a custom user agent string does not affect its interaction with New Relic's APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " using New Relic&#x27;s RESTful <em>APIs</em>, set a User-Agent header that identifies your integration in <em>API</em> calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic&#x27;s <em>APIs</em>. By setting a custom user agent, New Relic can track: Usage statistics for your"
      },
      "id": "6044070d196a67ce36960f5c"
    },
    {
      "sections": [
        "Specify a time range (v2)",
        "Change the default 30 minute time range",
        "Tip",
        "Offset UTC",
        "This API call shows a time zone east of UTC by 2 hours (-02:00)",
        "This API call shows a time zone west of UTC by +8 hours (%2B08:00)"
      ],
      "title": "Specify a time range (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "77aec38cd1f565f3a461cfd9401f337cda0936b5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/specify-time-range-v2/",
      "published_at": "2021-12-04T21:04:19Z",
      "updated_at": "2021-03-16T08:14:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can specify a time range for the data to be returned in a New Relic REST API call. You can also request to return an average over the time range instead of the series of values returned by default. Change the default 30 minute time range The default time range for an API call is the last 30 minutes. To modify the time range, include from= and optional to= values. (To end the time range at the current time, omit to=.) Tip Data availability is subject to the data retention policy for your subscription level. Example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00+00:00&to=2014-08-11T15:12:00+00:00' Copy The time period returned for each data point depends on the time range you specify. To modify the time period, include the period parameter in your query. If you are using the New Relic REST API Explorer (v2), you can use the diamond icon to select time ranges. If you have an EU region account, the above URL begins with https://api.eu.newrelic.com. Offset UTC By default the API time input uses Universal Time Coordinated (UTC). To offset the UTC, use plus or minus 00:00 in your API call. This allows you to input times in a different time zone; however, this does not modify the output times, which are always UTC. For time zones east of UTC, use a minus sign (-). This symbol has no special meaning in HTTP or HTTPS requests. For time zones west of UTC, use the encoded value %2B to indicate a plus sign (+). If you have an EU region account, the following URLs begin with https://api.eu.newrelic.com. This API call shows a time zone east of UTC by 2 hours (-02:00) curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00 -02:00 &to=2014-08-11T15:12:00 -02:00 ' Copy This API call shows a time zone west of UTC by +8 hours (%2B08:00) curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00 %2B08:00 &to=2014-08-11T15:12:00 %2B08:00 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.56035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Specify a time range (<em>v2</em>)",
        "sections": "This <em>API</em> call shows a time zone east of UTC by <em>2</em> hours (-02:00)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". If you are using the New Relic <em>REST</em> <em>API</em> Explorer (<em>v2</em>), you can use the diamond icon to select time ranges. If you have an EU region account, the above URL begins with https:&#x2F;&#x2F;<em>api</em>.eu.newrelic.com. Offset UTC By default the <em>API</em> time input uses Universal Time Coordinated (UTC). To offset the UTC, use"
      },
      "id": "603ece55196a67561ba83dc2"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Pagination for API output",
        "Requirements and limitations",
        "Important",
        "Request a specific page",
        "Link header examples showing page count",
        "Tip",
        "Example: Return 3 pages"
      ],
      "title": "Pagination for API output",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "e53248f738396172abad2740144738488b9f1c1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/pagination-api-output/",
      "published_at": "2021-12-04T15:37:40Z",
      "updated_at": "2021-03-13T05:36:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic REST API (v2) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination is no longer available for metrics output for some customers (deprecation beginning December 2020). Returns up to 3000 results per cell. For large outputs, we recommend narrowing the query using application ID or another attribute. The sort order for returned data is indeterminate. Do not assume or rely on a particular order. The data returned per page depends on what data is requested. The number of pages depends on the number of JSON objects necessary to complete the list. Important Before listing metric names, see Metric name listing guidelines. Request a specific page To specify a page, add the page= parameter to the query. Here's an example: curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json?page=3' \\ -H 'Api-Key:$API_KEY' -i Copy In the REST API Explorer, you can quickly change the page being viewed. Link header examples showing page count The API call returns the Link header if the data is paginated. This indicates the number of pages and the page being viewed. This line also appears at the top of the Response in the REST API Explorer. Important The Link header will only appear if the output data is paginated. Tip The rel=\"last\" reference will not be shown when making calls to the Violations endpoint (https://api.newrelic.com/v2/alerts_violations.json). To determine the final page when making calls to this endpoint, look for the absence of a rel=\"next\" reference. To obtain this line using some implementations of curl, you may need to include the -v option. curl -v -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/...' Copy New Relic uses the RFC 5988 standard format for links. Example: Return 3 pages The API output will contain a Link line similar to this. Lines are wrapped to improve readability. Link: <https://api.newrelic.com/v2/alert_policies.xml?page=2>;rel=\"next\", <https://api.newrelic.com/v2/alert_policies.xml?page=3>;rel=\"last\" Copy This indicates there are three pages and you are viewing the first one. Parameter Description ...page=2>;rel=\"next\" Page 2 is the next page ...page=3>;rel=\"last\" Page 3 is the last page",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pagination for <em>API</em> output",
        "sections": "Pagination for <em>API</em> output",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "The New Relic <em>REST</em> <em>API</em> (<em>v2</em>) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination"
      },
      "id": "604406cf28ccbce7b02c60ab"
    },
    {
      "sections": [
        "Specify a time range (v2)",
        "Change the default 30 minute time range",
        "Tip",
        "Offset UTC",
        "This API call shows a time zone east of UTC by 2 hours (-02:00)",
        "This API call shows a time zone west of UTC by +8 hours (%2B08:00)"
      ],
      "title": "Specify a time range (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "77aec38cd1f565f3a461cfd9401f337cda0936b5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/specify-time-range-v2/",
      "published_at": "2021-12-04T21:04:19Z",
      "updated_at": "2021-03-16T08:14:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can specify a time range for the data to be returned in a New Relic REST API call. You can also request to return an average over the time range instead of the series of values returned by default. Change the default 30 minute time range The default time range for an API call is the last 30 minutes. To modify the time range, include from= and optional to= values. (To end the time range at the current time, omit to=.) Tip Data availability is subject to the data retention policy for your subscription level. Example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00+00:00&to=2014-08-11T15:12:00+00:00' Copy The time period returned for each data point depends on the time range you specify. To modify the time period, include the period parameter in your query. If you are using the New Relic REST API Explorer (v2), you can use the diamond icon to select time ranges. If you have an EU region account, the above URL begins with https://api.eu.newrelic.com. Offset UTC By default the API time input uses Universal Time Coordinated (UTC). To offset the UTC, use plus or minus 00:00 in your API call. This allows you to input times in a different time zone; however, this does not modify the output times, which are always UTC. For time zones east of UTC, use a minus sign (-). This symbol has no special meaning in HTTP or HTTPS requests. For time zones west of UTC, use the encoded value %2B to indicate a plus sign (+). If you have an EU region account, the following URLs begin with https://api.eu.newrelic.com. This API call shows a time zone east of UTC by 2 hours (-02:00) curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00 -02:00 &to=2014-08-11T15:12:00 -02:00 ' Copy This API call shows a time zone west of UTC by +8 hours (%2B08:00) curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Agent/MetricsReported/count&from=2014-08-11T14:42:00 %2B08:00 &to=2014-08-11T15:12:00 %2B08:00 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.56035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Specify a time range (<em>v2</em>)",
        "sections": "This <em>API</em> call shows a time zone east of UTC by <em>2</em> hours (-02:00)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". If you are using the New Relic <em>REST</em> <em>API</em> Explorer (<em>v2</em>), you can use the diamond icon to select time ranges. If you have an EU region account, the above URL begins with https:&#x2F;&#x2F;<em>api</em>.eu.newrelic.com. Offset UTC By default the <em>API</em> time input uses Universal Time Coordinated (UTC). To offset the UTC, use"
      },
      "id": "603ece55196a67561ba83dc2"
    }
  ],
  "/docs/apis/rest-api-v2/basic-functions/specify-time-range-v2": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Set a custom user agent",
        "Prerequisites",
        "User agents",
        "Set a user agent",
        "Tip",
        "Set custom user-agent for your integration",
        "User agent strings and New Relic"
      ],
      "title": "Set a custom user agent",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "9135fbe2a8dc7c5b4ccbfb20c28af858ef81cdf8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/set-custom-user-agent/",
      "published_at": "2021-12-04T15:37:39Z",
      "updated_at": "2021-03-13T05:48:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure that New Relic correctly identifies API integration publishers, each integration needs a unique custom user agent string. If you are only using your integration internally, and don't plan on sharing it with anyone outside your organization, you don't need to set a unique custom agent string. Prerequisites This document assumes you plan to publicly distribute an integration that makes use of any of New Relic's public RESTful APIs. Examples of public distribution include: Publicizing your integration code on Github. Packaging your integration into a plugin, extension, or other package, and distributing it via a directory like WordPress Plugins. Offering an \"as a service\" integration between your product and New Relic, without actually distributing your integration code, like Runscope's integration. User agents When writing applications to work with New Relic's RESTful APIs (referred to as an integration in this document), you are creating an HTTP agent to manage information exchange between your application and New Relic. An integration identifies itself by submitting a standard identification string. In HTTP this string is included in the header field User-Agent. When using New Relic's RESTful APIs, set a User-Agent header that identifies your integration in API calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic's APIs. By setting a custom user agent, New Relic can track: Usage statistics for your integration. Potentially buggy or abusive API usage. Set a user agent To set a custom user agent, include an agent string in the HTTP header User-Agent. Examples: Language Example cURL curl -H 'User-Agent: my-integration/1.2.3' Copy Java (using GET) get.setHeader(\"User-Agent\", \"my-integration/1.2.3\"); Copy PHP header('User-Agent: my-integration/1.2.3'); Copy The minimum user agent string is the integration name and version: name/version. You can string together multiple values in a space-separated list. The full syntax is: name/version [(comments)] [name/version [(comments)]] [...]​ Copy For the integration name, use a string that clearly and meaningfully identifies your integration. Ambiguous name: New Relic Integration Clear and meaningful name: SaaS XYZTools Integration with New Relic For the integration version, use a build ID, commit hash, or other identifier that is updated when you release new integration versions. Wrap comments in parentheses () as a semi-colon separated list; Helpful comments to include: The publicly-accessible URL of your integration. For instance, a Github URL, or a page in your docs site that describes the integration. Contact information so that New Relic can easily reach the integration publisher. Tip Information from the user agent string will never be shared, nor used by New Relic for any purpose other than discussing the integration with its publisher. Set custom user-agent for your integration You have an integration with the following identifying information: Name: MetricMeter Version: 3.2 URL: meter.me/info Contact: help@meter.me The custom user agent string would be: MetricMeter for New Relic/3.2 (meter.me/info; help​@​meter.me) Copy User agent strings and New Relic New Relic captures user agent strings from API calls to identify their source. Using custom user agent strings for publicly-available integration is a recommended best practice. Depending on your business relationship with New Relic, it may be required. Labeling your integration with a custom user agent string does not affect its interaction with New Relic's APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " using New Relic&#x27;s RESTful <em>APIs</em>, set a User-Agent header that identifies your integration in <em>API</em> calls. This custom User-Agent string allows New Relic to identify the integration that is making requests to New Relic&#x27;s <em>APIs</em>. By setting a custom user agent, New Relic can track: Usage statistics for your"
      },
      "id": "6044070d196a67ce36960f5c"
    },
    {
      "sections": [
        "Pagination for API output",
        "Requirements and limitations",
        "Important",
        "Request a specific page",
        "Link header examples showing page count",
        "Tip",
        "Example: Return 3 pages"
      ],
      "title": "Pagination for API output",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "e53248f738396172abad2740144738488b9f1c1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/pagination-api-output/",
      "published_at": "2021-12-04T15:37:40Z",
      "updated_at": "2021-03-13T05:36:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic REST API (v2) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination is no longer available for metrics output for some customers (deprecation beginning December 2020). Returns up to 3000 results per cell. For large outputs, we recommend narrowing the query using application ID or another attribute. The sort order for returned data is indeterminate. Do not assume or rely on a particular order. The data returned per page depends on what data is requested. The number of pages depends on the number of JSON objects necessary to complete the list. Important Before listing metric names, see Metric name listing guidelines. Request a specific page To specify a page, add the page= parameter to the query. Here's an example: curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json?page=3' \\ -H 'Api-Key:$API_KEY' -i Copy In the REST API Explorer, you can quickly change the page being viewed. Link header examples showing page count The API call returns the Link header if the data is paginated. This indicates the number of pages and the page being viewed. This line also appears at the top of the Response in the REST API Explorer. Important The Link header will only appear if the output data is paginated. Tip The rel=\"last\" reference will not be shown when making calls to the Violations endpoint (https://api.newrelic.com/v2/alerts_violations.json). To determine the final page when making calls to this endpoint, look for the absence of a rel=\"next\" reference. To obtain this line using some implementations of curl, you may need to include the -v option. curl -v -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/...' Copy New Relic uses the RFC 5988 standard format for links. Example: Return 3 pages The API output will contain a Link line similar to this. Lines are wrapped to improve readability. Link: <https://api.newrelic.com/v2/alert_policies.xml?page=2>;rel=\"next\", <https://api.newrelic.com/v2/alert_policies.xml?page=3>;rel=\"last\" Copy This indicates there are three pages and you are viewing the first one. Parameter Description ...page=2>;rel=\"next\" Page 2 is the next page ...page=3>;rel=\"last\" Page 3 is the last page",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.30994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pagination for <em>API</em> output",
        "sections": "Pagination for <em>API</em> output",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "The New Relic <em>REST</em> <em>API</em> (<em>v2</em>) paginates some responses, for performance reasons. This is because returning the entire data set might be feasible for some queries but prohibitive for others that return a very large amount of data. Requirements and limitations Metric data return: Pagination"
      },
      "id": "604406cf28ccbce7b02c60ab"
    }
  ],
  "/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2": [
    {
      "sections": [
        "Average browser (end user) page throughput example (v2)",
        "Average page throughput"
      ],
      "title": "Average browser (end user) page throughput example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "713534d353c7a66e7c02ec00f7d5340dab172740",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-end-user-page-throughput-example-v2/",
      "published_at": "2021-12-04T20:50:44Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser throughput appears at the top right of the Throughput by browser chart on your Summary page. This is the average pages per minute (PPM) by browser type in the time range shown on the chart. Average page throughput To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET 'https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json' \\ -H 'X-Api-Key:${API_KEY}' -i \\ -d 'names[]=EndUser&values[]=requests_per_minute&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.04219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " minutes), use the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&#x27; \\ -H &#x27;X-<em>Api</em>-Key:${<em>API</em>_KEY}&#x27; -i \\ -d &#x27;names[]=EndUser&amp;values[]=requests_per_minute&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf28ccbc10652c6091"
    },
    {
      "sections": [
        "Obtaining browser (end user) page load time data (v2)",
        "General API values",
        "Network time",
        "Page rendering time",
        "DOM processing time",
        "Web application time",
        "Request queuing time"
      ],
      "title": "Obtaining browser (end user) page load time data (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "c0c497cf900d84a9e57a07aba5062003e86506a8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/obtaining-browser-end-user-page-load-time-data-v2/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-07-09T14:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The metric timeslice data presented on the Browser page load time chart on your application's Summary page will depend on your web app's configuration. Possible components may include: Network time Page rendering time DOM processing time Web application time Request queuing time This describes how to use the New Relic REST API (v2) to obtain the data shown on the Browser page load time chart. General API values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these examples. For calculated values, the time range you specify must be consistent in all of the queries; otherwise the final calculations will be incorrect. You must replace the ${APPID} and ${API_KEY} variables in these examples with your specific application ID and corresponding REST API key. Ensure you adjust the time units returned by the API requests as needed. Network time The EndUser:average_network_time is the network latency, or time it takes for a request to make a round trip over the Internet. Use the following command to obtain this. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_network_time' Copy This time is returned in milliseconds. Page rendering time Page rendering time is a derived value. To calculate it, use this equation: \"Page rendering\" time = EndUser:average_fe_response_time - EndUser/RB:average_dom_content_load_time Copy To obtain the data for this calculation, use the following commands. EndUser:average_fe_response_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_fe_response_time' Copy This time is returned in milliseconds. EndUser/RB:average_dom_content_load_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. DOM processing time The EndUser/RB:average_dom_content_load_time is the time spent in the browser to parse and interpret the HTML. This is measured by the browser's DOM Content event. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. Web application time The Web application time is the time spent in the application code. To calculate this value, use this equation: Web application = EndUser:total_app_time / EndUser:call_count Copy To obtain the data for this calculation, use the following commands. EndUser:total_app_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=total_app_time' Copy This time is returned in seconds. EndUser:call_count curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=call_count' Copy Request queuing time The EndUser/RB:average_queue_time is the wait time between the web server and the application code. Large numbers indicate a busy application server. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_queue_time' Copy This time is returned in milliseconds. The request queuing time is not included in the calculation of averages. New Relic includes it in this chart as a convenience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.41304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "sections": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the data shown on the <em>Browser</em> page load time chart. General <em>API</em> values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these <em>examples</em>. For calculated values, the time range you"
      },
      "id": "6044070de7b9d2b9f7579a16"
    },
    {
      "sections": [
        "Average browser page load time example (v2)",
        "Average page load time"
      ],
      "title": "Average browser page load time example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "2e2669a368831880e962cdbd39d95d31a98aa253",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-page-load-time-example-v2/",
      "published_at": "2021-12-04T20:58:59Z",
      "updated_at": "2021-03-13T03:36:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser page load time (or response time) appears at the top right of the main chart of your Summary page. This value is labeled Browser and shows the average page load time in seconds. Average page load time To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_response_time&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.11131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &quot;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&quot; \\ -H &quot;X-<em>Api</em>-Key:${<em>API</em>_KEY}&quot; -i \\ -d &#x27;names[]=EndUser&amp;values[]=average_response_time&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf196a670c98960f55"
    }
  ],
  "/docs/apis/rest-api-v2/browser-examples-v2/average-browser-end-user-page-throughput-example-v2": [
    {
      "sections": [
        "Add or list browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-12-04T21:04:35Z",
      "updated_at": "2021-11-13T06:57:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, set up single page app monitoring via another method. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser applications > POST create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your browser-monitored apps, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by browser application ID: To view a specific browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.15024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "sections": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to add apps to <em>browser</em> monitoring or to get a list of your <em>browser</em> apps for a specific <em>API</em> key. This helps you manage deployment outside of New Relic One. These <em>API</em> calls are useful, for example, with larger organizations deploying"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "sections": [
        "Obtaining browser (end user) page load time data (v2)",
        "General API values",
        "Network time",
        "Page rendering time",
        "DOM processing time",
        "Web application time",
        "Request queuing time"
      ],
      "title": "Obtaining browser (end user) page load time data (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "c0c497cf900d84a9e57a07aba5062003e86506a8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/obtaining-browser-end-user-page-load-time-data-v2/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-07-09T14:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The metric timeslice data presented on the Browser page load time chart on your application's Summary page will depend on your web app's configuration. Possible components may include: Network time Page rendering time DOM processing time Web application time Request queuing time This describes how to use the New Relic REST API (v2) to obtain the data shown on the Browser page load time chart. General API values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these examples. For calculated values, the time range you specify must be consistent in all of the queries; otherwise the final calculations will be incorrect. You must replace the ${APPID} and ${API_KEY} variables in these examples with your specific application ID and corresponding REST API key. Ensure you adjust the time units returned by the API requests as needed. Network time The EndUser:average_network_time is the network latency, or time it takes for a request to make a round trip over the Internet. Use the following command to obtain this. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_network_time' Copy This time is returned in milliseconds. Page rendering time Page rendering time is a derived value. To calculate it, use this equation: \"Page rendering\" time = EndUser:average_fe_response_time - EndUser/RB:average_dom_content_load_time Copy To obtain the data for this calculation, use the following commands. EndUser:average_fe_response_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_fe_response_time' Copy This time is returned in milliseconds. EndUser/RB:average_dom_content_load_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. DOM processing time The EndUser/RB:average_dom_content_load_time is the time spent in the browser to parse and interpret the HTML. This is measured by the browser's DOM Content event. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. Web application time The Web application time is the time spent in the application code. To calculate this value, use this equation: Web application = EndUser:total_app_time / EndUser:call_count Copy To obtain the data for this calculation, use the following commands. EndUser:total_app_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=total_app_time' Copy This time is returned in seconds. EndUser:call_count curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=call_count' Copy Request queuing time The EndUser/RB:average_queue_time is the wait time between the web server and the application code. Large numbers indicate a busy application server. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_queue_time' Copy This time is returned in milliseconds. The request queuing time is not included in the calculation of averages. New Relic includes it in this chart as a convenience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.41304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "sections": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the data shown on the <em>Browser</em> page load time chart. General <em>API</em> values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these <em>examples</em>. For calculated values, the time range you"
      },
      "id": "6044070de7b9d2b9f7579a16"
    },
    {
      "sections": [
        "Average browser page load time example (v2)",
        "Average page load time"
      ],
      "title": "Average browser page load time example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "2e2669a368831880e962cdbd39d95d31a98aa253",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-page-load-time-example-v2/",
      "published_at": "2021-12-04T20:58:59Z",
      "updated_at": "2021-03-13T03:36:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser page load time (or response time) appears at the top right of the main chart of your Summary page. This value is labeled Browser and shows the average page load time in seconds. Average page load time To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_response_time&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.11131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &quot;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&quot; \\ -H &quot;X-<em>Api</em>-Key:${<em>API</em>_KEY}&quot; -i \\ -d &#x27;names[]=EndUser&amp;values[]=average_response_time&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf196a670c98960f55"
    }
  ],
  "/docs/apis/rest-api-v2/browser-examples-v2/average-browser-page-load-time-example-v2": [
    {
      "sections": [
        "Add or list browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-12-04T21:04:35Z",
      "updated_at": "2021-11-13T06:57:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, set up single page app monitoring via another method. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser applications > POST create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your browser-monitored apps, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by browser application ID: To view a specific browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.15024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "sections": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to add apps to <em>browser</em> monitoring or to get a list of your <em>browser</em> apps for a specific <em>API</em> key. This helps you manage deployment outside of New Relic One. These <em>API</em> calls are useful, for example, with larger organizations deploying"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "sections": [
        "Average browser (end user) page throughput example (v2)",
        "Average page throughput"
      ],
      "title": "Average browser (end user) page throughput example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "713534d353c7a66e7c02ec00f7d5340dab172740",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-end-user-page-throughput-example-v2/",
      "published_at": "2021-12-04T20:50:44Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser throughput appears at the top right of the Throughput by browser chart on your Summary page. This is the average pages per minute (PPM) by browser type in the time range shown on the chart. Average page throughput To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET 'https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json' \\ -H 'X-Api-Key:${API_KEY}' -i \\ -d 'names[]=EndUser&values[]=requests_per_minute&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.04218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " minutes), use the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&#x27; \\ -H &#x27;X-<em>Api</em>-Key:${<em>API</em>_KEY}&#x27; -i \\ -d &#x27;names[]=EndUser&amp;values[]=requests_per_minute&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf28ccbc10652c6091"
    },
    {
      "sections": [
        "Obtaining browser (end user) page load time data (v2)",
        "General API values",
        "Network time",
        "Page rendering time",
        "DOM processing time",
        "Web application time",
        "Request queuing time"
      ],
      "title": "Obtaining browser (end user) page load time data (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "c0c497cf900d84a9e57a07aba5062003e86506a8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/obtaining-browser-end-user-page-load-time-data-v2/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-07-09T14:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The metric timeslice data presented on the Browser page load time chart on your application's Summary page will depend on your web app's configuration. Possible components may include: Network time Page rendering time DOM processing time Web application time Request queuing time This describes how to use the New Relic REST API (v2) to obtain the data shown on the Browser page load time chart. General API values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these examples. For calculated values, the time range you specify must be consistent in all of the queries; otherwise the final calculations will be incorrect. You must replace the ${APPID} and ${API_KEY} variables in these examples with your specific application ID and corresponding REST API key. Ensure you adjust the time units returned by the API requests as needed. Network time The EndUser:average_network_time is the network latency, or time it takes for a request to make a round trip over the Internet. Use the following command to obtain this. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_network_time' Copy This time is returned in milliseconds. Page rendering time Page rendering time is a derived value. To calculate it, use this equation: \"Page rendering\" time = EndUser:average_fe_response_time - EndUser/RB:average_dom_content_load_time Copy To obtain the data for this calculation, use the following commands. EndUser:average_fe_response_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_fe_response_time' Copy This time is returned in milliseconds. EndUser/RB:average_dom_content_load_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. DOM processing time The EndUser/RB:average_dom_content_load_time is the time spent in the browser to parse and interpret the HTML. This is measured by the browser's DOM Content event. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_dom_content_load_time' Copy This time is returned in milliseconds. Web application time The Web application time is the time spent in the application code. To calculate this value, use this equation: Web application = EndUser:total_app_time / EndUser:call_count Copy To obtain the data for this calculation, use the following commands. EndUser:total_app_time curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=total_app_time' Copy This time is returned in seconds. EndUser:call_count curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=call_count' Copy Request queuing time The EndUser/RB:average_queue_time is the wait time between the web server and the application code. Large numbers indicate a busy application server. To obtain this data, use the following command: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser/RB&values[]=average_queue_time' Copy This time is returned in milliseconds. The request queuing time is not included in the calculation of averages. New Relic includes it in this chart as a convenience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.41304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "sections": "Obtaining <em>browser</em> (end user) page load time data (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the data shown on the <em>Browser</em> page load time chart. General <em>API</em> values When making your own calculations, be aware of the following: You can change the default time range (30 minutes) used in these <em>examples</em>. For calculated values, the time range you"
      },
      "id": "6044070de7b9d2b9f7579a16"
    }
  ],
  "/docs/apis/rest-api-v2/browser-examples-v2/obtaining-browser-end-user-page-load-time-data-v2": [
    {
      "sections": [
        "Add or list browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-12-04T21:04:35Z",
      "updated_at": "2021-11-13T06:57:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, set up single page app monitoring via another method. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser applications > POST create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your browser-monitored apps, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by browser application ID: To view a specific browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.15024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "sections": "Add or list <em>browser</em> apps <em>via</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": "Here are <em>examples</em> of how to use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to add apps to <em>browser</em> monitoring or to get a list of your <em>browser</em> apps for a specific <em>API</em> key. This helps you manage deployment outside of New Relic One. These <em>API</em> calls are useful, for example, with larger organizations deploying"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "sections": [
        "Average browser (end user) page throughput example (v2)",
        "Average page throughput"
      ],
      "title": "Average browser (end user) page throughput example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "713534d353c7a66e7c02ec00f7d5340dab172740",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-end-user-page-throughput-example-v2/",
      "published_at": "2021-12-04T20:50:44Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser throughput appears at the top right of the Throughput by browser chart on your Summary page. This is the average pages per minute (PPM) by browser type in the time range shown on the chart. Average page throughput To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET 'https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json' \\ -H 'X-Api-Key:${API_KEY}' -i \\ -d 'names[]=EndUser&values[]=requests_per_minute&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.04218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> (end user) page throughput <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " minutes), use the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&#x27; \\ -H &#x27;X-<em>Api</em>-Key:${<em>API</em>_KEY}&#x27; -i \\ -d &#x27;names[]=EndUser&amp;values[]=requests_per_minute&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf28ccbc10652c6091"
    },
    {
      "sections": [
        "Average browser page load time example (v2)",
        "Average page load time"
      ],
      "title": "Average browser page load time example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "2e2669a368831880e962cdbd39d95d31a98aa253",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/average-browser-page-load-time-example-v2/",
      "published_at": "2021-12-04T20:58:59Z",
      "updated_at": "2021-03-13T03:36:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The average browser page load time (or response time) appears at the top right of the main chart of your Summary page. This value is labeled Browser and shows the average page load time in seconds. Average page load time To obtain the average for the time range (default is last 30 minutes), use the following command. Be sure to replace the ${APP_ID} and ${API_KEY} variables in this example with your specific application ID and REST API key. curl -X GET \"https://api.newrelic.com/v2/applications/${APP_ID}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=EndUser&values[]=average_response_time&summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.11131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "sections": "Average <em>browser</em> page load time <em>example</em> (<em>v2</em>)",
        "tags": "<em>Browser</em> <em>examples</em> (<em>v2</em>)",
        "body": " the following command. Be sure to replace the ${APP_ID} and ${<em>API</em>_KEY} variables in this example with your specific application ID and <em>REST</em> <em>API</em> key. curl -X GET &quot;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;${APP_ID}&#x2F;metrics&#x2F;data.json&quot; \\ -H &quot;X-<em>Api</em>-Key:${<em>API</em>_KEY}&quot; -i \\ -d &#x27;names[]=EndUser&amp;values[]=average_response_time&amp;summarize=true&#x27; Copy"
      },
      "id": "604406cf196a670c98960f55"
    }
  ],
  "/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships": [
    {
      "sections": [
        "Introduction to New Relic REST API (v2)",
        "Setup",
        "Tip",
        "URL",
        "API key $API_KEY",
        "Query details (PAYLOAD)",
        "Examples"
      ],
      "title": "Introduction to New Relic REST API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "97d12808fc706366121b8c005edc2320a0c7797b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-11-13T07:57:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST APIs let you retrieve data from, and push data to New Relic tools, and include configuration and delete capabilities. You can also use the API Explorer to understand the data available to you via the REST API, to obtain curl commands, and to see JSON responses. Setup The REST API command structure follows this template: curl -X GET <URL> -H \"Api-Key:$API_KEY\" -d '<PAYLOAD>' Copy The GET command could also be a POST or DELETE, depending on the query intent. To understand the placeholders, keep reading. Tip Our examples use curl as a common command line tool to pull metric timeslice data from the REST API. However, you can use any method to make your REST requests. The curl commands include target URLs, header information, and data which are relevant for any request mechanism. URL The API calls require a URL to specify the location from which the data will be accessed. You must replace the placeholder <URL> with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy The $APPID specifies the exact application or product for which the data is being requested. The information following this parameter will vary depending on the data request. If you have an EU region account, the URL is: api. eu .newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy Tip You can retrieve XML data instead of JSON by replacing .json with .xml. API key $API_KEY New Relic API calls require an API key. This may be one of several API keys: A user key: This is recommended. It's our latest key implementation and has fewer limitations than a REST API key. The user key is also used for our NerdGraph API. A REST API key: This is our older key implementation. For more information about it, see REST API key. If you use this key, the required header is X-Api-Key and not Api-Key. If you have a New Relic partnership account, you'll use a different key: see Partnership authentication. In our REST API examples, we borrow the API key placeholder $API_KEY from Unix shell programming. Be sure to replace that and other user-specific variables when forming calls. Query details (PAYLOAD) The < PAYLOAD> contains the query details, which define: The metric name you want to query and the value you want to retrieve The defined time range for retrieving metrics (Optional): The average of the metric timeslice data by using summarize Examples See the following docs for example REST API use cases: APM examples (how to retrieve metric timeslice data from APM) Browser examples (how to retrieve metric timeslice data from browser monitoring) Infrastructure alert examples Alerts examples (create alert conditions and configure notification channels, and more)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.82149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "sections": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". You must replace the placeholder &lt;URL&gt; with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;metrics&#x2F;data.json Copy The $APPID specifies the exact application or product"
      },
      "id": "604428f528ccbc84422c60ef"
    },
    {
      "sections": [
        "Get app and other IDs in New Relic One",
        "Find IDs using New Relic One",
        "APM: App ID",
        "Browser app ID",
        "Mobile app ID"
      ],
      "title": "Get app and other IDs in New Relic One",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "90dfb764139b1e4ad047635210a4ca7470293c8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/get-app-other-ids-new-relic-one/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using the New Relic REST API, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to get some of these IDs. You can also get a list of IDs using the REST API Explorer. Find IDs using New Relic One New Relic One includes the IDs of applications and some other components in a metadata panel. Click the icon next to the application name to open the metadata panel. Here are some examples: APM: App ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click APM and select an application. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Browser app ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click Browser and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Mobile app ID To locate the $MOBILE_ID from the New Relic UI: From one.newrelic.com, click Mobile and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $MOBILE_ID in your REST API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.08243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> app and other IDs in New Relic One",
        "sections": "<em>Get</em> app and other IDs in New Relic One",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "When using the New Relic <em>REST</em> <em>API</em>, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to <em>get</em> some of these IDs. You can also <em>get</em> a list of IDs using the <em>REST</em> <em>API</em> Explorer. Find"
      },
      "id": "603ed46c64441f70d44e8839"
    },
    {
      "sections": [
        "List application ID, host ID, instance ID",
        "Use the API Explorer",
        "List application IDs",
        "List host IDs",
        "Host ID and summary data using the REST API Explorer",
        "{HOST_ID} output",
        "List instance IDs",
        "Instance ID and summary data using the REST API Explorer",
        "{INSTANCE_ID} output",
        "Java instance ID (JVM) using the UI",
        "REST API application list example"
      ],
      "title": "List application ID, host ID, instance ID",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "87dd2a198e50edc8e78d7bb7c70ba724aff73053",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/list-application-id-host-id-instance-id/",
      "published_at": "2021-12-04T21:00:56Z",
      "updated_at": "2021-09-08T19:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM assigns IDs to entities related to an application. These are used to collect information about the operation and performance from different view points. These IDs can be returned via New Relic's REST API. The IDs may include: Application ID $APP_ID for each instrumented app Host ID $HOST_ID for each host Instance ID $INSTANCE_ID if there are multiple instances of the app To list any of these IDs in the New Relic API Explorer, you need an API key. Use the API Explorer You can use the API Explorer to return a list of all product IDs for a particular product: Go to one.newrelic.com > APM > (select an app). Go to the API Explorer at rpm.newrelic.com/api/explore, then select your account name from the Select an account dropdown. From the sidebar, select (product category) > GET List. Select Send Request. Browse the Response to locate the product ID. Use the product ID you located in your REST API calls. List application IDs Each app monitored by an APM agent is assigned a name. A unique $APP_ID is also associated with that name. The $APP_ID is fundamental for retrieving APM information about your apps. For more information about listing and using the $APP_ID, and obtaining the summary data, see Listing your app ID. List host IDs The $HOST_ID is used to get APM data for a specific host running an app. A physical server may have more than one host. For example, a web server program running on a physical server may be configured to have more than one virtual host. IDs for the host and physical server are not the same. Each host ID is unique and represents different items. Use the $HOST_ID to retrieve summary metrics for the host as well as specific metric timeslice values. For more information about available metrics: Go to rpm.newrelic.com. Go to the API Explorer, then select your account name from the Select an account dropdown. Go to the API Explorer's Application host page at rpm.newrelic.com/api/explore/application_hosts/names. Host ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $HOST_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the {HOST_ID} for each host. {HOST_ID} output The output will appear similar to this: { \"application_hosts\": [ { \"id\": 34966, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 13512 <---<<< {INSTANCE_ID} ], } }, { \"id\": 9999999, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { \". . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 186288 <---<<< {INSTANCE_ID} ], } }, . . . Copy List instance IDs The instance ID meaning depends on the New Relic language agent being used. You can list this ID from the REST API. For Java, you can also view the instance ID (JVM) from APM's Overview page. Agent Instance ID represents Go The Go program on the host reporting to the app name Java A Java Virtual Machine (JVM) .NET For New Relic's .NET Framework agent, this is the AppDomain Node.js A worker process PHP The daemon agent Ruby An individual Ruby worker process Python The master and worker processes You can retrieve summary metrics for the instance as well as specific metric timeslice values using the {INSTANCE_ID}. For details about available metrics, use the REST API Explorer Application Instance page. Instance ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $INSTANCE_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the $INSTANCE_ID for each instance. {INSTANCE_ID} output The { INSTANCE_ID} output will appear similar to this: { \"application_instances\": [ { \"id\": 35120, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 34966, <---<<< {HOST_ID} } }, { \"id\": 186288, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 186283, <---<<< {HOST_ID} } }, . . . Copy Java instance ID (JVM) using the UI Java apps: To locate a specific JVM $INSTANCE_ID in New Relic: Go to one.newrelic.com > APM > Applications > (select an app) > JVMs. Select the name of the instance. In the URL, the number after the _i designator represents the Java JVM instance: https://rpm.newrelic.com/accounts/$ACCOUNT_ID/applications/$APP_ID_i$INSTANCE_ID Copy REST API application list example The following example shows how to locate all the ID information for an application by using the APP_ID. If you have an EU account, the endpoint begins with https://api.eu.newrelic.com. curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[ids]=1441' <----<<<< {APP_ID} Copy The resulting example output is running on five servers. One server is hosting two virtual hosts for a total of six hosts. The output includes a links section listing the application_instances and application_hosts for the application. { \"applications\": [ { \"id\": 1441, <----<<<< {APP_ID} \"name\": \"RPM Combined Production\", \"language\": \"ruby\", \"health_status\": \"green\", \"reporting\": true, \"last_reported_at\": \"2015-11-10T23:19:47+00:00\", \"application_summary\": { . . . }, \"end_user_summary\": { . . . }, \"settings\": { . . . }, \"links\": { \"application_instances\": [ <---<<<< {INSTANCE_ID} list 21790, 24810, 27948, 35120, 35121, 35122, 186288, 247253, 247254, 247255, 247256 ], \"application_hosts\": [ <---<<<< {HOST_ID} list 21788, 24808, 34966, 186283, 247245, 286551 ] } } ], . . . Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.11252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Host ID and summary data using the <em>REST</em> <em>API</em> Explorer",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " for a particular application, you will need the $APP_ID. Go to the <em>API</em> Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X <em>GET</em> &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;hosts.json&#x27; \\ -H &#x27;<em>Api</em>-Key:$<em>API</em>_KEY&#x27; -i Copy"
      },
      "id": "60440c9628ccbc2de32c6078"
    }
  ],
  "/docs/apis/rest-api-v2/get-started/get-app-other-ids-new-relic-one": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.46004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Introduction to New Relic REST API (v2)",
        "Setup",
        "Tip",
        "URL",
        "API key $API_KEY",
        "Query details (PAYLOAD)",
        "Examples"
      ],
      "title": "Introduction to New Relic REST API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "97d12808fc706366121b8c005edc2320a0c7797b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-11-13T07:57:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST APIs let you retrieve data from, and push data to New Relic tools, and include configuration and delete capabilities. You can also use the API Explorer to understand the data available to you via the REST API, to obtain curl commands, and to see JSON responses. Setup The REST API command structure follows this template: curl -X GET <URL> -H \"Api-Key:$API_KEY\" -d '<PAYLOAD>' Copy The GET command could also be a POST or DELETE, depending on the query intent. To understand the placeholders, keep reading. Tip Our examples use curl as a common command line tool to pull metric timeslice data from the REST API. However, you can use any method to make your REST requests. The curl commands include target URLs, header information, and data which are relevant for any request mechanism. URL The API calls require a URL to specify the location from which the data will be accessed. You must replace the placeholder <URL> with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy The $APPID specifies the exact application or product for which the data is being requested. The information following this parameter will vary depending on the data request. If you have an EU region account, the URL is: api. eu .newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy Tip You can retrieve XML data instead of JSON by replacing .json with .xml. API key $API_KEY New Relic API calls require an API key. This may be one of several API keys: A user key: This is recommended. It's our latest key implementation and has fewer limitations than a REST API key. The user key is also used for our NerdGraph API. A REST API key: This is our older key implementation. For more information about it, see REST API key. If you use this key, the required header is X-Api-Key and not Api-Key. If you have a New Relic partnership account, you'll use a different key: see Partnership authentication. In our REST API examples, we borrow the API key placeholder $API_KEY from Unix shell programming. Be sure to replace that and other user-specific variables when forming calls. Query details (PAYLOAD) The < PAYLOAD> contains the query details, which define: The metric name you want to query and the value you want to retrieve The defined time range for retrieving metrics (Optional): The average of the metric timeslice data by using summarize Examples See the following docs for example REST API use cases: APM examples (how to retrieve metric timeslice data from APM) Browser examples (how to retrieve metric timeslice data from browser monitoring) Infrastructure alert examples Alerts examples (create alert conditions and configure notification channels, and more)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.82149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "sections": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". You must replace the placeholder &lt;URL&gt; with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;metrics&#x2F;data.json Copy The $APPID specifies the exact application or product"
      },
      "id": "604428f528ccbc84422c60ef"
    },
    {
      "sections": [
        "List application ID, host ID, instance ID",
        "Use the API Explorer",
        "List application IDs",
        "List host IDs",
        "Host ID and summary data using the REST API Explorer",
        "{HOST_ID} output",
        "List instance IDs",
        "Instance ID and summary data using the REST API Explorer",
        "{INSTANCE_ID} output",
        "Java instance ID (JVM) using the UI",
        "REST API application list example"
      ],
      "title": "List application ID, host ID, instance ID",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "87dd2a198e50edc8e78d7bb7c70ba724aff73053",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/list-application-id-host-id-instance-id/",
      "published_at": "2021-12-04T21:00:56Z",
      "updated_at": "2021-09-08T19:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM assigns IDs to entities related to an application. These are used to collect information about the operation and performance from different view points. These IDs can be returned via New Relic's REST API. The IDs may include: Application ID $APP_ID for each instrumented app Host ID $HOST_ID for each host Instance ID $INSTANCE_ID if there are multiple instances of the app To list any of these IDs in the New Relic API Explorer, you need an API key. Use the API Explorer You can use the API Explorer to return a list of all product IDs for a particular product: Go to one.newrelic.com > APM > (select an app). Go to the API Explorer at rpm.newrelic.com/api/explore, then select your account name from the Select an account dropdown. From the sidebar, select (product category) > GET List. Select Send Request. Browse the Response to locate the product ID. Use the product ID you located in your REST API calls. List application IDs Each app monitored by an APM agent is assigned a name. A unique $APP_ID is also associated with that name. The $APP_ID is fundamental for retrieving APM information about your apps. For more information about listing and using the $APP_ID, and obtaining the summary data, see Listing your app ID. List host IDs The $HOST_ID is used to get APM data for a specific host running an app. A physical server may have more than one host. For example, a web server program running on a physical server may be configured to have more than one virtual host. IDs for the host and physical server are not the same. Each host ID is unique and represents different items. Use the $HOST_ID to retrieve summary metrics for the host as well as specific metric timeslice values. For more information about available metrics: Go to rpm.newrelic.com. Go to the API Explorer, then select your account name from the Select an account dropdown. Go to the API Explorer's Application host page at rpm.newrelic.com/api/explore/application_hosts/names. Host ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $HOST_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the {HOST_ID} for each host. {HOST_ID} output The output will appear similar to this: { \"application_hosts\": [ { \"id\": 34966, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 13512 <---<<< {INSTANCE_ID} ], } }, { \"id\": 9999999, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { \". . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 186288 <---<<< {INSTANCE_ID} ], } }, . . . Copy List instance IDs The instance ID meaning depends on the New Relic language agent being used. You can list this ID from the REST API. For Java, you can also view the instance ID (JVM) from APM's Overview page. Agent Instance ID represents Go The Go program on the host reporting to the app name Java A Java Virtual Machine (JVM) .NET For New Relic's .NET Framework agent, this is the AppDomain Node.js A worker process PHP The daemon agent Ruby An individual Ruby worker process Python The master and worker processes You can retrieve summary metrics for the instance as well as specific metric timeslice values using the {INSTANCE_ID}. For details about available metrics, use the REST API Explorer Application Instance page. Instance ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $INSTANCE_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the $INSTANCE_ID for each instance. {INSTANCE_ID} output The { INSTANCE_ID} output will appear similar to this: { \"application_instances\": [ { \"id\": 35120, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 34966, <---<<< {HOST_ID} } }, { \"id\": 186288, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 186283, <---<<< {HOST_ID} } }, . . . Copy Java instance ID (JVM) using the UI Java apps: To locate a specific JVM $INSTANCE_ID in New Relic: Go to one.newrelic.com > APM > Applications > (select an app) > JVMs. Select the name of the instance. In the URL, the number after the _i designator represents the Java JVM instance: https://rpm.newrelic.com/accounts/$ACCOUNT_ID/applications/$APP_ID_i$INSTANCE_ID Copy REST API application list example The following example shows how to locate all the ID information for an application by using the APP_ID. If you have an EU account, the endpoint begins with https://api.eu.newrelic.com. curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[ids]=1441' <----<<<< {APP_ID} Copy The resulting example output is running on five servers. One server is hosting two virtual hosts for a total of six hosts. The output includes a links section listing the application_instances and application_hosts for the application. { \"applications\": [ { \"id\": 1441, <----<<<< {APP_ID} \"name\": \"RPM Combined Production\", \"language\": \"ruby\", \"health_status\": \"green\", \"reporting\": true, \"last_reported_at\": \"2015-11-10T23:19:47+00:00\", \"application_summary\": { . . . }, \"end_user_summary\": { . . . }, \"settings\": { . . . }, \"links\": { \"application_instances\": [ <---<<<< {INSTANCE_ID} list 21790, 24810, 27948, 35120, 35121, 35122, 186288, 247253, 247254, 247255, 247256 ], \"application_hosts\": [ <---<<<< {HOST_ID} list 21788, 24808, 34966, 186283, 247245, 286551 ] } } ], . . . Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.11252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Host ID and summary data using the <em>REST</em> <em>API</em> Explorer",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " for a particular application, you will need the $APP_ID. Go to the <em>API</em> Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X <em>GET</em> &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;hosts.json&#x27; \\ -H &#x27;<em>Api</em>-Key:$<em>API</em>_KEY&#x27; -i Copy"
      },
      "id": "60440c9628ccbc2de32c6078"
    }
  ],
  "/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.46002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get app and other IDs in New Relic One",
        "Find IDs using New Relic One",
        "APM: App ID",
        "Browser app ID",
        "Mobile app ID"
      ],
      "title": "Get app and other IDs in New Relic One",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "90dfb764139b1e4ad047635210a4ca7470293c8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/get-app-other-ids-new-relic-one/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using the New Relic REST API, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to get some of these IDs. You can also get a list of IDs using the REST API Explorer. Find IDs using New Relic One New Relic One includes the IDs of applications and some other components in a metadata panel. Click the icon next to the application name to open the metadata panel. Here are some examples: APM: App ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click APM and select an application. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Browser app ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click Browser and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Mobile app ID To locate the $MOBILE_ID from the New Relic UI: From one.newrelic.com, click Mobile and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $MOBILE_ID in your REST API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.08241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> app and other IDs in New Relic One",
        "sections": "<em>Get</em> app and other IDs in New Relic One",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "When using the New Relic <em>REST</em> <em>API</em>, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to <em>get</em> some of these IDs. You can also <em>get</em> a list of IDs using the <em>REST</em> <em>API</em> Explorer. Find"
      },
      "id": "603ed46c64441f70d44e8839"
    },
    {
      "sections": [
        "List application ID, host ID, instance ID",
        "Use the API Explorer",
        "List application IDs",
        "List host IDs",
        "Host ID and summary data using the REST API Explorer",
        "{HOST_ID} output",
        "List instance IDs",
        "Instance ID and summary data using the REST API Explorer",
        "{INSTANCE_ID} output",
        "Java instance ID (JVM) using the UI",
        "REST API application list example"
      ],
      "title": "List application ID, host ID, instance ID",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "87dd2a198e50edc8e78d7bb7c70ba724aff73053",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/list-application-id-host-id-instance-id/",
      "published_at": "2021-12-04T21:00:56Z",
      "updated_at": "2021-09-08T19:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM assigns IDs to entities related to an application. These are used to collect information about the operation and performance from different view points. These IDs can be returned via New Relic's REST API. The IDs may include: Application ID $APP_ID for each instrumented app Host ID $HOST_ID for each host Instance ID $INSTANCE_ID if there are multiple instances of the app To list any of these IDs in the New Relic API Explorer, you need an API key. Use the API Explorer You can use the API Explorer to return a list of all product IDs for a particular product: Go to one.newrelic.com > APM > (select an app). Go to the API Explorer at rpm.newrelic.com/api/explore, then select your account name from the Select an account dropdown. From the sidebar, select (product category) > GET List. Select Send Request. Browse the Response to locate the product ID. Use the product ID you located in your REST API calls. List application IDs Each app monitored by an APM agent is assigned a name. A unique $APP_ID is also associated with that name. The $APP_ID is fundamental for retrieving APM information about your apps. For more information about listing and using the $APP_ID, and obtaining the summary data, see Listing your app ID. List host IDs The $HOST_ID is used to get APM data for a specific host running an app. A physical server may have more than one host. For example, a web server program running on a physical server may be configured to have more than one virtual host. IDs for the host and physical server are not the same. Each host ID is unique and represents different items. Use the $HOST_ID to retrieve summary metrics for the host as well as specific metric timeslice values. For more information about available metrics: Go to rpm.newrelic.com. Go to the API Explorer, then select your account name from the Select an account dropdown. Go to the API Explorer's Application host page at rpm.newrelic.com/api/explore/application_hosts/names. Host ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $HOST_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the {HOST_ID} for each host. {HOST_ID} output The output will appear similar to this: { \"application_hosts\": [ { \"id\": 34966, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 13512 <---<<< {INSTANCE_ID} ], } }, { \"id\": 9999999, <---<<< {HOST_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { \". . . }, \"links\": { \"application\": 1234, <---<<< {APP_ID} \"application_instances\": [ 186288 <---<<< {INSTANCE_ID} ], } }, . . . Copy List instance IDs The instance ID meaning depends on the New Relic language agent being used. You can list this ID from the REST API. For Java, you can also view the instance ID (JVM) from APM's Overview page. Agent Instance ID represents Go The Go program on the host reporting to the app name Java A Java Virtual Machine (JVM) .NET For New Relic's .NET Framework agent, this is the AppDomain Node.js A worker process PHP The daemon agent Ruby An individual Ruby worker process Python The master and worker processes You can retrieve summary metrics for the instance as well as specific metric timeslice values using the {INSTANCE_ID}. For details about available metrics, use the REST API Explorer Application Instance page. Instance ID and summary data using the REST API Explorer To use the API Explorer to return a list of every $INSTANCE_ID for a particular application, you will need the $APP_ID. Go to the API Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X GET 'https://api.newrelic.com/v2/applications/$APP_ID/hosts.json' \\ -H 'Api-Key:$API_KEY' -i Copy If you have an EU region account, the endpoint begins with https://api.eu.newrelic.com. Select Send Request. Browse the Response to locate the $INSTANCE_ID for each instance. {INSTANCE_ID} output The { INSTANCE_ID} output will appear similar to this: { \"application_instances\": [ { \"id\": 35120, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-10.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 34966, <---<<< {HOST_ID} } }, { \"id\": 186288, <---<<< {INSTANCE_ID} \"application_name\": \"Combined Production\", \"host\": \"prod-app-11.com\", \"language\": \"ruby\", \"health_status\": \"green\", \"application_summary\": { . . . }, \"links\": { \"application\": 1441, <---<<< {APP_ID} \"application_host\": 186283, <---<<< {HOST_ID} } }, . . . Copy Java instance ID (JVM) using the UI Java apps: To locate a specific JVM $INSTANCE_ID in New Relic: Go to one.newrelic.com > APM > Applications > (select an app) > JVMs. Select the name of the instance. In the URL, the number after the _i designator represents the Java JVM instance: https://rpm.newrelic.com/accounts/$ACCOUNT_ID/applications/$APP_ID_i$INSTANCE_ID Copy REST API application list example The following example shows how to locate all the ID information for an application by using the APP_ID. If you have an EU account, the endpoint begins with https://api.eu.newrelic.com. curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[ids]=1441' <----<<<< {APP_ID} Copy The resulting example output is running on five servers. One server is hosting two virtual hosts for a total of six hosts. The output includes a links section listing the application_instances and application_hosts for the application. { \"applications\": [ { \"id\": 1441, <----<<<< {APP_ID} \"name\": \"RPM Combined Production\", \"language\": \"ruby\", \"health_status\": \"green\", \"reporting\": true, \"last_reported_at\": \"2015-11-10T23:19:47+00:00\", \"application_summary\": { . . . }, \"end_user_summary\": { . . . }, \"settings\": { . . . }, \"links\": { \"application_instances\": [ <---<<<< {INSTANCE_ID} list 21790, 24810, 27948, 35120, 35121, 35122, 186288, 247253, 247254, 247255, 247256 ], \"application_hosts\": [ <---<<<< {HOST_ID} list 21788, 24808, 34966, 186283, 247245, 286551 ] } } ], . . . Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.11252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Host ID and summary data using the <em>REST</em> <em>API</em> Explorer",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": " for a particular application, you will need the $APP_ID. Go to the <em>API</em> Explorer, then select your account name from the Select an account dropdown. Enter the specific $APP_ID in the following command: curl -X <em>GET</em> &#x27;https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;hosts.json&#x27; \\ -H &#x27;<em>Api</em>-Key:$<em>API</em>_KEY&#x27; -i Copy"
      },
      "id": "60440c9628ccbc2de32c6078"
    }
  ],
  "/docs/apis/rest-api-v2/get-started/list-application-id-host-id-instance-id": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.46002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Introduction to New Relic REST API (v2)",
        "Setup",
        "Tip",
        "URL",
        "API key $API_KEY",
        "Query details (PAYLOAD)",
        "Examples"
      ],
      "title": "Introduction to New Relic REST API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "97d12808fc706366121b8c005edc2320a0c7797b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-11-13T07:57:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST APIs let you retrieve data from, and push data to New Relic tools, and include configuration and delete capabilities. You can also use the API Explorer to understand the data available to you via the REST API, to obtain curl commands, and to see JSON responses. Setup The REST API command structure follows this template: curl -X GET <URL> -H \"Api-Key:$API_KEY\" -d '<PAYLOAD>' Copy The GET command could also be a POST or DELETE, depending on the query intent. To understand the placeholders, keep reading. Tip Our examples use curl as a common command line tool to pull metric timeslice data from the REST API. However, you can use any method to make your REST requests. The curl commands include target URLs, header information, and data which are relevant for any request mechanism. URL The API calls require a URL to specify the location from which the data will be accessed. You must replace the placeholder <URL> with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy The $APPID specifies the exact application or product for which the data is being requested. The information following this parameter will vary depending on the data request. If you have an EU region account, the URL is: api. eu .newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy Tip You can retrieve XML data instead of JSON by replacing .json with .xml. API key $API_KEY New Relic API calls require an API key. This may be one of several API keys: A user key: This is recommended. It's our latest key implementation and has fewer limitations than a REST API key. The user key is also used for our NerdGraph API. A REST API key: This is our older key implementation. For more information about it, see REST API key. If you use this key, the required header is X-Api-Key and not Api-Key. If you have a New Relic partnership account, you'll use a different key: see Partnership authentication. In our REST API examples, we borrow the API key placeholder $API_KEY from Unix shell programming. Be sure to replace that and other user-specific variables when forming calls. Query details (PAYLOAD) The < PAYLOAD> contains the query details, which define: The metric name you want to query and the value you want to retrieve The defined time range for retrieving metrics (Optional): The average of the metric timeslice data by using summarize Examples See the following docs for example REST API use cases: APM examples (how to retrieve metric timeslice data from APM) Browser examples (how to retrieve metric timeslice data from browser monitoring) Infrastructure alert examples Alerts examples (create alert conditions and configure notification channels, and more)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.82147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "sections": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". You must replace the placeholder &lt;URL&gt; with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;metrics&#x2F;data.json Copy The $APPID specifies the exact application or product"
      },
      "id": "604428f528ccbc84422c60ef"
    },
    {
      "sections": [
        "Get app and other IDs in New Relic One",
        "Find IDs using New Relic One",
        "APM: App ID",
        "Browser app ID",
        "Mobile app ID"
      ],
      "title": "Get app and other IDs in New Relic One",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "90dfb764139b1e4ad047635210a4ca7470293c8a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/get-app-other-ids-new-relic-one/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using the New Relic REST API, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to get some of these IDs. You can also get a list of IDs using the REST API Explorer. Find IDs using New Relic One New Relic One includes the IDs of applications and some other components in a metadata panel. Click the icon next to the application name to open the metadata panel. Here are some examples: APM: App ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click APM and select an application. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Browser app ID To locate the $APP_ID from the New Relic UI: From one.newrelic.com, click Browser and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $APP_ID in your REST API calls. Mobile app ID To locate the $MOBILE_ID from the New Relic UI: From one.newrelic.com, click Mobile and select a monitored app. Click the icon next to the application name to open the metadata panel. Locate the App ID. Substitute this number for the $MOBILE_ID in your REST API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.08241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> app and other IDs in New Relic One",
        "sections": "<em>Get</em> app and other IDs in New Relic One",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "When using the New Relic <em>REST</em> <em>API</em>, you need to replace some ID placeholders (like $APP_ID, $KEYTX_ID, $COMPONENT_ID, etc.) with the ID for an app, transaction, or other component. You can use New Relic One to <em>get</em> some of these IDs. You can also <em>get</em> a list of IDs using the <em>REST</em> <em>API</em> Explorer. Find"
      },
      "id": "603ed46c64441f70d44e8839"
    }
  ],
  "/docs/apis/rest-api-v2/labels-examples-v2/create-labels-apps-v2": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.69815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Introduction to New Relic REST API (v2)",
        "Setup",
        "Tip",
        "URL",
        "API key $API_KEY",
        "Query details (PAYLOAD)",
        "Examples"
      ],
      "title": "Introduction to New Relic REST API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "97d12808fc706366121b8c005edc2320a0c7797b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-11-13T07:57:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST APIs let you retrieve data from, and push data to New Relic tools, and include configuration and delete capabilities. You can also use the API Explorer to understand the data available to you via the REST API, to obtain curl commands, and to see JSON responses. Setup The REST API command structure follows this template: curl -X GET <URL> -H \"Api-Key:$API_KEY\" -d '<PAYLOAD>' Copy The GET command could also be a POST or DELETE, depending on the query intent. To understand the placeholders, keep reading. Tip Our examples use curl as a common command line tool to pull metric timeslice data from the REST API. However, you can use any method to make your REST requests. The curl commands include target URLs, header information, and data which are relevant for any request mechanism. URL The API calls require a URL to specify the location from which the data will be accessed. You must replace the placeholder <URL> with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy The $APPID specifies the exact application or product for which the data is being requested. The information following this parameter will vary depending on the data request. If you have an EU region account, the URL is: api. eu .newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy Tip You can retrieve XML data instead of JSON by replacing .json with .xml. API key $API_KEY New Relic API calls require an API key. This may be one of several API keys: A user key: This is recommended. It's our latest key implementation and has fewer limitations than a REST API key. The user key is also used for our NerdGraph API. A REST API key: This is our older key implementation. For more information about it, see REST API key. If you use this key, the required header is X-Api-Key and not Api-Key. If you have a New Relic partnership account, you'll use a different key: see Partnership authentication. In our REST API examples, we borrow the API key placeholder $API_KEY from Unix shell programming. Be sure to replace that and other user-specific variables when forming calls. Query details (PAYLOAD) The < PAYLOAD> contains the query details, which define: The metric name you want to query and the value you want to retrieve The defined time range for retrieving metrics (Optional): The average of the metric timeslice data by using summarize Examples See the following docs for example REST API use cases: APM examples (how to retrieve metric timeslice data from APM) Browser examples (how to retrieve metric timeslice data from browser monitoring) Infrastructure alert examples Alerts examples (create alert conditions and configure notification channels, and more)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.85635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "sections": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". You must replace the placeholder &lt;URL&gt; with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;metrics&#x2F;data.json Copy The $APPID specifies the exact application or product"
      },
      "id": "604428f528ccbc84422c60ef"
    }
  ],
  "/docs/apis/rest-api-v2/mobile-examples-v2/mobile-crash-count-crash-rate-example-v2": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.69815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Introduction to New Relic REST API (v2)",
        "Setup",
        "Tip",
        "URL",
        "API key $API_KEY",
        "Query details (PAYLOAD)",
        "Examples"
      ],
      "title": "Introduction to New Relic REST API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "97d12808fc706366121b8c005edc2320a0c7797b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/introduction-new-relic-rest-api-v2/",
      "published_at": "2021-12-04T15:39:04Z",
      "updated_at": "2021-11-13T07:57:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST APIs let you retrieve data from, and push data to New Relic tools, and include configuration and delete capabilities. You can also use the API Explorer to understand the data available to you via the REST API, to obtain curl commands, and to see JSON responses. Setup The REST API command structure follows this template: curl -X GET <URL> -H \"Api-Key:$API_KEY\" -d '<PAYLOAD>' Copy The GET command could also be a POST or DELETE, depending on the query intent. To understand the placeholders, keep reading. Tip Our examples use curl as a common command line tool to pull metric timeslice data from the REST API. However, you can use any method to make your REST requests. The curl commands include target URLs, header information, and data which are relevant for any request mechanism. URL The API calls require a URL to specify the location from which the data will be accessed. You must replace the placeholder <URL> with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy The $APPID specifies the exact application or product for which the data is being requested. The information following this parameter will vary depending on the data request. If you have an EU region account, the URL is: api. eu .newrelic.com/v2/applications/$APP_ID/metrics/data.json Copy Tip You can retrieve XML data instead of JSON by replacing .json with .xml. API key $API_KEY New Relic API calls require an API key. This may be one of several API keys: A user key: This is recommended. It's our latest key implementation and has fewer limitations than a REST API key. The user key is also used for our NerdGraph API. A REST API key: This is our older key implementation. For more information about it, see REST API key. If you use this key, the required header is X-Api-Key and not Api-Key. If you have a New Relic partnership account, you'll use a different key: see Partnership authentication. In our REST API examples, we borrow the API key placeholder $API_KEY from Unix shell programming. Be sure to replace that and other user-specific variables when forming calls. Query details (PAYLOAD) The < PAYLOAD> contains the query details, which define: The metric name you want to query and the value you want to retrieve The defined time range for retrieving metrics (Optional): The average of the metric timeslice data by using summarize Examples See the following docs for example REST API use cases: APM examples (how to retrieve metric timeslice data from APM) Browser examples (how to retrieve metric timeslice data from browser monitoring) Infrastructure alert examples Alerts examples (create alert conditions and configure notification channels, and more)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.85635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "sections": "Introduction to New Relic <em>REST</em> <em>API</em> (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": ". You must replace the placeholder &lt;URL&gt; with the appropriate URL which will change depending on the type of data being requested. In general the URL follows this template: https:&#x2F;&#x2F;<em>api</em>.newrelic.com&#x2F;<em>v2</em>&#x2F;applications&#x2F;$APP_ID&#x2F;metrics&#x2F;data.json Copy The $APPID specifies the exact application or product"
      },
      "id": "604428f528ccbc84422c60ef"
    }
  ],
  "/docs/apis/rest-api-v2/troubleshooting/301-response-rest-api-calls": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.17769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Mobile crash count and crash rate example (v2)",
        "Tip",
        "Prerequisites",
        "Mobile app: Get crash data",
        "Mobile app version: Get crash count data",
        "Mobile app version: Get crash rate data",
        "Find the mobile app version ID",
        "Important"
      ],
      "title": "Mobile crash count and crash rate example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Mobile examples (v2)"
      ],
      "external_id": "151eef499250bd2a444ed8c49b610772d7c7e56e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/mobile-examples-v2/mobile-crash-count-crash-rate-example-v2/",
      "published_at": "2021-12-04T15:39:40Z",
      "updated_at": "2021-07-09T14:37:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes how to use the New Relic REST API (v2) to get your mobile application's overall and version-specific crash count and crash rate, which appear on the Summary page in the upper right corner. These examples use the default time period of the last 30 minutes. To obtain crash data for a different time range, add the time period to the commands. Tip You can also use the New Relic API Explorer to retrieve mobile metric data. Prerequisites To use the API in these examples, you need: Your New Relic REST API key Your New Relic mobile monitoring app ID or your mobile monitoring app version ID. To find the mobile monitoring app ID, see Finding the product ID: mobile monitoring. To find the mobile monitoring app version ID, see Find the mobile app version ID below. Mobile app: Get crash data To obtain crash count and crash rate data for the overall mobile application, use the mobile application ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_ID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy The crash_summary output data contains both the crash_count and crash_rate. \"crash_summary\": { \"supports_crash_data\": true, \"unresolved_crash_count\": 14, \"crash_rate\": 28.155339805825243 } Copy To obtain crash summary data for all the mobile applications in the account, use this REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy Mobile app version: Get crash count data To obtain the crash count metric data for a specific version of the mobile application, include the mobile application version ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'name=Mobile/Crash/All&values[]=call_count&summarize=true' Copy Mobile app version: Get crash rate data To calculate a specific version's crash rate, use the following equation: Crash Rate = (Mobile/Crash/All:call_count) / (Session/Start:call_count) Copy To get the two metric values needed in the equation, use the following REST API command with the mobile application version ID . curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=Mobile/Crash/All&names[]=Session/Start&values[]=call_count&summarize=true' Copy Find the mobile app version ID Important You must provide the version ID only when you want to obtain crash data for a specific version. To find the version ID of your mobile application, run the following NRQL query: SELECT count(*) from Mobile where appName='YOUR_APP_NAME' facet appVersionId since 1 day ago export const _frontmatter = {\"title\":\"Mobile crash count and crash rate example (v2)\",\"tags\":[\"APIs\",\"REST API v2\",\"Mobile examples (v2)\"],\"metaDescription\":\"How to use New Relic's REST API (v2) to get crash count and crash rate data for the overall mobile app or a specific version.\",\"redirects\":[\"/docs/apis/rest-api-v2/application-examples-v2/mobile-crash-count-crash-rate-example-v2\"]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile crash count and crash rate example (<em>v2</em>)",
        "sections": "Mobile crash count and crash rate example (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "&#x27; facet appVersionId since 1 day ago export const _frontmatter = {&quot;title&quot;:&quot;Mobile crash count and crash rate example (<em>v2</em>)&quot;,&quot;tags&quot;:[&quot;<em>APIs</em>&quot;,&quot;<em>REST</em> <em>API</em> <em>v2</em>&quot;,&quot;Mobile examples (<em>v2</em>)&quot;],&quot;metaDescription&quot;:&quot;How to use New Relic&#x27;s <em>REST</em> <em>API</em> (<em>v2</em>) to get crash count and crash rate data for the overall mobile app or a specific version.&quot;,&quot;redirects&quot;:[&quot;&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>rest</em>-<em>api</em>-<em>v2</em>&#x2F;application-examples-<em>v2</em>&#x2F;mobile-crash-count-crash-rate-example-<em>v2</em>&quot;]} Copy"
      },
      "id": "60440c9628ccbc04a23021ec"
    }
  ],
  "/docs/apis/rest-api-v2/troubleshooting/500-error-when-starting-api-explorer": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.17769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Mobile crash count and crash rate example (v2)",
        "Tip",
        "Prerequisites",
        "Mobile app: Get crash data",
        "Mobile app version: Get crash count data",
        "Mobile app version: Get crash rate data",
        "Find the mobile app version ID",
        "Important"
      ],
      "title": "Mobile crash count and crash rate example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Mobile examples (v2)"
      ],
      "external_id": "151eef499250bd2a444ed8c49b610772d7c7e56e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/mobile-examples-v2/mobile-crash-count-crash-rate-example-v2/",
      "published_at": "2021-12-04T15:39:40Z",
      "updated_at": "2021-07-09T14:37:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes how to use the New Relic REST API (v2) to get your mobile application's overall and version-specific crash count and crash rate, which appear on the Summary page in the upper right corner. These examples use the default time period of the last 30 minutes. To obtain crash data for a different time range, add the time period to the commands. Tip You can also use the New Relic API Explorer to retrieve mobile metric data. Prerequisites To use the API in these examples, you need: Your New Relic REST API key Your New Relic mobile monitoring app ID or your mobile monitoring app version ID. To find the mobile monitoring app ID, see Finding the product ID: mobile monitoring. To find the mobile monitoring app version ID, see Find the mobile app version ID below. Mobile app: Get crash data To obtain crash count and crash rate data for the overall mobile application, use the mobile application ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_ID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy The crash_summary output data contains both the crash_count and crash_rate. \"crash_summary\": { \"supports_crash_data\": true, \"unresolved_crash_count\": 14, \"crash_rate\": 28.155339805825243 } Copy To obtain crash summary data for all the mobile applications in the account, use this REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy Mobile app version: Get crash count data To obtain the crash count metric data for a specific version of the mobile application, include the mobile application version ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'name=Mobile/Crash/All&values[]=call_count&summarize=true' Copy Mobile app version: Get crash rate data To calculate a specific version's crash rate, use the following equation: Crash Rate = (Mobile/Crash/All:call_count) / (Session/Start:call_count) Copy To get the two metric values needed in the equation, use the following REST API command with the mobile application version ID . curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=Mobile/Crash/All&names[]=Session/Start&values[]=call_count&summarize=true' Copy Find the mobile app version ID Important You must provide the version ID only when you want to obtain crash data for a specific version. To find the version ID of your mobile application, run the following NRQL query: SELECT count(*) from Mobile where appName='YOUR_APP_NAME' facet appVersionId since 1 day ago export const _frontmatter = {\"title\":\"Mobile crash count and crash rate example (v2)\",\"tags\":[\"APIs\",\"REST API v2\",\"Mobile examples (v2)\"],\"metaDescription\":\"How to use New Relic's REST API (v2) to get crash count and crash rate data for the overall mobile app or a specific version.\",\"redirects\":[\"/docs/apis/rest-api-v2/application-examples-v2/mobile-crash-count-crash-rate-example-v2\"]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile crash count and crash rate example (<em>v2</em>)",
        "sections": "Mobile crash count and crash rate example (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "&#x27; facet appVersionId since 1 day ago export const _frontmatter = {&quot;title&quot;:&quot;Mobile crash count and crash rate example (<em>v2</em>)&quot;,&quot;tags&quot;:[&quot;<em>APIs</em>&quot;,&quot;<em>REST</em> <em>API</em> <em>v2</em>&quot;,&quot;Mobile examples (<em>v2</em>)&quot;],&quot;metaDescription&quot;:&quot;How to use New Relic&#x27;s <em>REST</em> <em>API</em> (<em>v2</em>) to get crash count and crash rate data for the overall mobile app or a specific version.&quot;,&quot;redirects&quot;:[&quot;&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>rest</em>-<em>api</em>-<em>v2</em>&#x2F;application-examples-<em>v2</em>&#x2F;mobile-crash-count-crash-rate-example-<em>v2</em>&quot;]} Copy"
      },
      "id": "60440c9628ccbc04a23021ec"
    }
  ],
  "/docs/apis/rest-api-v2/troubleshooting/http-200-status-api-explorer": [
    {
      "sections": [
        "New Relic partnership account authentication",
        "Custom headers and API calls",
        "Known limitations"
      ],
      "title": "New Relic partnership account authentication",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Get started"
      ],
      "external_id": "a4e139380383b634e44d288b7065597de60e6b84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/get-started/admin-users-api-key-partnerships/",
      "published_at": "2021-12-04T15:38:24Z",
      "updated_at": "2021-10-31T04:03:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This approach adds a new authentication method to the customer-facing New Relic REST API (v2) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all REST API (v2) calls. It offers no new functionality for non-partner API users. When calling endpoints in the New Relic REST API (v2) that require the user key, New Relic suggests you use the described authentication method. Custom headers and API calls When making API calls, use the following custom headers with your partner API key, partner ID, and your account ID: X-Api-Key:YOUR_PARTNER_ACCOUNT_API_KEY NewRelic-Partner-Id:YOUR_PARTNER_ID NewRelic-Account-Id:YOUR_CUSTOMERS_ACCOUNT_ID Providing authentication to the REST API (v2) in this form allows you to complete any API operation on your customer’s accounts. This bypasses the customer-facing requirement that some API calls require an Admin user’s API key. This authentication method also works for API endpoints that require only the REST API key. This new authentication method works for all endpoints, not only those that require the Admin User’s API key. Known limitations This partner-only authentication method will only work with the New Relic REST API (v2). It does not work with the following: Deployment API Infrastructure API for alerts Insights API Insights Dashboard API Partner API Synthetics API",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.65692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Custom headers and <em>API</em> calls",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "This approach adds a new authentication method to the customer-facing New Relic <em>REST</em> <em>API</em> (<em>v2</em>) that allows partners (and enterprise-scale customers that use the partnership structure to manage their multiple accounts) to use their partnership credentials to authorize all <em>REST</em> <em>API</em> (<em>v2</em>) calls"
      },
      "id": "60440747e7b9d2a1465799f2"
    },
    {
      "sections": [
        "Get average throughput for an app (v2)",
        "Web app throughput",
        "Web app throughput (single host)",
        "Non-web app throughput",
        "Non-web app throughput (single host)"
      ],
      "title": "Get average throughput for an app (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Application examples (v2)"
      ],
      "external_id": "69213d0faede1c54abe3ab51a41b506fd27427bc",
      "image": "https://docs.newrelic.com/static/8f3717e1b97fa8027a5db9ecca408b7f/6c1e7/Web_app_throughput.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/application-examples-v2/get-average-throughput-app-v2/",
      "published_at": "2021-12-04T20:55:56Z",
      "updated_at": "2021-10-31T03:58:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic REST API (v2) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app's APM Summary page: Go to one.newrelic.com > APM > (select an app). Click the app's Transaction time chart title, then select your choice. Web app throughput To find the average web application throughput value for a time period, use a single command to get the metric HttpDispatcher:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range, include from and to values. To keep the default time period of the last 30 minutes, omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Web app throughput (single host) To find the average throughput from a single host, for a given time period, use a single command to get the metric HttpDispatcher:requests_per_minute, and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=HttpDispatcher&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy Non-web app throughput To find the average non-web application throughput value for a given time period, use a single command to get the metric OtherTransaction/all:requests_per_minute. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=OtherTransaction/all&values[]=requests_per_minute&;from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&summarize=true' Copy Be sure to replace $ { APPID} and $ { APIKEY} with your application ID and API key for the account. To change the time range (as shown in this example), include from and to values. To keep the default time period (last 30 minutes), omit the from and to values. To return a series of throughput values instead of an average, omit summarize. Here is an example of the Throughput chart for a non-web app on the APM Summary page. You can use the New Relic REST API (v2) to return the average Throughput value that appears here. Non-web app throughput (single host) To obtain the average throughput for a non-web app from a single host, for a given time period, use a single command to obtain the metric OtherTransaction:requests_per_minute and specify the numeric $ { HOST}. To identify the host, use the UI or the REST API. This example shows the time range for a specific 24 hour period. curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/hosts/${HOST}/metrics/data.json\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\     -d 'names[]=OtherTransaction/all&:values[]=requests_per_minute&from=2014-02-21T23:59:00+00:00&to=2014-02-22T23:59:00+00:00&:summarize=true' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.17769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get average throughput for an app (<em>v2</em>)",
        "sections": "Get average throughput for an app (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "You can use the New Relic <em>REST</em> <em>API</em> (<em>v2</em>) to obtain the average throughput for your app, including web application and non-web application throughput. These values appear in the Throughput chart on your app&#x27;s APM Summary page: Go to one.newrelic.com &gt; APM &gt; (select an app). Click the app"
      },
      "id": "603ec9ba28ccbccf81eba797"
    },
    {
      "sections": [
        "Mobile crash count and crash rate example (v2)",
        "Tip",
        "Prerequisites",
        "Mobile app: Get crash data",
        "Mobile app version: Get crash count data",
        "Mobile app version: Get crash rate data",
        "Find the mobile app version ID",
        "Important"
      ],
      "title": "Mobile crash count and crash rate example (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Mobile examples (v2)"
      ],
      "external_id": "151eef499250bd2a444ed8c49b610772d7c7e56e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/mobile-examples-v2/mobile-crash-count-crash-rate-example-v2/",
      "published_at": "2021-12-04T15:39:40Z",
      "updated_at": "2021-07-09T14:37:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes how to use the New Relic REST API (v2) to get your mobile application's overall and version-specific crash count and crash rate, which appear on the Summary page in the upper right corner. These examples use the default time period of the last 30 minutes. To obtain crash data for a different time range, add the time period to the commands. Tip You can also use the New Relic API Explorer to retrieve mobile metric data. Prerequisites To use the API in these examples, you need: Your New Relic REST API key Your New Relic mobile monitoring app ID or your mobile monitoring app version ID. To find the mobile monitoring app ID, see Finding the product ID: mobile monitoring. To find the mobile monitoring app version ID, see Find the mobile app version ID below. Mobile app: Get crash data To obtain crash count and crash rate data for the overall mobile application, use the mobile application ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_ID}.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy The crash_summary output data contains both the crash_count and crash_rate. \"crash_summary\": { \"supports_crash_data\": true, \"unresolved_crash_count\": 14, \"crash_rate\": 28.155339805825243 } Copy To obtain crash summary data for all the mobile applications in the account, use this REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i Copy Mobile app version: Get crash count data To obtain the crash count metric data for a specific version of the mobile application, include the mobile application version ID in the following REST API command: curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'name=Mobile/Crash/All&values[]=call_count&summarize=true' Copy Mobile app version: Get crash rate data To calculate a specific version's crash rate, use the following equation: Crash Rate = (Mobile/Crash/All:call_count) / (Session/Start:call_count) Copy To get the two metric values needed in the equation, use the following REST API command with the mobile application version ID . curl -X GET \"https://api.newrelic.com/v2/mobile_applications/${MOBILE_APP_VERSION}/metrics/data.json\" \\ -H \"X-Api-Key:${API_KEY}\" -i \\ -d 'names[]=Mobile/Crash/All&names[]=Session/Start&values[]=call_count&summarize=true' Copy Find the mobile app version ID Important You must provide the version ID only when you want to obtain crash data for a specific version. To find the version ID of your mobile application, run the following NRQL query: SELECT count(*) from Mobile where appName='YOUR_APP_NAME' facet appVersionId since 1 day ago export const _frontmatter = {\"title\":\"Mobile crash count and crash rate example (v2)\",\"tags\":[\"APIs\",\"REST API v2\",\"Mobile examples (v2)\"],\"metaDescription\":\"How to use New Relic's REST API (v2) to get crash count and crash rate data for the overall mobile app or a specific version.\",\"redirects\":[\"/docs/apis/rest-api-v2/application-examples-v2/mobile-crash-count-crash-rate-example-v2\"]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile crash count and crash rate example (<em>v2</em>)",
        "sections": "Mobile crash count and crash rate example (<em>v2</em>)",
        "tags": "<em>REST</em> <em>API</em> <em>v2</em>",
        "body": "&#x27; facet appVersionId since 1 day ago export const _frontmatter = {&quot;title&quot;:&quot;Mobile crash count and crash rate example (<em>v2</em>)&quot;,&quot;tags&quot;:[&quot;<em>APIs</em>&quot;,&quot;<em>REST</em> <em>API</em> <em>v2</em>&quot;,&quot;Mobile examples (<em>v2</em>)&quot;],&quot;metaDescription&quot;:&quot;How to use New Relic&#x27;s <em>REST</em> <em>API</em> (<em>v2</em>) to get crash count and crash rate data for the overall mobile app or a specific version.&quot;,&quot;redirects&quot;:[&quot;&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>rest</em>-<em>api</em>-<em>v2</em>&#x2F;application-examples-<em>v2</em>&#x2F;mobile-crash-count-crash-rate-example-<em>v2</em>&quot;]} Copy"
      },
      "id": "60440c9628ccbc04a23021ec"
    }
  ],
  "/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api": [
    {
      "sections": [
        "Synthetics REST API version 1 (deprecated)",
        "Caution",
        "Managing simple and scripted monitors",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Delete an existing monitor",
        "Get list of valid locations",
        "Managing scripted monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Synthetics attributes",
        "Specific monitor endpoint"
      ],
      "title": "Synthetics REST API version 1 (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "38f3b7d441889cea39fa8a10d1593473bffa8cf7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1/",
      "published_at": "2021-12-05T05:20:51Z",
      "updated_at": "2021-10-31T10:08:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the Synthetics API: v1 and v3. Version 3 was released October 2016. Version 1 is deprecated and will eventually no longer be available. No termination date has been announced. However, no further development or modifications will be made to v1. Caution Recommendation: Create new monitors using the v3 Synthetics API and migrate v1 scripts to their v3 equivalent. To use the REST API for New Relic's synthetic monitoring, you must activate API access and generate your Admin User's API key from your account settings. Then you can make standard API calls via the command line. Managing simple and scripted monitors You must use your Admin User's API key to make Synthetics REST API calls. The account's REST API key will not work. Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. These examples show curl commands: Get all monitors To view a list of all monitors in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors. For example: curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"count\": integer, \"monitors\": [ { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } ] } Copy Get a specific monitor To view a single existing monitor in New Relic, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return the error 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your account in New Relic, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/monitors with a JSON payload that describes the monitor: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings (send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/locations to get a list of valid locations) [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, } Copy In addition, to add a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. Replace the Synthetics REST API attributes in the following example with your specific values. curl -v \\ -X POST -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. Replace the { id} in the following example with the specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} \\ -d '{ \"name\" : \"updated monitor name\", \"type\" : \"simple\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response, 404 Not Found: The specified monitor does not exist. Get list of valid locations To retrieve the list of valid locations in New Relic, use the following command. curl -v \\ -X GET -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/locations Copy Managing scripted monitors In addition to the general API, there are several API methods for the scripted browser (SCRIPT_BROWSER) and api test (SCRIPT_API) monitor types. These examples show curl commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script. Replace the { id} with the specific monitor ID. For example: curl -v -H 'X-Api-Key: {Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the ${MONITOR_UUID}/script endpoint. For more information, refer to the example. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script with a JSON payload that contains the scriptText (required). The scriptLocations data is required only for private locations with Verified Script Execution turned on. The password used to generate the HMAC string must match the password set for the private location. When generating the HMAC string, use the SHA256 algorithm. { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy Replace the { id} with the specific monitor ID. Here is an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation. curl -v -H 'X-Api-Key: '{Admin_User_Key}' -H 'content-type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4\"} ]}' Copy A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows curl commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example show the bash script that will create the SCRIPTED_BROWSER monitor. #!/bin/bash # Admin API key from your account settings adminAPIKey='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload='{\"scriptText\":\"'$encoded'\"}' curl -s -X PUT -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy Synthetics attributes Here are the attributes used with Synthetics REST API calls, listed in alphabetical order. Synthetics API attribute Definition apiVersion String: The version number. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific Synthetics monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected Synthetics monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.5856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "sections": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " the SCRIPTED_BROWSER <em>monitor</em>. #!&#x2F;bin&#x2F;bash # Admin <em>API</em> key from your account settings adminAPIKey=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>Type=&#x27;SCRIPT_BROWSER"
      },
      "id": "60452541e7b9d27829579a0a"
    },
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-12-04T21:26:42Z",
      "updated_at": "2021-10-31T04:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.38486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " <em>REST</em> <em>API</em> calls for a specific <em>monitor</em>, include the <em>monitor</em>_uuid as part of the endpoint. The <em>monitor</em>_uuid is the GUID which is part of the URL. For example, a selected synthetic <em>monitor</em> has this URL: https:&#x2F;&#x2F;<em>synthetics</em>.newrelic.com&#x2F;accounts&#x2F;nnnn&#x2F;monitors&#x2F;ab123-c456d-e78-90123-f45g Copy The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;."
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Use synthetic monitoring secure credentials APIs",
        "Requirements and rules",
        "API examples",
        "Add a secure credential",
        "Get all secure credentials",
        "Get a specific secure credential",
        "Update an existing secure credential",
        "Delete an existing secure credential"
      ],
      "title": "Use synthetic monitoring secure credentials APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Secure credentials examples"
      ],
      "external_id": "bd66e43160c1fd4c9f66bfdfa2d9a3223eb5d4d7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/secure-credentials-examples/use-synthetics-secure-credentials-apis/",
      "published_at": "2021-12-04T20:56:47Z",
      "updated_at": "2021-10-31T04:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Synthetics REST API, you can make API calls to change or retrieve secure credentials data. This document explains the API requirements and contains API curl command examples. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials. Requirements and rules For general rules about this feature, see the secure credentials requirements. API requirements and rules include: See general Synthetics REST API requirements. An account's rate of requests is limited to three requests per second. Requests that exceed this threshold will return a 429 response code. A key's value cannot be accessed via the API; an unauthorized user would not have access to the secure key values. API examples Add a secure credential To send a secure credential to your New Relic account, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials with a JSON payload that describes the secure credential. Here's an example: { \"key\": string [required, 1-64 characters uppercase], \"value\": string [required, 1-3,000 characters], \"description\": string [optional] } Copy Here's an example of doing this with a curl command: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy A successful request will return a 201 Created response, with the URI of the newly-created secure credential specified in the location header. Possible error codes include: 303 See Other: The specified key already exists. The returned location header will contain the URI to the key. 400 Bad Request: Key too long or missing, value too long or missing, non-parsable JSON payload. Get all secure credentials To view a list of all the secure credentials in your New Relic account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials. For example: curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"secureCredentials\": [ { \"key\": \"MYKEY1\", \"description\": \"Description of MYKEY1\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" }, { \"key\": \"MYKEY2\", \"description\": \"Description of MYKEY2\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" } ], \"count\": 2 } Copy Get a specific secure credential To view a single secure credential, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"key\": string, \"description\": string, \"createdAt\": date,​ \"lastUpdated\": date } Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Update an existing secure credential To update an existing credential in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Delete an existing secure credential To delete an existing credential in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy Please note that if the specified key does not exist, no error will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.9643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "sections": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": "With the <em>Synthetics</em> <em>REST</em> <em>API</em>, you can make <em>API</em> calls to change or retrieve secure credentials data. This document explains the <em>API</em> requirements and contains <em>API</em> curl command <em>examples</em>. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials"
      },
      "id": "6044070d196a67b171960f76"
    }
  ],
  "/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api": [
    {
      "sections": [
        "Synthetics REST API version 1 (deprecated)",
        "Caution",
        "Managing simple and scripted monitors",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Delete an existing monitor",
        "Get list of valid locations",
        "Managing scripted monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Synthetics attributes",
        "Specific monitor endpoint"
      ],
      "title": "Synthetics REST API version 1 (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "38f3b7d441889cea39fa8a10d1593473bffa8cf7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1/",
      "published_at": "2021-12-05T05:20:51Z",
      "updated_at": "2021-10-31T10:08:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the Synthetics API: v1 and v3. Version 3 was released October 2016. Version 1 is deprecated and will eventually no longer be available. No termination date has been announced. However, no further development or modifications will be made to v1. Caution Recommendation: Create new monitors using the v3 Synthetics API and migrate v1 scripts to their v3 equivalent. To use the REST API for New Relic's synthetic monitoring, you must activate API access and generate your Admin User's API key from your account settings. Then you can make standard API calls via the command line. Managing simple and scripted monitors You must use your Admin User's API key to make Synthetics REST API calls. The account's REST API key will not work. Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. These examples show curl commands: Get all monitors To view a list of all monitors in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors. For example: curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"count\": integer, \"monitors\": [ { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } ] } Copy Get a specific monitor To view a single existing monitor in New Relic, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return the error 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your account in New Relic, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/monitors with a JSON payload that describes the monitor: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings (send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/locations to get a list of valid locations) [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, } Copy In addition, to add a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. Replace the Synthetics REST API attributes in the following example with your specific values. curl -v \\ -X POST -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. Replace the { id} in the following example with the specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} \\ -d '{ \"name\" : \"updated monitor name\", \"type\" : \"simple\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response, 404 Not Found: The specified monitor does not exist. Get list of valid locations To retrieve the list of valid locations in New Relic, use the following command. curl -v \\ -X GET -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/locations Copy Managing scripted monitors In addition to the general API, there are several API methods for the scripted browser (SCRIPT_BROWSER) and api test (SCRIPT_API) monitor types. These examples show curl commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script. Replace the { id} with the specific monitor ID. For example: curl -v -H 'X-Api-Key: {Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the ${MONITOR_UUID}/script endpoint. For more information, refer to the example. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script with a JSON payload that contains the scriptText (required). The scriptLocations data is required only for private locations with Verified Script Execution turned on. The password used to generate the HMAC string must match the password set for the private location. When generating the HMAC string, use the SHA256 algorithm. { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy Replace the { id} with the specific monitor ID. Here is an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation. curl -v -H 'X-Api-Key: '{Admin_User_Key}' -H 'content-type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4\"} ]}' Copy A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows curl commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example show the bash script that will create the SCRIPTED_BROWSER monitor. #!/bin/bash # Admin API key from your account settings adminAPIKey='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload='{\"scriptText\":\"'$encoded'\"}' curl -s -X PUT -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy Synthetics attributes Here are the attributes used with Synthetics REST API calls, listed in alphabetical order. Synthetics API attribute Definition apiVersion String: The version number. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific Synthetics monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected Synthetics monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.5856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "sections": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " the SCRIPTED_BROWSER <em>monitor</em>. #!&#x2F;bin&#x2F;bash # Admin <em>API</em> key from your account settings adminAPIKey=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>Type=&#x27;SCRIPT_BROWSER"
      },
      "id": "60452541e7b9d27829579a0a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-12-04T15:40:21Z",
      "updated_at": "2021-09-14T18:17:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 50. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.83588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Use synthetic monitoring secure credentials APIs",
        "Requirements and rules",
        "API examples",
        "Add a secure credential",
        "Get all secure credentials",
        "Get a specific secure credential",
        "Update an existing secure credential",
        "Delete an existing secure credential"
      ],
      "title": "Use synthetic monitoring secure credentials APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Secure credentials examples"
      ],
      "external_id": "bd66e43160c1fd4c9f66bfdfa2d9a3223eb5d4d7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/secure-credentials-examples/use-synthetics-secure-credentials-apis/",
      "published_at": "2021-12-04T20:56:47Z",
      "updated_at": "2021-10-31T04:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Synthetics REST API, you can make API calls to change or retrieve secure credentials data. This document explains the API requirements and contains API curl command examples. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials. Requirements and rules For general rules about this feature, see the secure credentials requirements. API requirements and rules include: See general Synthetics REST API requirements. An account's rate of requests is limited to three requests per second. Requests that exceed this threshold will return a 429 response code. A key's value cannot be accessed via the API; an unauthorized user would not have access to the secure key values. API examples Add a secure credential To send a secure credential to your New Relic account, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials with a JSON payload that describes the secure credential. Here's an example: { \"key\": string [required, 1-64 characters uppercase], \"value\": string [required, 1-3,000 characters], \"description\": string [optional] } Copy Here's an example of doing this with a curl command: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy A successful request will return a 201 Created response, with the URI of the newly-created secure credential specified in the location header. Possible error codes include: 303 See Other: The specified key already exists. The returned location header will contain the URI to the key. 400 Bad Request: Key too long or missing, value too long or missing, non-parsable JSON payload. Get all secure credentials To view a list of all the secure credentials in your New Relic account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials. For example: curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"secureCredentials\": [ { \"key\": \"MYKEY1\", \"description\": \"Description of MYKEY1\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" }, { \"key\": \"MYKEY2\", \"description\": \"Description of MYKEY2\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" } ], \"count\": 2 } Copy Get a specific secure credential To view a single secure credential, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"key\": string, \"description\": string, \"createdAt\": date,​ \"lastUpdated\": date } Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Update an existing secure credential To update an existing credential in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Delete an existing secure credential To delete an existing credential in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy Please note that if the specified key does not exist, no error will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.9643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "sections": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": "With the <em>Synthetics</em> <em>REST</em> <em>API</em>, you can make <em>API</em> calls to change or retrieve secure credentials data. This document explains the <em>API</em> requirements and contains <em>API</em> curl command <em>examples</em>. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials"
      },
      "id": "6044070d196a67b171960f76"
    }
  ],
  "/docs/apis/synthetics-rest-api/secure-credentials-examples/use-synthetics-secure-credentials-apis": [
    {
      "sections": [
        "Synthetics REST API version 1 (deprecated)",
        "Caution",
        "Managing simple and scripted monitors",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Delete an existing monitor",
        "Get list of valid locations",
        "Managing scripted monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Synthetics attributes",
        "Specific monitor endpoint"
      ],
      "title": "Synthetics REST API version 1 (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "38f3b7d441889cea39fa8a10d1593473bffa8cf7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1/",
      "published_at": "2021-12-05T05:20:51Z",
      "updated_at": "2021-10-31T10:08:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the Synthetics API: v1 and v3. Version 3 was released October 2016. Version 1 is deprecated and will eventually no longer be available. No termination date has been announced. However, no further development or modifications will be made to v1. Caution Recommendation: Create new monitors using the v3 Synthetics API and migrate v1 scripts to their v3 equivalent. To use the REST API for New Relic's synthetic monitoring, you must activate API access and generate your Admin User's API key from your account settings. Then you can make standard API calls via the command line. Managing simple and scripted monitors You must use your Admin User's API key to make Synthetics REST API calls. The account's REST API key will not work. Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. These examples show curl commands: Get all monitors To view a list of all monitors in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors. For example: curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"count\": integer, \"monitors\": [ { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } ] } Copy Get a specific monitor To view a single existing monitor in New Relic, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return the error 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your account in New Relic, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/monitors with a JSON payload that describes the monitor: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings (send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/locations to get a list of valid locations) [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, } Copy In addition, to add a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. Replace the Synthetics REST API attributes in the following example with your specific values. curl -v \\ -X POST -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. Replace the { id} in the following example with the specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'X-Api-Key:{Admin_User_Key}' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} \\ -d '{ \"name\" : \"updated monitor name\", \"type\" : \"simple\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}. Replace the { id} in the following example with the specific monitor ID. curl -v \\ -H 'X-Api-Key:{Admin_User_Key}' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id} Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response, 404 Not Found: The specified monitor does not exist. Get list of valid locations To retrieve the list of valid locations in New Relic, use the following command. curl -v \\ -X GET -H 'X-Api-Key:{Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/locations Copy Managing scripted monitors In addition to the general API, there are several API methods for the scripted browser (SCRIPT_BROWSER) and api test (SCRIPT_API) monitor types. These examples show curl commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script. Replace the { id} with the specific monitor ID. For example: curl -v -H 'X-Api-Key: {Admin_User_Key}' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the ${MONITOR_UUID}/script endpoint. For more information, refer to the example. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic for your account, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script with a JSON payload that contains the scriptText (required). The scriptLocations data is required only for private locations with Verified Script Execution turned on. The password used to generate the HMAC string must match the password set for the private location. When generating the HMAC string, use the SHA256 algorithm. { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy Replace the { id} with the specific monitor ID. Here is an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation. curl -v -H 'X-Api-Key: '{Admin_User_Key}' -H 'content-type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors/{id}/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4\"} ]}' Copy A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows curl commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example show the bash script that will create the SCRIPTED_BROWSER monitor. #!/bin/bash # Admin API key from your account settings adminAPIKey='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload='{\"scriptText\":\"'$encoded'\"}' curl -s -X PUT -H \"X-Api-Key:$adminAPIKey\" -H 'Content-Type: application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy Synthetics attributes Here are the attributes used with Synthetics REST API calls, listed in alphabetical order. Synthetics API attribute Definition apiVersion String: The version number. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific Synthetics monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected Synthetics monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.0729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "sections": "<em>Synthetics</em> <em>REST</em> <em>API</em> version 1 (deprecated)",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " the SCRIPTED_BROWSER monitor. #!&#x2F;bin&#x2F;bash # Admin <em>API</em> key from your account settings adminAPIKey=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;monitor-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes monitorName=&#x27;Test <em>API</em> Script&#x27; monitorType=&#x27;SCRIPT_BROWSER"
      },
      "id": "60452541e7b9d27829579a0a"
    },
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-12-04T21:26:42Z",
      "updated_at": "2021-10-31T04:10:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.93732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": "For <em>REST</em> <em>API</em> requirements for <em>synthetics</em>, see Use the <em>API</em>. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the <em>Synthetics</em> <em>REST</em> <em>API</em>: <em>Synthetics</em> <em>API</em> attribute Definition <em>api</em>Version String: The version number. count Integer: The number"
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-12-04T15:40:21Z",
      "updated_at": "2021-09-14T18:17:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 50. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.40929,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> monitors via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> monitors via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;monitor-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes monitorName=&#x27;Test <em>API</em> Script&#x27; monitorType"
      },
      "id": "60440d4628ccbc74532c606a"
    }
  ],
  "/docs/apm/agents/c-sdk/get-started/apm-security-c-sdk": [
    {
      "sections": [
        "Introduction to the C SDK",
        "Monitor app performance",
        "Architecture: C library and daemon",
        "Get started with the C SDK",
        "Check the source code"
      ],
      "title": "Introduction to the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "9f45dcee154d21769c5bffe822338f3355c3aaa1",
      "image": "https://docs.newrelic.com/static/e224c0fb3a99dac4ed9622f398d2db6d/8c557/c-apm-summary.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/introduction-c-sdk/",
      "published_at": "2021-12-05T04:54:18Z",
      "updated_at": "2021-11-15T10:19:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The C SDK is designed to support the often complex, multi-threaded nature of C/C++ applications. You can gain a new level of visibility to help you identify and solve performance issues. You can also collect and analyze data to help you improve the customer experience and make data-driven business decisions. The C SDK can be used to instrument a wide range of applications beyond C or C++. If your application does not use other languages supported by New Relic and can import C libraries, then you can use the New Relic C SDK to take advantage of our monitoring capabilities and features. Monitor app performance one.newrelic.com > APM > (select an app): Here is an example of some of the data you can view in New Relic after you deploy the C SDK for your app. If your app meets the C SDK's compatibility and requirements in Linux environments, you can customize the generic library to communicate with New Relic, then start with APM to monitor your app's performance. What you can do How to do it See the big picture Start with the APM Summary page to monitor the throughput, response times, errors, memory and CPU usage transactions in your applications and services, then explore other details with additional APM dashboards. With deployment markers, see how code changes impact application performance and health. Use infrastructure monitoring to view detailed host and server data. When you install the infrastructure agent and APM on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by app in the Infrastructure UI. Identify and fix errors Use error analytics tools to find bottlenecks by seeing time spent on database calls, external system calls, and key blocks of code. Get alert notifications for problems or errors before they affect users. Create custom dashboards for important metrics. View logs for your APM and infrastructure data You can bring your logs and application's data together to make troubleshooting easier and faster. No need to switch to another UI page in New Relic One. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. Analyze business data Query user-related data and improve business processes. Send your own custom data to New Relic. Create custom queries of your application data. Create and share visual, interactive displays of your data. And more! Monitor and troubleshoot your application users' desktop experience with your application, including page load timing problems, JavaScript errors, session trace timelines, etc., by using browser monitoring. Use automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints with synthetic monitoring. Analyze and fine-tune your Android and iOS application performance, troubleshoot crashes, compare multiple versions, and examine the performance of HTTP and other network components with mobile monitoring. Architecture: C library and daemon The C SDK relies on two components to send data from your application to New Relic: The lC SDK calls: You download this library, then add the calls and instrumentation to your application's code. This allows you to identify and customize the kinds of data that matters the most to you. The C SDK daemon: This is a separate binary that accumulates data from the C SDK calls, and sends it to New Relic. This acts as a proxy between the SDK and New Relic. C SDK architecture: To send data from your application to New Relic, the daemon must be invoked before making calls to your application's C SDK instrumentation library. Working together, the C SDK instrumentation and the daemon forward data on to New Relic where you can view and query data about transactions. The workflow between your application and New Relic must occur in this order: An HTTPS link is established between the daemon and New Relic. The daemon must be invoked first, before your instrumented application is invoked. Next, socket communication is established between your instrumented application and the daemon. This occurs after successful calls to newrelic_new_app_config() and newrelic_create_app(). The call to newrelic_create_app() is non-blocking. Its second parameter allows you to specify an amount of time for your instrumented application to wait so that the socket communication is adequately established. For example: newrelic_app_t* app = newrelic_create_app(config, 10000); Copy If your instrumented application sends transactions before both the daemon connection and your application's socket communication are established, data reported from your application will be lost. Get started with the C SDK To use our C SDK agent: Make sure your application meets the compatibility and requirements for the C SDK. If you do not already have one, sign up for a free New Relic account. Use our launcher, or follow the installation and instrumentation procedures to install the agent. Within a few minutes, you will be able to view data from your application in your New Relic account's UI. Read the install docs Add C data Check the source code The C SDK is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.8026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>C</em> <em>SDK</em>",
        "sections": "<em>Get</em> <em>started</em> with the <em>C</em> <em>SDK</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " established. For example: newrelic_app_t* app = newrelic_create_app(config, 10000); Copy If your instrumented application sends transactions before both the daemon connection and your application&#x27;s socket communication are established, data reported from your application will be lost. <em>Get</em> <em>started</em> with the <em>C</em>"
      },
      "id": "617e6cda196a671853f7c605"
    },
    {
      "sections": [
        "Introduction to APM",
        "Tip",
        "Ready to get started?",
        "Identify problems before your users do",
        "Monitor all aspects of your business"
      ],
      "title": "Introduction to APM",
      "type": "docs",
      "tags": [
        "APM",
        "Getting started"
      ],
      "external_id": "317c07d4b32daa51186fd7d2cb857c392b595b5c",
      "image": "https://docs.newrelic.com/static/576604215ce4407c00e97b1072e557b5/c1b63/apm-screenshot.png",
      "url": "https://docs.newrelic.com/docs/apm/new-relic-apm/getting-started/introduction-apm/",
      "published_at": "2021-12-08T01:47:20Z",
      "updated_at": "2021-12-04T01:47:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application performance monitoring (APM) is exactly what it sounds like: monitoring of your web or non-web application's performance. APM supports apps for several programming languages, including Go, Java, .NET, Node.js, PHP, Python, and Ruby, as well as a C SDK. View the status of all your services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It's free, forever!) Then, after you install the agent, you can start working with your data. Ready to get started? Start benefiting from APM in five simple steps (and just a few minutes!). Sign up for a New Relic account (it's free, forever!). Install and customize the language agent for your app. Generate some traffic for your app. Wait a few minutes for New Relic to start receiving your data. Log in to your account, and start exploring New Relic! Use the Explorer in New Relic One to access and observe the full stack of your software, including your apps, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. If data does not appear after waiting a few minutes, follow the troubleshooting tips for your APM agent. Identify problems before your users do Our APM agents report and store the state of your application so you can quickly identify potential problems before they affect your end users. With APM, your DevOps teams don't need to guess whether a performance blocker comes from the app itself, CPU availability, database loads, or something entirely unexpected. Use our APM solutions to gather both current and historical information about memory usage, CPU utilization, database query performance, web browser rendering performance, app availability, error analysis, external services, and other useful metrics. Monitor all aspects of your business Take advantage of these APM features, and more: Features Description App performance at a glance When you sign in to APM and select an app for your account, use the Summary page to quickly examine relationships across different aspects of your environment; for example: Web transactions response time: Where is the most time being spent? In the request queue, during different stages of page rendering and execution, from external services, or something else? Transaction traces: Which transactions are the slowest, and why? Error rate and throughput: What relationship is there between a spike in errors or slower throughput for a particular time period? Was there a deployment or outage at that time? Hosts: What kind of impact does this have on CPU usage, memory, etc.? Apdex: How are these events affecting customers' satisfaction with the site? Web and non-web transactions Start by comparing the top twenty web transactions or non-web transactions in terms of most time consuming, slowest average response time, highest throughput, or worst Apdex. From there, drill down into deeper trace levels for individual transactions, which in turn break down into smaller segments and components, from HTTPS requests on down to SQL queries. Want to explore even deeper? Set up distributed tracing to see how requests move across a distributed system. Select the transactions that are most important to your business (key transactions). APM and Infrastructure When your APM and Infrastructure accounts are linked, you will have access to APM data charts on these Infrastructure UI pages: Hosts, Network, Storage, and Processes. Distributed tracing Distributed tracing gives you visibility across distributed systems, showing you the path of a request as it travels between services. This feature is especially valuable for large, distributed systems that rely on many small services and microservices. Logs Bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Service maps APM's service maps show your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. You can create and customize service maps to visualize and monitor your complex architectures. Query your data You can query and visualize your data: Sample and search APM transaction and error data to gain full understanding of the data being collected. Browse your data visually with the data explorer. Create custom SQL-like queries of your data using the New Relic Query Language (NRQL), or using our PromQL-style queries. Use dashboards to build advanced data visualizations, contextualize data, and understand what's going on in your system, real-time. These are just a few of APM's features. To find out more, see the table of contents for APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.96335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Ready to <em>get</em> <em>started</em>?",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It&#x27;s free, forever!) Then, after you install the <em>agent</em>, you can <em>start</em> working with your data. Ready to <em>get</em> <em>started</em>? <em>Start</em>"
      },
      "id": "60440835e7b9d29c2f5799e0"
    },
    {
      "sections": [
        "C SDK compatibility and requirements",
        "Language versions",
        "Operating environments",
        "License key",
        "Processor type",
        "Security requirements",
        "Database and instance-level performance"
      ],
      "title": " C SDK compatibility and requirements",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "8f6f0ee939383fff5783892ed0b7cbb71113ec7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/c-sdk-compatibility-requirements/",
      "published_at": "2021-12-05T04:54:18Z",
      "updated_at": "2021-10-23T20:02:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's C SDK provides a generic library you can customize to communicate with New Relic. Before you install New Relic's C SDK, make sure your system meets these requirements. Also refer to the C SDK licenses documentation. Want to try out our C SDK? Create a New Relic account for free! No credit card required. Language versions The C SDK allows you to instrument any application on Linux, provided: You must have access to the source code. The target language must be able to import C libraries. You can use the C SDK to create instrumentation for applications written in C and C++. You can also use it in languages like Perl, which are implemented in C or C++, and in any language that has a foreign function interface with C. Operating environments The C SDK works in 64-bit Linux operating systems with: gcc 4.8 or higher glibc 2.17 or higher Kernel version 2.6.26 or higher libpcre 8.20 or higher libpthread cmake 2.8 or higher Compiling the New Relic daemon requires Go 1.7 or higher. License key You will need a New Relic license key for the account you want to report data to. Processor type Intel (and compatible) platforms only Support for SSE2 instructions is required Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Database and instance-level performance You can collect instance details for a variety of databases and database drivers. You can also view slow query trace details for the following SQL-based database platforms: Firebird Informix Microsoft SQL Server MySQL Oracle Postgres SQLite Sybase",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.64578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": " <em>C</em> <em>SDK</em> <em>compatibility</em> and requirements",
        "sections": "<em>C</em> <em>SDK</em> <em>compatibility</em> and requirements",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "New Relic&#x27;s <em>C</em> <em>SDK</em> provides a generic library you can customize to communicate with New Relic. Before you install New Relic&#x27;s <em>C</em> <em>SDK</em>, make sure your system meets these requirements. Also refer to the <em>C</em> <em>SDK</em> licenses documentation. Want to try out our <em>C</em> <em>SDK</em>? Create a New Relic account for free"
      },
      "id": "617e510464441fa31dfbc502"
    }
  ],
  "/docs/apm/agents/c-sdk/get-started/c-sdk-compatibility-requirements": [
    {
      "sections": [
        "Introduction to the C SDK",
        "Monitor app performance",
        "Architecture: C library and daemon",
        "Get started with the C SDK",
        "Check the source code"
      ],
      "title": "Introduction to the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "9f45dcee154d21769c5bffe822338f3355c3aaa1",
      "image": "https://docs.newrelic.com/static/e224c0fb3a99dac4ed9622f398d2db6d/8c557/c-apm-summary.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/introduction-c-sdk/",
      "published_at": "2021-12-05T04:54:18Z",
      "updated_at": "2021-11-15T10:19:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The C SDK is designed to support the often complex, multi-threaded nature of C/C++ applications. You can gain a new level of visibility to help you identify and solve performance issues. You can also collect and analyze data to help you improve the customer experience and make data-driven business decisions. The C SDK can be used to instrument a wide range of applications beyond C or C++. If your application does not use other languages supported by New Relic and can import C libraries, then you can use the New Relic C SDK to take advantage of our monitoring capabilities and features. Monitor app performance one.newrelic.com > APM > (select an app): Here is an example of some of the data you can view in New Relic after you deploy the C SDK for your app. If your app meets the C SDK's compatibility and requirements in Linux environments, you can customize the generic library to communicate with New Relic, then start with APM to monitor your app's performance. What you can do How to do it See the big picture Start with the APM Summary page to monitor the throughput, response times, errors, memory and CPU usage transactions in your applications and services, then explore other details with additional APM dashboards. With deployment markers, see how code changes impact application performance and health. Use infrastructure monitoring to view detailed host and server data. When you install the infrastructure agent and APM on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by app in the Infrastructure UI. Identify and fix errors Use error analytics tools to find bottlenecks by seeing time spent on database calls, external system calls, and key blocks of code. Get alert notifications for problems or errors before they affect users. Create custom dashboards for important metrics. View logs for your APM and infrastructure data You can bring your logs and application's data together to make troubleshooting easier and faster. No need to switch to another UI page in New Relic One. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. Analyze business data Query user-related data and improve business processes. Send your own custom data to New Relic. Create custom queries of your application data. Create and share visual, interactive displays of your data. And more! Monitor and troubleshoot your application users' desktop experience with your application, including page load timing problems, JavaScript errors, session trace timelines, etc., by using browser monitoring. Use automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints with synthetic monitoring. Analyze and fine-tune your Android and iOS application performance, troubleshoot crashes, compare multiple versions, and examine the performance of HTTP and other network components with mobile monitoring. Architecture: C library and daemon The C SDK relies on two components to send data from your application to New Relic: The lC SDK calls: You download this library, then add the calls and instrumentation to your application's code. This allows you to identify and customize the kinds of data that matters the most to you. The C SDK daemon: This is a separate binary that accumulates data from the C SDK calls, and sends it to New Relic. This acts as a proxy between the SDK and New Relic. C SDK architecture: To send data from your application to New Relic, the daemon must be invoked before making calls to your application's C SDK instrumentation library. Working together, the C SDK instrumentation and the daemon forward data on to New Relic where you can view and query data about transactions. The workflow between your application and New Relic must occur in this order: An HTTPS link is established between the daemon and New Relic. The daemon must be invoked first, before your instrumented application is invoked. Next, socket communication is established between your instrumented application and the daemon. This occurs after successful calls to newrelic_new_app_config() and newrelic_create_app(). The call to newrelic_create_app() is non-blocking. Its second parameter allows you to specify an amount of time for your instrumented application to wait so that the socket communication is adequately established. For example: newrelic_app_t* app = newrelic_create_app(config, 10000); Copy If your instrumented application sends transactions before both the daemon connection and your application's socket communication are established, data reported from your application will be lost. Get started with the C SDK To use our C SDK agent: Make sure your application meets the compatibility and requirements for the C SDK. If you do not already have one, sign up for a free New Relic account. Use our launcher, or follow the installation and instrumentation procedures to install the agent. Within a few minutes, you will be able to view data from your application in your New Relic account's UI. Read the install docs Add C data Check the source code The C SDK is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.8026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>C</em> <em>SDK</em>",
        "sections": "<em>Get</em> <em>started</em> with the <em>C</em> <em>SDK</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " established. For example: newrelic_app_t* app = newrelic_create_app(config, 10000); Copy If your instrumented application sends transactions before both the daemon connection and your application&#x27;s socket communication are established, data reported from your application will be lost. <em>Get</em> <em>started</em> with the <em>C</em>"
      },
      "id": "617e6cda196a671853f7c605"
    },
    {
      "sections": [
        "Introduction to APM",
        "Tip",
        "Ready to get started?",
        "Identify problems before your users do",
        "Monitor all aspects of your business"
      ],
      "title": "Introduction to APM",
      "type": "docs",
      "tags": [
        "APM",
        "Getting started"
      ],
      "external_id": "317c07d4b32daa51186fd7d2cb857c392b595b5c",
      "image": "https://docs.newrelic.com/static/576604215ce4407c00e97b1072e557b5/c1b63/apm-screenshot.png",
      "url": "https://docs.newrelic.com/docs/apm/new-relic-apm/getting-started/introduction-apm/",
      "published_at": "2021-12-08T01:47:20Z",
      "updated_at": "2021-12-04T01:47:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application performance monitoring (APM) is exactly what it sounds like: monitoring of your web or non-web application's performance. APM supports apps for several programming languages, including Go, Java, .NET, Node.js, PHP, Python, and Ruby, as well as a C SDK. View the status of all your services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It's free, forever!) Then, after you install the agent, you can start working with your data. Ready to get started? Start benefiting from APM in five simple steps (and just a few minutes!). Sign up for a New Relic account (it's free, forever!). Install and customize the language agent for your app. Generate some traffic for your app. Wait a few minutes for New Relic to start receiving your data. Log in to your account, and start exploring New Relic! Use the Explorer in New Relic One to access and observe the full stack of your software, including your apps, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. If data does not appear after waiting a few minutes, follow the troubleshooting tips for your APM agent. Identify problems before your users do Our APM agents report and store the state of your application so you can quickly identify potential problems before they affect your end users. With APM, your DevOps teams don't need to guess whether a performance blocker comes from the app itself, CPU availability, database loads, or something entirely unexpected. Use our APM solutions to gather both current and historical information about memory usage, CPU utilization, database query performance, web browser rendering performance, app availability, error analysis, external services, and other useful metrics. Monitor all aspects of your business Take advantage of these APM features, and more: Features Description App performance at a glance When you sign in to APM and select an app for your account, use the Summary page to quickly examine relationships across different aspects of your environment; for example: Web transactions response time: Where is the most time being spent? In the request queue, during different stages of page rendering and execution, from external services, or something else? Transaction traces: Which transactions are the slowest, and why? Error rate and throughput: What relationship is there between a spike in errors or slower throughput for a particular time period? Was there a deployment or outage at that time? Hosts: What kind of impact does this have on CPU usage, memory, etc.? Apdex: How are these events affecting customers' satisfaction with the site? Web and non-web transactions Start by comparing the top twenty web transactions or non-web transactions in terms of most time consuming, slowest average response time, highest throughput, or worst Apdex. From there, drill down into deeper trace levels for individual transactions, which in turn break down into smaller segments and components, from HTTPS requests on down to SQL queries. Want to explore even deeper? Set up distributed tracing to see how requests move across a distributed system. Select the transactions that are most important to your business (key transactions). APM and Infrastructure When your APM and Infrastructure accounts are linked, you will have access to APM data charts on these Infrastructure UI pages: Hosts, Network, Storage, and Processes. Distributed tracing Distributed tracing gives you visibility across distributed systems, showing you the path of a request as it travels between services. This feature is especially valuable for large, distributed systems that rely on many small services and microservices. Logs Bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Service maps APM's service maps show your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. You can create and customize service maps to visualize and monitor your complex architectures. Query your data You can query and visualize your data: Sample and search APM transaction and error data to gain full understanding of the data being collected. Browse your data visually with the data explorer. Create custom SQL-like queries of your data using the New Relic Query Language (NRQL), or using our PromQL-style queries. Use dashboards to build advanced data visualizations, contextualize data, and understand what's going on in your system, real-time. These are just a few of APM's features. To find out more, see the table of contents for APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.96335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Ready to <em>get</em> <em>started</em>?",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It&#x27;s free, forever!) Then, after you install the <em>agent</em>, you can <em>start</em> working with your data. Ready to <em>get</em> <em>started</em>? <em>Start</em>"
      },
      "id": "60440835e7b9d29c2f5799e0"
    },
    {
      "sections": [
        "APM security: C SDK",
        "Default security settings",
        "Tip",
        "Customize security settings",
        "Caution"
      ],
      "title": "APM security: C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "f0865a8aae571854fb86a506ef6229380b03eb4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/apm-security-c-sdk/",
      "published_at": "2021-12-05T04:53:48Z",
      "updated_at": "2021-10-23T20:01:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Due of the nature of the C SDK, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls. In addition, the C SDK reports all data to New Relic over HTTPS. For more information about our security measures, see our security and privacy documentation, or visit the New Relic security website. Default security settings By default, this is how the C SDK handles the following potentially sensitive data. For more information, including code values and examples, see the C SDK documentation about data structures on GitHub. Type of information C SDK data security Datastore instance name or database name The newrelic_datastore_segment_config_t is a struct that configures whether a datastore's instance name and table name are captured for datastore segment instrumentation. Instance names: By default, the configuration returned by newrelic_new_config() enables datastore segments with instance_reporting set to true. Database names: By default, the configuration returned by newrelic_new_config() enables datastore segments with database_name_reporting set to true. SQL The record_sql setting in the newrelic_transaction_tracer_config_t controls the SQL format in transaction traces for supported SQL-like products. The default setting, NEWRELIC_SQL_OBFUSCATED, sets alphanumeric characters to ?. Audit mode The audit log is a plain text logging of all data sent to New Relic by the C SDK. When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Tip To see all of the available options for the C daemon: At the command line, type: ./newrelic-daemon --help Copy Customize security settings If the default settings do not work for your business needs, you can customize how information is sent to New Relic by altering the newrelic_datastore_segment_config_t and the newrelic_transaction_tracer_config_t. Caution If you customize your configuration, it may impact the security of your application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.64551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM security: <em>C</em> <em>SDK</em>",
        "sections": "APM security: <em>C</em> <em>SDK</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Due of the nature of the <em>C</em> <em>SDK</em>, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls. In addition, the <em>C</em> <em>SDK</em> reports all data to New"
      },
      "id": "617e5104e7b9d2e66dc05613"
    }
  ],
  "/docs/apm/agents/c-sdk/get-started/introduction-c-sdk": [
    {
      "sections": [
        "Introduction to APM",
        "Tip",
        "Ready to get started?",
        "Identify problems before your users do",
        "Monitor all aspects of your business"
      ],
      "title": "Introduction to APM",
      "type": "docs",
      "tags": [
        "APM",
        "Getting started"
      ],
      "external_id": "317c07d4b32daa51186fd7d2cb857c392b595b5c",
      "image": "https://docs.newrelic.com/static/576604215ce4407c00e97b1072e557b5/c1b63/apm-screenshot.png",
      "url": "https://docs.newrelic.com/docs/apm/new-relic-apm/getting-started/introduction-apm/",
      "published_at": "2021-12-08T01:47:20Z",
      "updated_at": "2021-12-04T01:47:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application performance monitoring (APM) is exactly what it sounds like: monitoring of your web or non-web application's performance. APM supports apps for several programming languages, including Go, Java, .NET, Node.js, PHP, Python, and Ruby, as well as a C SDK. View the status of all your services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It's free, forever!) Then, after you install the agent, you can start working with your data. Ready to get started? Start benefiting from APM in five simple steps (and just a few minutes!). Sign up for a New Relic account (it's free, forever!). Install and customize the language agent for your app. Generate some traffic for your app. Wait a few minutes for New Relic to start receiving your data. Log in to your account, and start exploring New Relic! Use the Explorer in New Relic One to access and observe the full stack of your software, including your apps, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. If data does not appear after waiting a few minutes, follow the troubleshooting tips for your APM agent. Identify problems before your users do Our APM agents report and store the state of your application so you can quickly identify potential problems before they affect your end users. With APM, your DevOps teams don't need to guess whether a performance blocker comes from the app itself, CPU availability, database loads, or something entirely unexpected. Use our APM solutions to gather both current and historical information about memory usage, CPU utilization, database query performance, web browser rendering performance, app availability, error analysis, external services, and other useful metrics. Monitor all aspects of your business Take advantage of these APM features, and more: Features Description App performance at a glance When you sign in to APM and select an app for your account, use the Summary page to quickly examine relationships across different aspects of your environment; for example: Web transactions response time: Where is the most time being spent? In the request queue, during different stages of page rendering and execution, from external services, or something else? Transaction traces: Which transactions are the slowest, and why? Error rate and throughput: What relationship is there between a spike in errors or slower throughput for a particular time period? Was there a deployment or outage at that time? Hosts: What kind of impact does this have on CPU usage, memory, etc.? Apdex: How are these events affecting customers' satisfaction with the site? Web and non-web transactions Start by comparing the top twenty web transactions or non-web transactions in terms of most time consuming, slowest average response time, highest throughput, or worst Apdex. From there, drill down into deeper trace levels for individual transactions, which in turn break down into smaller segments and components, from HTTPS requests on down to SQL queries. Want to explore even deeper? Set up distributed tracing to see how requests move across a distributed system. Select the transactions that are most important to your business (key transactions). APM and Infrastructure When your APM and Infrastructure accounts are linked, you will have access to APM data charts on these Infrastructure UI pages: Hosts, Network, Storage, and Processes. Distributed tracing Distributed tracing gives you visibility across distributed systems, showing you the path of a request as it travels between services. This feature is especially valuable for large, distributed systems that rely on many small services and microservices. Logs Bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Service maps APM's service maps show your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. You can create and customize service maps to visualize and monitor your complex architectures. Query your data You can query and visualize your data: Sample and search APM transaction and error data to gain full understanding of the data being collected. Browse your data visually with the data explorer. Create custom SQL-like queries of your data using the New Relic Query Language (NRQL), or using our PromQL-style queries. Use dashboards to build advanced data visualizations, contextualize data, and understand what's going on in your system, real-time. These are just a few of APM's features. To find out more, see the table of contents for APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.96329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Ready to <em>get</em> <em>started</em>?",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " services at a glance with APM. Tip This doc gives you detailed information about why APM matters to your business. But if you want to skip ahead, just sign up for a New Relic account. (It&#x27;s free, forever!) Then, after you install the <em>agent</em>, you can <em>start</em> working with your data. Ready to <em>get</em> <em>started</em>? <em>Start</em>"
      },
      "id": "60440835e7b9d29c2f5799e0"
    },
    {
      "sections": [
        "C SDK compatibility and requirements",
        "Language versions",
        "Operating environments",
        "License key",
        "Processor type",
        "Security requirements",
        "Database and instance-level performance"
      ],
      "title": " C SDK compatibility and requirements",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "8f6f0ee939383fff5783892ed0b7cbb71113ec7e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/c-sdk-compatibility-requirements/",
      "published_at": "2021-12-05T04:54:18Z",
      "updated_at": "2021-10-23T20:02:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's C SDK provides a generic library you can customize to communicate with New Relic. Before you install New Relic's C SDK, make sure your system meets these requirements. Also refer to the C SDK licenses documentation. Want to try out our C SDK? Create a New Relic account for free! No credit card required. Language versions The C SDK allows you to instrument any application on Linux, provided: You must have access to the source code. The target language must be able to import C libraries. You can use the C SDK to create instrumentation for applications written in C and C++. You can also use it in languages like Perl, which are implemented in C or C++, and in any language that has a foreign function interface with C. Operating environments The C SDK works in 64-bit Linux operating systems with: gcc 4.8 or higher glibc 2.17 or higher Kernel version 2.6.26 or higher libpcre 8.20 or higher libpthread cmake 2.8 or higher Compiling the New Relic daemon requires Go 1.7 or higher. License key You will need a New Relic license key for the account you want to report data to. Processor type Intel (and compatible) platforms only Support for SSE2 instructions is required Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Database and instance-level performance You can collect instance details for a variety of databases and database drivers. You can also view slow query trace details for the following SQL-based database platforms: Firebird Informix Microsoft SQL Server MySQL Oracle Postgres SQLite Sybase",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.64578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": " <em>C</em> <em>SDK</em> <em>compatibility</em> and requirements",
        "sections": "<em>C</em> <em>SDK</em> <em>compatibility</em> and requirements",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "New Relic&#x27;s <em>C</em> <em>SDK</em> provides a generic library you can customize to communicate with New Relic. Before you install New Relic&#x27;s <em>C</em> <em>SDK</em>, make sure your system meets these requirements. Also refer to the <em>C</em> <em>SDK</em> licenses documentation. Want to try out our <em>C</em> <em>SDK</em>? Create a New Relic account for free"
      },
      "id": "617e510464441fa31dfbc502"
    },
    {
      "sections": [
        "APM security: C SDK",
        "Default security settings",
        "Tip",
        "Customize security settings",
        "Caution"
      ],
      "title": "APM security: C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "f0865a8aae571854fb86a506ef6229380b03eb4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/apm-security-c-sdk/",
      "published_at": "2021-12-05T04:53:48Z",
      "updated_at": "2021-10-23T20:01:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Due of the nature of the C SDK, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls. In addition, the C SDK reports all data to New Relic over HTTPS. For more information about our security measures, see our security and privacy documentation, or visit the New Relic security website. Default security settings By default, this is how the C SDK handles the following potentially sensitive data. For more information, including code values and examples, see the C SDK documentation about data structures on GitHub. Type of information C SDK data security Datastore instance name or database name The newrelic_datastore_segment_config_t is a struct that configures whether a datastore's instance name and table name are captured for datastore segment instrumentation. Instance names: By default, the configuration returned by newrelic_new_config() enables datastore segments with instance_reporting set to true. Database names: By default, the configuration returned by newrelic_new_config() enables datastore segments with database_name_reporting set to true. SQL The record_sql setting in the newrelic_transaction_tracer_config_t controls the SQL format in transaction traces for supported SQL-like products. The default setting, NEWRELIC_SQL_OBFUSCATED, sets alphanumeric characters to ?. Audit mode The audit log is a plain text logging of all data sent to New Relic by the C SDK. When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Tip To see all of the available options for the C daemon: At the command line, type: ./newrelic-daemon --help Copy Customize security settings If the default settings do not work for your business needs, you can customize how information is sent to New Relic by altering the newrelic_datastore_segment_config_t and the newrelic_transaction_tracer_config_t. Caution If you customize your configuration, it may impact the security of your application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.6455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM security: <em>C</em> <em>SDK</em>",
        "sections": "APM security: <em>C</em> <em>SDK</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Due of the nature of the <em>C</em> <em>SDK</em>, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls. In addition, the <em>C</em> <em>SDK</em> reports all data to New"
      },
      "id": "617e5104e7b9d2e66dc05613"
    }
  ],
  "/docs/apm/agents/c-sdk/index": [
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "ebc829a1c1b74c866f5326f90a6d5119fdcfae10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-12-06T01:43:28Z",
      "updated_at": "2021-12-04T22:00:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata For PHP, logs in context is only supported from the distributed tracing UI, not in the Logs tab of the APM UI. Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension PHP: Monolog extension Python: Streamhandler example Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.54706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM <em>agent</em> APIs with logs in <em>context</em>",
        "sections": "Use APM <em>agent</em> APIs with logs in <em>context</em>",
        "tags": "Logs in <em>context</em> with <em>agent</em> APIs",
        "body": " APIs to annotate logs for logs in context, review the APM <em>agent</em> specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: <em>C</em> <em>SDK</em>: n&#x2F;a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension PHP: Monolog extension Python: Streamhandler example Ruby: logging.rb extension"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Enable distributed tracing for your C applications",
        "Enable distributed tracing",
        "Important",
        "Instrument transactions and HTTP requests",
        "Examine logs for trace details"
      ],
      "title": "Enable distributed tracing for your C applications ",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "9036e53bb3b807f6a6f52b8137beadb748b0dc15",
      "image": "https://docs.newrelic.com/static/ee7733b8ef099e619b93592bf8ebcbef/c1b63/logs-in-context-traces.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/instrumentation/enable-distributed-tracing-your-c-applications/",
      "published_at": "2021-12-05T05:25:06Z",
      "updated_at": "2021-11-15T10:23:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to enable and instrument distributed tracing for the New Relic's C SDK. Enable distributed tracing To enable distributed tracing for a New Relic-monitored C application: Create a default newrelic_app_config_t and set the distributed_tracing.enabled field to true. newrelic_app_config_t* config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Continue with the procedures to instrument transactions and HTTP requests. Important Span events can be enabled/disabled separately from distributed tracing. Instrument transactions and HTTP requests For transactions that occur in multiple services, the distributed trace payload contains information that allows New Relic to stitch them together into a complete transaction trace. However, if New Relic-monitored services are not sending trace context to each other, it will result in incomplete trace details. For more information, see the documentation about passing the distributed tracing API header and the C SDK's distributed tracing documentation on GitHub. If you want to... Use this Create and return a payload to be sent to the called service newrelic_create_distributed_trace_payload() Copy Accept a payload sent from the first service newrelic_accept_distributed_trace_payload() Copy This will link these services together in a trace. Return a base64-encoded JSON string representation of the payload newrelic_create_distributed_trace_payload_httpsafe() Copy This offers the same behavior as newrelic_create_distributed_trace_payload(). Accept a base64-encoded string for the payload newrelic_accept_distributed_trace_payload_httpsafe() Copy This offers the same behavior as newrelic_accept_distributed_trace_payload(). Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. With logs in context, you can examine log data directly within your trace details. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.476105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable distributed tracing for your <em>C</em> applications ",
        "sections": "Enable distributed tracing for your <em>C</em> applications",
        "tags": "<em>Agents</em>",
        "body": "Read on to learn how to enable and instrument distributed tracing for the New Relic&#x27;s <em>C</em> <em>SDK</em>. Enable distributed tracing To enable distributed tracing for a New Relic-monitored <em>C</em> application: Create a default newrelic_app_config_t and set the distributed_tracing.enabled field to true"
      },
      "id": "617e6cda64441fac06fbd93e"
    },
    {
      "sections": [
        "Introduction to the C SDK",
        "Monitor app performance",
        "Architecture: C library and daemon",
        "Get started with the C SDK",
        "Check the source code"
      ],
      "title": "Introduction to the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Get started"
      ],
      "external_id": "9f45dcee154d21769c5bffe822338f3355c3aaa1",
      "image": "https://docs.newrelic.com/static/e224c0fb3a99dac4ed9622f398d2db6d/8c557/c-apm-summary.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/get-started/introduction-c-sdk/",
      "published_at": "2021-12-05T04:54:18Z",
      "updated_at": "2021-11-15T10:19:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The C SDK is designed to support the often complex, multi-threaded nature of C/C++ applications. You can gain a new level of visibility to help you identify and solve performance issues. You can also collect and analyze data to help you improve the customer experience and make data-driven business decisions. The C SDK can be used to instrument a wide range of applications beyond C or C++. If your application does not use other languages supported by New Relic and can import C libraries, then you can use the New Relic C SDK to take advantage of our monitoring capabilities and features. Monitor app performance one.newrelic.com > APM > (select an app): Here is an example of some of the data you can view in New Relic after you deploy the C SDK for your app. If your app meets the C SDK's compatibility and requirements in Linux environments, you can customize the generic library to communicate with New Relic, then start with APM to monitor your app's performance. What you can do How to do it See the big picture Start with the APM Summary page to monitor the throughput, response times, errors, memory and CPU usage transactions in your applications and services, then explore other details with additional APM dashboards. With deployment markers, see how code changes impact application performance and health. Use infrastructure monitoring to view detailed host and server data. When you install the infrastructure agent and APM on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by app in the Infrastructure UI. Identify and fix errors Use error analytics tools to find bottlenecks by seeing time spent on database calls, external system calls, and key blocks of code. Get alert notifications for problems or errors before they affect users. Create custom dashboards for important metrics. View logs for your APM and infrastructure data You can bring your logs and application's data together to make troubleshooting easier and faster. No need to switch to another UI page in New Relic One. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. Analyze business data Query user-related data and improve business processes. Send your own custom data to New Relic. Create custom queries of your application data. Create and share visual, interactive displays of your data. And more! Monitor and troubleshoot your application users' desktop experience with your application, including page load timing problems, JavaScript errors, session trace timelines, etc., by using browser monitoring. Use automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints with synthetic monitoring. Analyze and fine-tune your Android and iOS application performance, troubleshoot crashes, compare multiple versions, and examine the performance of HTTP and other network components with mobile monitoring. Architecture: C library and daemon The C SDK relies on two components to send data from your application to New Relic: The lC SDK calls: You download this library, then add the calls and instrumentation to your application's code. This allows you to identify and customize the kinds of data that matters the most to you. The C SDK daemon: This is a separate binary that accumulates data from the C SDK calls, and sends it to New Relic. This acts as a proxy between the SDK and New Relic. C SDK architecture: To send data from your application to New Relic, the daemon must be invoked before making calls to your application's C SDK instrumentation library. Working together, the C SDK instrumentation and the daemon forward data on to New Relic where you can view and query data about transactions. The workflow between your application and New Relic must occur in this order: An HTTPS link is established between the daemon and New Relic. The daemon must be invoked first, before your instrumented application is invoked. Next, socket communication is established between your instrumented application and the daemon. This occurs after successful calls to newrelic_new_app_config() and newrelic_create_app(). The call to newrelic_create_app() is non-blocking. Its second parameter allows you to specify an amount of time for your instrumented application to wait so that the socket communication is adequately established. For example: newrelic_app_t* app = newrelic_create_app(config, 10000); Copy If your instrumented application sends transactions before both the daemon connection and your application's socket communication are established, data reported from your application will be lost. Get started with the C SDK To use our C SDK agent: Make sure your application meets the compatibility and requirements for the C SDK. If you do not already have one, sign up for a free New Relic account. Use our launcher, or follow the installation and instrumentation procedures to install the agent. Within a few minutes, you will be able to view data from your application in your New Relic account's UI. Read the install docs Add C data Check the source code The C SDK is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.46245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>C</em> <em>SDK</em>",
        "sections": "Introduction to the <em>C</em> <em>SDK</em>",
        "tags": "<em>Agents</em>",
        "body": " <em>SDK</em> To use our <em>C</em> <em>SDK</em> <em>agent</em>: Make sure your application meets the compatibility and requirements for the <em>C</em> <em>SDK</em>. If you do not already have one, sign up for a free New Relic account. Use our launcher, or follow the installation and instrumentation procedures to install the <em>agent</em>. Within a few minutes"
      },
      "id": "617e6cda196a671853f7c605"
    }
  ],
  "/docs/apm/agents/c-sdk/install-configure/c-sdk-configuration": [
    {
      "sections": [
        "Docker and other container environments: Install C SDK",
        "Install C SDK in container environment",
        "Caution"
      ],
      "title": "Docker and other container environments: Install C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "9f7f514c867c46d447a624d5a59962082cc5a429",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/docker-other-container-environments-install-c-sdk/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can install the New Relic C SDK on a Docker container (or other container) to monitor one or more of your C applications. Install C SDK in container environment Requirements: Meet C SDK requirements C SDK version 1.2 or higher Caution Data transmitted from the agent to the daemon is not encrypted. We recommend only using a private network connection between the agent and daemon. This only applies when the agent and daemon are running on different hosts. To install C SDK for a container environment, we recommend installing the C SDK daemon on a separate docker container: Install the daemon by cloning the C SDK repository and building the daemon. This is done most effectively via the command make daemon. See the README.md for further details. If you are using Docker, you can use the C SDK daemon image on Dockerhub. Start the daemon using --address and --watchdog-foreground arguments. The --address argument is used to set a port where the daemon is accepting connections. The --watchdog-foreground argument ensures that the daemon runs in the foreground. Then, use the C SDK in your containerized application: Follow the steps to add the C SDK to your code. Point the C SDK to the daemon by adding a newrelic_init call and passing a valid address argument. The value for this argument must be HOST:PORT, where HOST is the name or IP address of the host where the daemon is running, and PORT is the port number where the daemon is listening.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.49847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "sections": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "You can <em>install</em> the New Relic <em>C</em> <em>SDK</em> on a Docker container (or other container) to monitor one or more of your <em>C</em> applications. <em>Install</em> <em>C</em> <em>SDK</em> in container environment Requirements: Meet <em>C</em> <em>SDK</em> requirements <em>C</em> <em>SDK</em> version 1.2 or higher Caution Data transmitted from the <em>agent</em> to the daemon"
      },
      "id": "617e586828ccbc28fd8003f8"
    },
    {
      "sections": [
        "Install the C SDK: Compile and link your code",
        "Add the C SDK to your code",
        "1. Verify requirements.",
        "2. Include the provided header file.",
        "3. Configure logging.",
        "4. Be ready to provide a meaningful app name.",
        "5. Finish instrumenting your code.",
        "6. Compile and link your app.",
        "7. Start the daemon and check logs.",
        "Tip",
        "View app performance in New Relic"
      ],
      "title": "Install the C SDK: Compile and link your code",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "f403769d1be59206b211c778bd56a83c88bf4887",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/install-c-sdk-compile-link-your-code/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our C SDK auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic C SDK installation. If you don't have one already, create a New Relic account. It's free, forever. Add C data Add the C SDK to your code To monitor your application with New Relic's C SDK, instrument the features you want to use: Web transactions, transaction events, non-web transactions Segments (for additional levels of timing details) Attributes Errors Then compile and link your app against the C SDK static library. To install the C SDK into your application's code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic's compatibility and requirements for the C SDK. Make sure you have a New Relic license key. 2. Include the provided header file. #include \"libnewrelic.h\" Copy 3. Configure logging. Follow the procedures to configure logging for both the C SDK and the daemon. For example: if (!newrelic_configure_log(\"./c_sdk.log\", NEWRELIC_LOG_INFO)) { printf(\"Error configuring logging.\\n\"); return -1; } Copy 4. Be ready to provide a meaningful app name. Be prepared to provide a meaningful app name in your initial application configuration; for example: newrelic_app_config_t* config; /* ... */ config = newrelic_create_app_config(\"Your Application Name\", \"LICENSE_KEY_HERE\"); Copy You may give your application up to three different names, separated by ;. Giving your application multiple names allows you to aggregate metrics for multiple agents across an entire app or service; for example: config = newrelic_create_app_config(\"YOUR_APP_NAME;APP_GROUP_1;ALL_APPS\", \"LICENSE_KEY_HERE\"); Copy With the application configured, you can create a new application to connect to the daemon. newrelic_app_t* app; /* ... */ if (!newrelic_init(NULL, 0)) { printf(\"Error connecting to daemon.\\n\"); return -1; } /* Wait up to 10 seconds for the SDK to connect to the daemon */ app = newrelic_create_app(config, 10000); newrelic_destroy_app_config(&config); Copy 5. Finish instrumenting your code. To finish instrumenting your code, refer to the example programs in the C SDK Examples documentation on GitHub. For more information about source code and features, see the C SDK's source documentation for libnewrelic.h on GitHub. 6. Compile and link your app. The C SDK's libnewrelic.a is a static library that is already linked with the libpcre and libpthread libraries. To avoid symbol collisions in this linking step, be sure to link against each of these libraries. In addition, to take full advantage of error traces in APM's Error analytics page, link your application using GNU's -rdynamic linker flag. This will allow more meaningful information to appear in the stack trace for the error recording on a transaction using the C SDK's newrelic_notice_error API call. For example: gcc -o test_app test_app.c -L. -lnewrelic -lpcre -lm -pthread -rdynamic Copy 7. Start the daemon and check logs. Start the C SDK's daemon. For example: ./newrelic-daemon -f -logfile newrelic-daemon.log -loglevel debug Copy Check the output in the c_sdk.log and newrelic-daemon.log files. The C SDK's architecture requires that the daemon must be invoked first before your instrumented application is invoked. Tip To see all of the available options for the C daemon: At the command line, type: ./newrelic-daemon --help Copy For more information, see the C SDK GUIDE.md. View app performance in New Relic To view your app's performance with APM: Generate some traffic for your app, then wait a few minutes for your app to send data to New Relic. Explore your app's data in the APM UI. If no data appears within a few minutes, check your c_sdk.log and newrelic-daemon.log files for errors. If you still have problems, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "sections": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": ". To <em>install</em> the <em>C</em> <em>SDK</em> into your application&#x27;s code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic&#x27;s compatibility and requirements for the <em>C</em> <em>SDK</em>. Make sure you have a New Relic license key. 2. Include the provided header file. #include &quot;libnewrelic.h&quot; Copy"
      },
      "id": "617e5b3764441f4c66fbe0bb"
    },
    {
      "sections": [
        "Update your C SDK library",
        "Update your C SDK code library"
      ],
      "title": "Update your C SDK library",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "697c24bac00edcaec09dd8b875bbf6d30f1f370c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/update-your-c-sdk-library/",
      "published_at": "2021-12-05T04:01:49Z",
      "updated_at": "2021-10-23T20:03:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure you have the most up-to-date version of the New Relic C SDK for your application's code library, check the release notes. Update your C SDK code library To update your application's code library to the latest version of New Relic's C SDK: Review the C SDK library changes to verify your code is compatible. Manually update the code for your app as applicable. Compile the C SDK code, using the make command, to create the latest version of the libnewrelic.a and link it into your application or service. If applicable, redeploy your application to your test environment. Generate traffic for your application, then check your its c_sdk.log file and newrelic-daemon.log output for any errors. Redeploy your application to your production environment. Wait a few minutes for your application to send data to New Relic. Then, check your application's performance in New Relic. If no data appears within a few minutes, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update your <em>C</em> <em>SDK</em> library",
        "sections": "Update your <em>C</em> <em>SDK</em> library",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "To ensure you have the most up-to-date version of the New Relic <em>C</em> <em>SDK</em> for your application&#x27;s code library, check the release notes. Update your <em>C</em> <em>SDK</em> code library To update your application&#x27;s code library to the latest version of New Relic&#x27;s <em>C</em> <em>SDK</em>: Review the <em>C</em> <em>SDK</em> library changes to verify your"
      },
      "id": "617e6cda64441f9dd0fbd32e"
    }
  ],
  "/docs/apm/agents/c-sdk/install-configure/docker-other-container-environments-install-c-sdk": [
    {
      "sections": [
        "C SDK configuration",
        "Change configuration settings",
        "Change app name (alias) in UI",
        "Change app name in configuration",
        "Caution",
        "View logs for your APM and infrastructure data"
      ],
      "title": "C SDK configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "c1121d9af1643bf40ebfa749aa7d26a14fc59233",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/c-sdk-configuration/",
      "published_at": "2021-12-05T04:13:36Z",
      "updated_at": "2021-11-15T05:36:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your C application requires two configuration values: Application's name: app_name New Relic license key: license_key All other configuration values are optional, and typically the default settings do not need to be changed. However, when necessary, you can adjust New Relic's C SDK configuration. This document is a quick reference for using some basic configuration options with the C SDK API. For detailed information about changing your configuration settings, including code values and examples, see the C SDK's configuration GUIDE.md on GitHub. Change configuration settings Here are examples of some available configuration options you can change, as defined in the C SDK's public header, libnewrelic.h. C SDK configuration options Comments General configuration settings To set or change the app name, set the license key, logging level, transaction tracing, datastore tracing, etc., use: newrelic_app_config_t Additional transaction tracing configuration To enable the transaction tracer and to configure what transaction durations are considered for reporting a trace to New Relic, use: newrelic_transaction_tracer_config_t Datastore segments To configure whether a database name and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the C SDK To set the socket endpoint for agent-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application's alias from the Application settings page in the New Relic UI. This is useful, for example, to give your application a different name, yet keep historic data under the new alias. For more information, see Name your application. New Relic's C SDK does not support server-side configuration. However, you can also use this Application settings page in the UI to set your application's Apdex T threshold. To change the application's alias or Apdex T threshold in the UI go to one.newrelic.com > APM > (select an app) > Settings > Application. Change app name in configuration If you change your application's name in your configuration settings, this will result in the same app appearing in the UI with a new name. Any historic data (based on the data retention schedule) will only exist under the old name. (To rename your application but still keep historic data, use the UI settings to change the alias.) If you need to change your application's name in your configuration after your application is connected to the daemon: Make a new config with a call to newrelic_create_app_config() using the new application name. Make a new connected app with a call to newrelic_create_app(). Caution Timing is everything. Switching application names during a single application execution may mean that your instrumented data is sent under the new application name. View logs for your APM and infrastructure data You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.48425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "sections": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the <em>C</em> <em>SDK</em> To set the socket endpoint for <em>agent</em>-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application&#x27;s alias from the Application settings page in the New"
      },
      "id": "617e5154e7b9d27dc5c06406"
    },
    {
      "sections": [
        "Install the C SDK: Compile and link your code",
        "Add the C SDK to your code",
        "1. Verify requirements.",
        "2. Include the provided header file.",
        "3. Configure logging.",
        "4. Be ready to provide a meaningful app name.",
        "5. Finish instrumenting your code.",
        "6. Compile and link your app.",
        "7. Start the daemon and check logs.",
        "Tip",
        "View app performance in New Relic"
      ],
      "title": "Install the C SDK: Compile and link your code",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "f403769d1be59206b211c778bd56a83c88bf4887",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/install-c-sdk-compile-link-your-code/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our C SDK auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic C SDK installation. If you don't have one already, create a New Relic account. It's free, forever. Add C data Add the C SDK to your code To monitor your application with New Relic's C SDK, instrument the features you want to use: Web transactions, transaction events, non-web transactions Segments (for additional levels of timing details) Attributes Errors Then compile and link your app against the C SDK static library. To install the C SDK into your application's code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic's compatibility and requirements for the C SDK. Make sure you have a New Relic license key. 2. Include the provided header file. #include \"libnewrelic.h\" Copy 3. Configure logging. Follow the procedures to configure logging for both the C SDK and the daemon. For example: if (!newrelic_configure_log(\"./c_sdk.log\", NEWRELIC_LOG_INFO)) { printf(\"Error configuring logging.\\n\"); return -1; } Copy 4. Be ready to provide a meaningful app name. Be prepared to provide a meaningful app name in your initial application configuration; for example: newrelic_app_config_t* config; /* ... */ config = newrelic_create_app_config(\"Your Application Name\", \"LICENSE_KEY_HERE\"); Copy You may give your application up to three different names, separated by ;. Giving your application multiple names allows you to aggregate metrics for multiple agents across an entire app or service; for example: config = newrelic_create_app_config(\"YOUR_APP_NAME;APP_GROUP_1;ALL_APPS\", \"LICENSE_KEY_HERE\"); Copy With the application configured, you can create a new application to connect to the daemon. newrelic_app_t* app; /* ... */ if (!newrelic_init(NULL, 0)) { printf(\"Error connecting to daemon.\\n\"); return -1; } /* Wait up to 10 seconds for the SDK to connect to the daemon */ app = newrelic_create_app(config, 10000); newrelic_destroy_app_config(&config); Copy 5. Finish instrumenting your code. To finish instrumenting your code, refer to the example programs in the C SDK Examples documentation on GitHub. For more information about source code and features, see the C SDK's source documentation for libnewrelic.h on GitHub. 6. Compile and link your app. The C SDK's libnewrelic.a is a static library that is already linked with the libpcre and libpthread libraries. To avoid symbol collisions in this linking step, be sure to link against each of these libraries. In addition, to take full advantage of error traces in APM's Error analytics page, link your application using GNU's -rdynamic linker flag. This will allow more meaningful information to appear in the stack trace for the error recording on a transaction using the C SDK's newrelic_notice_error API call. For example: gcc -o test_app test_app.c -L. -lnewrelic -lpcre -lm -pthread -rdynamic Copy 7. Start the daemon and check logs. Start the C SDK's daemon. For example: ./newrelic-daemon -f -logfile newrelic-daemon.log -loglevel debug Copy Check the output in the c_sdk.log and newrelic-daemon.log files. The C SDK's architecture requires that the daemon must be invoked first before your instrumented application is invoked. Tip To see all of the available options for the C daemon: At the command line, type: ./newrelic-daemon --help Copy For more information, see the C SDK GUIDE.md. View app performance in New Relic To view your app's performance with APM: Generate some traffic for your app, then wait a few minutes for your app to send data to New Relic. Explore your app's data in the APM UI. If no data appears within a few minutes, check your c_sdk.log and newrelic-daemon.log files for errors. If you still have problems, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "sections": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": ". To <em>install</em> the <em>C</em> <em>SDK</em> into your application&#x27;s code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic&#x27;s compatibility and requirements for the <em>C</em> <em>SDK</em>. Make sure you have a New Relic license key. 2. Include the provided header file. #include &quot;libnewrelic.h&quot; Copy"
      },
      "id": "617e5b3764441f4c66fbe0bb"
    },
    {
      "sections": [
        "Update your C SDK library",
        "Update your C SDK code library"
      ],
      "title": "Update your C SDK library",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "697c24bac00edcaec09dd8b875bbf6d30f1f370c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/update-your-c-sdk-library/",
      "published_at": "2021-12-05T04:01:49Z",
      "updated_at": "2021-10-23T20:03:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure you have the most up-to-date version of the New Relic C SDK for your application's code library, check the release notes. Update your C SDK code library To update your application's code library to the latest version of New Relic's C SDK: Review the C SDK library changes to verify your code is compatible. Manually update the code for your app as applicable. Compile the C SDK code, using the make command, to create the latest version of the libnewrelic.a and link it into your application or service. If applicable, redeploy your application to your test environment. Generate traffic for your application, then check your its c_sdk.log file and newrelic-daemon.log output for any errors. Redeploy your application to your production environment. Wait a few minutes for your application to send data to New Relic. Then, check your application's performance in New Relic. If no data appears within a few minutes, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update your <em>C</em> <em>SDK</em> library",
        "sections": "Update your <em>C</em> <em>SDK</em> library",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "To ensure you have the most up-to-date version of the New Relic <em>C</em> <em>SDK</em> for your application&#x27;s code library, check the release notes. Update your <em>C</em> <em>SDK</em> code library To update your application&#x27;s code library to the latest version of New Relic&#x27;s <em>C</em> <em>SDK</em>: Review the <em>C</em> <em>SDK</em> library changes to verify your"
      },
      "id": "617e6cda64441f9dd0fbd32e"
    }
  ],
  "/docs/apm/agents/c-sdk/install-configure/install-c-sdk-compile-link-your-code": [
    {
      "sections": [
        "C SDK configuration",
        "Change configuration settings",
        "Change app name (alias) in UI",
        "Change app name in configuration",
        "Caution",
        "View logs for your APM and infrastructure data"
      ],
      "title": "C SDK configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "c1121d9af1643bf40ebfa749aa7d26a14fc59233",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/c-sdk-configuration/",
      "published_at": "2021-12-05T04:13:36Z",
      "updated_at": "2021-11-15T05:36:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your C application requires two configuration values: Application's name: app_name New Relic license key: license_key All other configuration values are optional, and typically the default settings do not need to be changed. However, when necessary, you can adjust New Relic's C SDK configuration. This document is a quick reference for using some basic configuration options with the C SDK API. For detailed information about changing your configuration settings, including code values and examples, see the C SDK's configuration GUIDE.md on GitHub. Change configuration settings Here are examples of some available configuration options you can change, as defined in the C SDK's public header, libnewrelic.h. C SDK configuration options Comments General configuration settings To set or change the app name, set the license key, logging level, transaction tracing, datastore tracing, etc., use: newrelic_app_config_t Additional transaction tracing configuration To enable the transaction tracer and to configure what transaction durations are considered for reporting a trace to New Relic, use: newrelic_transaction_tracer_config_t Datastore segments To configure whether a database name and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the C SDK To set the socket endpoint for agent-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application's alias from the Application settings page in the New Relic UI. This is useful, for example, to give your application a different name, yet keep historic data under the new alias. For more information, see Name your application. New Relic's C SDK does not support server-side configuration. However, you can also use this Application settings page in the UI to set your application's Apdex T threshold. To change the application's alias or Apdex T threshold in the UI go to one.newrelic.com > APM > (select an app) > Settings > Application. Change app name in configuration If you change your application's name in your configuration settings, this will result in the same app appearing in the UI with a new name. Any historic data (based on the data retention schedule) will only exist under the old name. (To rename your application but still keep historic data, use the UI settings to change the alias.) If you need to change your application's name in your configuration after your application is connected to the daemon: Make a new config with a call to newrelic_create_app_config() using the new application name. Make a new connected app with a call to newrelic_create_app(). Caution Timing is everything. Switching application names during a single application execution may mean that your instrumented data is sent under the new application name. View logs for your APM and infrastructure data You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.48424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "sections": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the <em>C</em> <em>SDK</em> To set the socket endpoint for <em>agent</em>-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application&#x27;s alias from the Application settings page in the New"
      },
      "id": "617e5154e7b9d27dc5c06406"
    },
    {
      "sections": [
        "Docker and other container environments: Install C SDK",
        "Install C SDK in container environment",
        "Caution"
      ],
      "title": "Docker and other container environments: Install C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "9f7f514c867c46d447a624d5a59962082cc5a429",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/docker-other-container-environments-install-c-sdk/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can install the New Relic C SDK on a Docker container (or other container) to monitor one or more of your C applications. Install C SDK in container environment Requirements: Meet C SDK requirements C SDK version 1.2 or higher Caution Data transmitted from the agent to the daemon is not encrypted. We recommend only using a private network connection between the agent and daemon. This only applies when the agent and daemon are running on different hosts. To install C SDK for a container environment, we recommend installing the C SDK daemon on a separate docker container: Install the daemon by cloning the C SDK repository and building the daemon. This is done most effectively via the command make daemon. See the README.md for further details. If you are using Docker, you can use the C SDK daemon image on Dockerhub. Start the daemon using --address and --watchdog-foreground arguments. The --address argument is used to set a port where the daemon is accepting connections. The --watchdog-foreground argument ensures that the daemon runs in the foreground. Then, use the C SDK in your containerized application: Follow the steps to add the C SDK to your code. Point the C SDK to the daemon by adding a newrelic_init call and passing a valid address argument. The value for this argument must be HOST:PORT, where HOST is the name or IP address of the host where the daemon is running, and PORT is the port number where the daemon is listening.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.49847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "sections": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "You can <em>install</em> the New Relic <em>C</em> <em>SDK</em> on a Docker container (or other container) to monitor one or more of your <em>C</em> applications. <em>Install</em> <em>C</em> <em>SDK</em> in container environment Requirements: Meet <em>C</em> <em>SDK</em> requirements <em>C</em> <em>SDK</em> version 1.2 or higher Caution Data transmitted from the <em>agent</em> to the daemon"
      },
      "id": "617e586828ccbc28fd8003f8"
    },
    {
      "sections": [
        "Update your C SDK library",
        "Update your C SDK code library"
      ],
      "title": "Update your C SDK library",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "697c24bac00edcaec09dd8b875bbf6d30f1f370c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/update-your-c-sdk-library/",
      "published_at": "2021-12-05T04:01:49Z",
      "updated_at": "2021-10-23T20:03:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure you have the most up-to-date version of the New Relic C SDK for your application's code library, check the release notes. Update your C SDK code library To update your application's code library to the latest version of New Relic's C SDK: Review the C SDK library changes to verify your code is compatible. Manually update the code for your app as applicable. Compile the C SDK code, using the make command, to create the latest version of the libnewrelic.a and link it into your application or service. If applicable, redeploy your application to your test environment. Generate traffic for your application, then check your its c_sdk.log file and newrelic-daemon.log output for any errors. Redeploy your application to your production environment. Wait a few minutes for your application to send data to New Relic. Then, check your application's performance in New Relic. If no data appears within a few minutes, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update your <em>C</em> <em>SDK</em> library",
        "sections": "Update your <em>C</em> <em>SDK</em> library",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "To ensure you have the most up-to-date version of the New Relic <em>C</em> <em>SDK</em> for your application&#x27;s code library, check the release notes. Update your <em>C</em> <em>SDK</em> code library To update your application&#x27;s code library to the latest version of New Relic&#x27;s <em>C</em> <em>SDK</em>: Review the <em>C</em> <em>SDK</em> library changes to verify your"
      },
      "id": "617e6cda64441f9dd0fbd32e"
    }
  ],
  "/docs/apm/agents/c-sdk/install-configure/uninstall-remove-c-sdk": [
    {
      "sections": [
        "C SDK configuration",
        "Change configuration settings",
        "Change app name (alias) in UI",
        "Change app name in configuration",
        "Caution",
        "View logs for your APM and infrastructure data"
      ],
      "title": "C SDK configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "c1121d9af1643bf40ebfa749aa7d26a14fc59233",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/c-sdk-configuration/",
      "published_at": "2021-12-05T04:13:36Z",
      "updated_at": "2021-11-15T05:36:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your C application requires two configuration values: Application's name: app_name New Relic license key: license_key All other configuration values are optional, and typically the default settings do not need to be changed. However, when necessary, you can adjust New Relic's C SDK configuration. This document is a quick reference for using some basic configuration options with the C SDK API. For detailed information about changing your configuration settings, including code values and examples, see the C SDK's configuration GUIDE.md on GitHub. Change configuration settings Here are examples of some available configuration options you can change, as defined in the C SDK's public header, libnewrelic.h. C SDK configuration options Comments General configuration settings To set or change the app name, set the license key, logging level, transaction tracing, datastore tracing, etc., use: newrelic_app_config_t Additional transaction tracing configuration To enable the transaction tracer and to configure what transaction durations are considered for reporting a trace to New Relic, use: newrelic_transaction_tracer_config_t Datastore segments To configure whether a database name and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the C SDK To set the socket endpoint for agent-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application's alias from the Application settings page in the New Relic UI. This is useful, for example, to give your application a different name, yet keep historic data under the new alias. For more information, see Name your application. New Relic's C SDK does not support server-side configuration. However, you can also use this Application settings page in the UI to set your application's Apdex T threshold. To change the application's alias or Apdex T threshold in the UI go to one.newrelic.com > APM > (select an app) > Settings > Application. Change app name in configuration If you change your application's name in your configuration settings, this will result in the same app appearing in the UI with a new name. Any historic data (based on the data retention schedule) will only exist under the old name. (To rename your application but still keep historic data, use the UI settings to change the alias.) If you need to change your application's name in your configuration after your application is connected to the daemon: Make a new config with a call to newrelic_create_app_config() using the new application name. Make a new connected app with a call to newrelic_create_app(). Caution Timing is everything. Switching application names during a single application execution may mean that your instrumented data is sent under the new application name. View logs for your APM and infrastructure data You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.48422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "sections": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the <em>C</em> <em>SDK</em> To set the socket endpoint for <em>agent</em>-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application&#x27;s alias from the Application settings page in the New"
      },
      "id": "617e5154e7b9d27dc5c06406"
    },
    {
      "sections": [
        "Docker and other container environments: Install C SDK",
        "Install C SDK in container environment",
        "Caution"
      ],
      "title": "Docker and other container environments: Install C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "9f7f514c867c46d447a624d5a59962082cc5a429",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/docker-other-container-environments-install-c-sdk/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can install the New Relic C SDK on a Docker container (or other container) to monitor one or more of your C applications. Install C SDK in container environment Requirements: Meet C SDK requirements C SDK version 1.2 or higher Caution Data transmitted from the agent to the daemon is not encrypted. We recommend only using a private network connection between the agent and daemon. This only applies when the agent and daemon are running on different hosts. To install C SDK for a container environment, we recommend installing the C SDK daemon on a separate docker container: Install the daemon by cloning the C SDK repository and building the daemon. This is done most effectively via the command make daemon. See the README.md for further details. If you are using Docker, you can use the C SDK daemon image on Dockerhub. Start the daemon using --address and --watchdog-foreground arguments. The --address argument is used to set a port where the daemon is accepting connections. The --watchdog-foreground argument ensures that the daemon runs in the foreground. Then, use the C SDK in your containerized application: Follow the steps to add the C SDK to your code. Point the C SDK to the daemon by adding a newrelic_init call and passing a valid address argument. The value for this argument must be HOST:PORT, where HOST is the name or IP address of the host where the daemon is running, and PORT is the port number where the daemon is listening.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.49847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "sections": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "You can <em>install</em> the New Relic <em>C</em> <em>SDK</em> on a Docker container (or other container) to monitor one or more of your <em>C</em> applications. <em>Install</em> <em>C</em> <em>SDK</em> in container environment Requirements: Meet <em>C</em> <em>SDK</em> requirements <em>C</em> <em>SDK</em> version 1.2 or higher Caution Data transmitted from the <em>agent</em> to the daemon"
      },
      "id": "617e586828ccbc28fd8003f8"
    },
    {
      "sections": [
        "Update your C SDK library",
        "Update your C SDK code library"
      ],
      "title": "Update your C SDK library",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "697c24bac00edcaec09dd8b875bbf6d30f1f370c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/update-your-c-sdk-library/",
      "published_at": "2021-12-05T04:01:49Z",
      "updated_at": "2021-10-23T20:03:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure you have the most up-to-date version of the New Relic C SDK for your application's code library, check the release notes. Update your C SDK code library To update your application's code library to the latest version of New Relic's C SDK: Review the C SDK library changes to verify your code is compatible. Manually update the code for your app as applicable. Compile the C SDK code, using the make command, to create the latest version of the libnewrelic.a and link it into your application or service. If applicable, redeploy your application to your test environment. Generate traffic for your application, then check your its c_sdk.log file and newrelic-daemon.log output for any errors. Redeploy your application to your production environment. Wait a few minutes for your application to send data to New Relic. Then, check your application's performance in New Relic. If no data appears within a few minutes, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.4397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update your <em>C</em> <em>SDK</em> library",
        "sections": "Update your <em>C</em> <em>SDK</em> library",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "To ensure you have the most up-to-date version of the New Relic <em>C</em> <em>SDK</em> for your application&#x27;s code library, check the release notes. Update your <em>C</em> <em>SDK</em> code library To update your application&#x27;s code library to the latest version of New Relic&#x27;s <em>C</em> <em>SDK</em>: Review the <em>C</em> <em>SDK</em> library changes to verify your"
      },
      "id": "617e6cda64441f9dd0fbd32e"
    }
  ],
  "/docs/apm/agents/c-sdk/install-configure/update-your-c-sdk-library": [
    {
      "sections": [
        "C SDK configuration",
        "Change configuration settings",
        "Change app name (alias) in UI",
        "Change app name in configuration",
        "Caution",
        "View logs for your APM and infrastructure data"
      ],
      "title": "C SDK configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "c1121d9af1643bf40ebfa749aa7d26a14fc59233",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/c-sdk-configuration/",
      "published_at": "2021-12-05T04:13:36Z",
      "updated_at": "2021-11-15T05:36:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your C application requires two configuration values: Application's name: app_name New Relic license key: license_key All other configuration values are optional, and typically the default settings do not need to be changed. However, when necessary, you can adjust New Relic's C SDK configuration. This document is a quick reference for using some basic configuration options with the C SDK API. For detailed information about changing your configuration settings, including code values and examples, see the C SDK's configuration GUIDE.md on GitHub. Change configuration settings Here are examples of some available configuration options you can change, as defined in the C SDK's public header, libnewrelic.h. C SDK configuration options Comments General configuration settings To set or change the app name, set the license key, logging level, transaction tracing, datastore tracing, etc., use: newrelic_app_config_t Additional transaction tracing configuration To enable the transaction tracer and to configure what transaction durations are considered for reporting a trace to New Relic, use: newrelic_transaction_tracer_config_t Datastore segments To configure whether a database name and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the C SDK To set the socket endpoint for agent-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application's alias from the Application settings page in the New Relic UI. This is useful, for example, to give your application a different name, yet keep historic data under the new alias. For more information, see Name your application. New Relic's C SDK does not support server-side configuration. However, you can also use this Application settings page in the UI to set your application's Apdex T threshold. To change the application's alias or Apdex T threshold in the UI go to one.newrelic.com > APM > (select an app) > Settings > Application. Change app name in configuration If you change your application's name in your configuration settings, this will result in the same app appearing in the UI with a new name. Any historic data (based on the data retention schedule) will only exist under the old name. (To rename your application but still keep historic data, use the UI settings to change the alias.) If you need to change your application's name in your configuration after your application is connected to the daemon: Make a new config with a call to newrelic_create_app_config() using the new application name. Make a new connected app with a call to newrelic_create_app(). Caution Timing is everything. Switching application names during a single application execution may mean that your instrumented data is sent under the new application name. View logs for your APM and infrastructure data You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.48422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "sections": "<em>C</em> <em>SDK</em> <em>configuration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": " and datastore instance name are reported, use: newrelic_datastore_segment_config_t Communication with the <em>C</em> <em>SDK</em> To set the socket endpoint for <em>agent</em>-to-daemon communications, use: newrelic_init Change app name (alias) in UI You can change your application&#x27;s alias from the Application settings page in the New"
      },
      "id": "617e5154e7b9d27dc5c06406"
    },
    {
      "sections": [
        "Docker and other container environments: Install C SDK",
        "Install C SDK in container environment",
        "Caution"
      ],
      "title": "Docker and other container environments: Install C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "9f7f514c867c46d447a624d5a59962082cc5a429",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/docker-other-container-environments-install-c-sdk/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can install the New Relic C SDK on a Docker container (or other container) to monitor one or more of your C applications. Install C SDK in container environment Requirements: Meet C SDK requirements C SDK version 1.2 or higher Caution Data transmitted from the agent to the daemon is not encrypted. We recommend only using a private network connection between the agent and daemon. This only applies when the agent and daemon are running on different hosts. To install C SDK for a container environment, we recommend installing the C SDK daemon on a separate docker container: Install the daemon by cloning the C SDK repository and building the daemon. This is done most effectively via the command make daemon. See the README.md for further details. If you are using Docker, you can use the C SDK daemon image on Dockerhub. Start the daemon using --address and --watchdog-foreground arguments. The --address argument is used to set a port where the daemon is accepting connections. The --watchdog-foreground argument ensures that the daemon runs in the foreground. Then, use the C SDK in your containerized application: Follow the steps to add the C SDK to your code. Point the C SDK to the daemon by adding a newrelic_init call and passing a valid address argument. The value for this argument must be HOST:PORT, where HOST is the name or IP address of the host where the daemon is running, and PORT is the port number where the daemon is listening.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.49847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "sections": "Docker <em>and</em> other <em>container</em> environments: <em>Install</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": "You can <em>install</em> the New Relic <em>C</em> <em>SDK</em> on a Docker container (or other container) to monitor one or more of your <em>C</em> applications. <em>Install</em> <em>C</em> <em>SDK</em> in container environment Requirements: Meet <em>C</em> <em>SDK</em> requirements <em>C</em> <em>SDK</em> version 1.2 or higher Caution Data transmitted from the <em>agent</em> to the daemon"
      },
      "id": "617e586828ccbc28fd8003f8"
    },
    {
      "sections": [
        "Install the C SDK: Compile and link your code",
        "Add the C SDK to your code",
        "1. Verify requirements.",
        "2. Include the provided header file.",
        "3. Configure logging.",
        "4. Be ready to provide a meaningful app name.",
        "5. Finish instrumenting your code.",
        "6. Compile and link your app.",
        "7. Start the daemon and check logs.",
        "Tip",
        "View app performance in New Relic"
      ],
      "title": "Install the C SDK: Compile and link your code",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Install and configure"
      ],
      "external_id": "f403769d1be59206b211c778bd56a83c88bf4887",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/install-configure/install-c-sdk-compile-link-your-code/",
      "published_at": "2021-12-05T03:55:58Z",
      "updated_at": "2021-10-23T20:03:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our C SDK auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic C SDK installation. If you don't have one already, create a New Relic account. It's free, forever. Add C data Add the C SDK to your code To monitor your application with New Relic's C SDK, instrument the features you want to use: Web transactions, transaction events, non-web transactions Segments (for additional levels of timing details) Attributes Errors Then compile and link your app against the C SDK static library. To install the C SDK into your application's code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic's compatibility and requirements for the C SDK. Make sure you have a New Relic license key. 2. Include the provided header file. #include \"libnewrelic.h\" Copy 3. Configure logging. Follow the procedures to configure logging for both the C SDK and the daemon. For example: if (!newrelic_configure_log(\"./c_sdk.log\", NEWRELIC_LOG_INFO)) { printf(\"Error configuring logging.\\n\"); return -1; } Copy 4. Be ready to provide a meaningful app name. Be prepared to provide a meaningful app name in your initial application configuration; for example: newrelic_app_config_t* config; /* ... */ config = newrelic_create_app_config(\"Your Application Name\", \"LICENSE_KEY_HERE\"); Copy You may give your application up to three different names, separated by ;. Giving your application multiple names allows you to aggregate metrics for multiple agents across an entire app or service; for example: config = newrelic_create_app_config(\"YOUR_APP_NAME;APP_GROUP_1;ALL_APPS\", \"LICENSE_KEY_HERE\"); Copy With the application configured, you can create a new application to connect to the daemon. newrelic_app_t* app; /* ... */ if (!newrelic_init(NULL, 0)) { printf(\"Error connecting to daemon.\\n\"); return -1; } /* Wait up to 10 seconds for the SDK to connect to the daemon */ app = newrelic_create_app(config, 10000); newrelic_destroy_app_config(&config); Copy 5. Finish instrumenting your code. To finish instrumenting your code, refer to the example programs in the C SDK Examples documentation on GitHub. For more information about source code and features, see the C SDK's source documentation for libnewrelic.h on GitHub. 6. Compile and link your app. The C SDK's libnewrelic.a is a static library that is already linked with the libpcre and libpthread libraries. To avoid symbol collisions in this linking step, be sure to link against each of these libraries. In addition, to take full advantage of error traces in APM's Error analytics page, link your application using GNU's -rdynamic linker flag. This will allow more meaningful information to appear in the stack trace for the error recording on a transaction using the C SDK's newrelic_notice_error API call. For example: gcc -o test_app test_app.c -L. -lnewrelic -lpcre -lm -pthread -rdynamic Copy 7. Start the daemon and check logs. Start the C SDK's daemon. For example: ./newrelic-daemon -f -logfile newrelic-daemon.log -loglevel debug Copy Check the output in the c_sdk.log and newrelic-daemon.log files. The C SDK's architecture requires that the daemon must be invoked first before your instrumented application is invoked. Tip To see all of the available options for the C daemon: At the command line, type: ./newrelic-daemon --help Copy For more information, see the C SDK GUIDE.md. View app performance in New Relic To view your app's performance with APM: Generate some traffic for your app, then wait a few minutes for your app to send data to New Relic. Explore your app's data in the APM UI. If no data appears within a few minutes, check your c_sdk.log and newrelic-daemon.log files for errors. If you still have problems, follow the troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.43968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "sections": "<em>Install</em> the <em>C</em> <em>SDK</em>: <em>Compile</em> <em>and</em> link your <em>code</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em>",
        "body": ". To <em>install</em> the <em>C</em> <em>SDK</em> into your application&#x27;s code library, follow this procedure. 1. Verify requirements. Make sure your application meets New Relic&#x27;s compatibility and requirements for the <em>C</em> <em>SDK</em>. Make sure you have a New Relic license key. 2. Include the provided header file. #include &quot;libnewrelic.h&quot; Copy"
      },
      "id": "617e5b3764441f4c66fbe0bb"
    }
  ],
  "/docs/apm/agents/c-sdk/instrumentation/enable-distributed-tracing-your-c-applications": [
    {
      "sections": [
        "Use default or custom attributes (C SDK)",
        "View and use attributes",
        "C-specific attributes",
        "Important"
      ],
      "title": "Use default or custom attributes (C SDK)",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "0be06d9b5722e32ba9eb200dea589c1e149716d0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/instrumentation/use-default-or-custom-attributes-c-sdk/",
      "published_at": "2021-12-05T05:26:42Z",
      "updated_at": "2021-10-23T20:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In New Relic, attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can help you gain greater insight into your application and query your data. View and use attributes Both default APM attributes and custom attributes for your C application appear in: APM transaction traces and error analytics APM events C-specific attributes Important Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur. To add custom attributes to your C application, call one of the attribute functions in the C SDK API; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.34181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use default or <em>custom</em> attributes (<em>C</em> <em>SDK</em>)",
        "sections": "Use default or <em>custom</em> attributes (<em>C</em> <em>SDK</em>)",
        "tags": "<em>Agents</em>",
        "body": ", call one of the attribute functions in the <em>C</em> <em>SDK</em> API; for example, newrelic_add_attribute_double(). The key name for your custom attribute depends on what you specify when you call the function."
      },
      "id": "617e6d7464441f001afbd364"
    },
    {
      "sections": [
        "Instrument your app with the C SDK",
        "Instrument a transaction",
        "Instrument segments",
        "Instrument calls to external services",
        "Instrument calls to arbitrary code (custom segments)",
        "Instrument calls to datastores",
        "Tip",
        "Report slow query traces for datastore segments (SQL only)",
        "Important",
        "Instrument errors",
        "Avoid metric grouping issues"
      ],
      "title": "Instrument your app with the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "9cfd92acd1dc3e5185922d39462fdcbb3accd23e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/instrumentation/instrument-your-app-c-sdk/",
      "published_at": "2021-12-05T03:41:56Z",
      "updated_at": "2021-10-23T20:07:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to monitor any application on Linux using a language that can import C libraries, you must: Create a config using newrelic_new_app_config(), connect to the daemon using newrelic_init(), and connect your application using newrelic_create_app(). For more information, see the C SDK installation procedures. Manually instrument transactions using the C SDK, as described in this document. New Relic defines a web or non-web transaction as one logical unit of work in a software application. After you manually instrument transactions in your source code by adding New Relic functions, you can view the data on the Transactions page in New Relic. You can also instrument segments of a transaction and errors. Instrument a transaction To instrument a transaction so you can monitor it, wrap the New Relic functions that start and stop instrumentation around the transaction. The function that you use depends on whether you want to instrument a web or non-web transaction. In the following example, the app is created after a call to newrelic_create_app(). For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Add the following code immediately before the transaction that you want to monitor, supplying the required parameters. For web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy For non-web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_non_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy Add newrelic_end_transaction() immediately after the web or non-web transaction that you want to monitor, supplying a pointer the transaction, &txn, as a parameter. Instrument segments Once you instrument a transaction using the C SDK, you can instrument segments in it. By instrumenting segments, you can monitor the individual functions and calls inside a transaction. Segments example You have a transaction associated with a checkout process, which processes both shipping information and credit card information. You can instrument your application to break that transaction up into two segments: one segment for shipping and one segment for payment. You can instrument segments to monitor the following kinds of calls: External services using external segments Custom segments for arbitrary code Datastores using datastore segments Slow query traces (SQL databases only) For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to external services To monitor calls to external services, instrument external segments that are within an instrumented transaction. External segments appear in the Transactions page's Breakdown table and the External services page. To instrument an external segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_external_segment_params_t that describes the external segment, supplying the required parameters. Add newrelic_start_external_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to arbitrary code (custom segments) To monitor calls to arbitrary code, instrument custom segments that are within an instrumented transaction. Custom segments appear in the Breakdown table on the Transactions page. To instrument a custom segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Add newrelic_start_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to datastores To monitor calls to datastores, instrument the datastore segments within an instrumented transaction. Datastore segments appear in the Breakdown table and Databases tab on the Transactions page in New Relic. You can also view datastore segments as a databaseDuration attribute of APM Transaction events. To instrument a datastore segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_datastore_segment_params_t that describes the datastore segment. Add newrelic_start_datastore_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Tip To configure how the database name and database instance are reported, use the newrelic_datastore_segment_config_t. Report slow query traces for datastore segments (SQL only) Important You can report slow query traces for SQL databases only. To report slow query trace data for datastore segments that take longer than the time you specify, enable these settings in your newrelic_app_config_t: Enable slow query tracing by setting transaction_tracer.datastore_reporting.enabled to true. To set the threshold, add a length of time in microseconds to transaction_tracer.datastore_reporting.threshold_us. Then, if a datastore call takes longer than the threshold, the C SDK reports it as a slow query. To view slow query trace details, use the Databases and Slow queries pages in New Relic. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument errors In order to use the C SDK to monitor errors in transactions, you must manually instrument your source code by adding the newrelic_notice_error() function to it. Transaction errors and error traces appear on the Error analytics page in New Relic. The C SDK reports the total number of errors and up to 100 error traces per minute. You can also view, query, and visualize transaction errors as APM TransactionError events. Tip To include function calls in error traces, use GNU's -rdynamic linker flag to link your apps when compiling. The -rdynamic linker flag gives you more meaningful error traces. To instrument errors in transactions: Start a transaction. Record an error with newrelic_notice_error(), supplying the required parameters. End the transaction, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Avoid metric grouping issues When an account or application sends many individual metrics that could be better managed in groups, New Relic uses the term metric grouping issue or MGI to describe this situation. If your application sends unnecessarily large amounts of data to New Relic, this reduces the effectiveness of charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. To help prevent this situation, see Metric grouping issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.34125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> your app with the <em>C</em> <em>SDK</em>",
        "sections": "<em>Instrument</em> your app with the <em>C</em> <em>SDK</em>",
        "tags": "<em>Agents</em>",
        "body": " installation procedures. Manually <em>instrument</em> transactions using the <em>C</em> <em>SDK</em>, as described in this document. New Relic defines a web or non-web transaction as one logical unit of work in a software application. After you manually <em>instrument</em> transactions in your source code by adding New Relic functions, you can"
      },
      "id": "617e6d38196a674d6af7c535"
    },
    {
      "sections": [
        "Guide to using the C SDK API",
        "Ensure your customization is thread-safe",
        "Monitor transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Instrument calls to external services",
        "Collect or log errors",
        "Send custom data from your app",
        "Custom events",
        "Tip",
        "Custom event attributes",
        "Custom metrics",
        "Important",
        "Monitor desktop browser performance",
        "Change configuration settings"
      ],
      "title": "Guide to using the C SDK API",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "31ba3be376985cc4ed47f8a5f0069720e229ba8d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/c-sdk/instrumentation/guide-using-c-sdk-api/",
      "published_at": "2021-12-05T05:25:54Z",
      "updated_at": "2021-10-23T20:07:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's C SDK monitors your applications and microservices to help you identify and solve performance issues. C applications run from a compiled, native binary file. In order to monitor transactions, you must manually instrument your code by adding New Relic methods to it. This guide helps you to decide which method to use. The method's code, required parameters, and examples reside in New Relic's C SDK documentation on GitHub. Ensure your customization is thread-safe The C SDK supports instrumentation of multi-threaded applications, but it must be initialized before instrumenting multiple threads. When calling any of the following functions, ensure that they are called on the main thread before any other C SDK functions are called: newrelic_configure_log newrelic_init Monitor transactions Before you manually instrument your code to monitor transactions: Check the C SDK compatibility and requirements for your app. Make sure you are using the latest version of the C SDK library, and update as needed. If you want to... Use this method... Start timing a web transaction newrelic_start_web_transaction() Start timing a non-web transaction newrelic_start_non_web_transaction() Stop timing a transaction newrelic_end_transaction() Prevent a transaction from reporting to New Relic newrelic_ignore_transaction() Time specific methods using segments If a transaction is already visible in New Relic, but you do not have enough data about a particular method that was called during that transaction, you can instrument segments. For example, if you want to time a method that has complex logic, you can create a segment for each of the methods in the transaction. To instrument a method within an existing transaction, create segments for any of the following: External services Functions or other arbitrary blocks of code (using custom segments) Datastores Slow query traces (SQL datastores only) If you want to... Use this method... Start timing a segment newrelic_start_datastore_segment()newrelic_start_external_segment()newrelic_start_segment() Stop timing a segment newrelic_end_segment() Manually parent segments newrelic_set_segment_parent() and newrelic_set_segment_parent_root() This is useful, for example, with an asynchronous process when you want to visualize a segment as a child of the transaction's top-level call. For more information, see the manual segment parenting documentation on GitHub. Segments are recorded on the active transaction. When adding a segment to an active transaction, you need access to the newrelic_txn_t* or transaction pointer, returned by newrelic_start_web_transaction() or newrelic_start_non_web_transaction(). Enhance the metadata of a transaction You can manage the metadata that New Relic reports for transactions. This is useful when you want a different level of detail for your transactions. For example: If you are experiencing a metric grouping issue, you can change the default names for your transactions to make them more identifiable. If you want to create dashboards for your transactions, you can add custom attributes. If you want to... Use this method... Add metadata (such as your customer's account name or subscription level) to your transaction Add custom attributes to your transaction based on their type: newrelic_add_attribute_int() newrelic_add_attribute_string() newrelic_add_attribute_long() newrelic_add_attribute_double() Instrument calls to external services Use these methods to collect data about your app's connections to other apps or databases: If you want to... Use this method... See the path that a request takes as it travels through a distributed system Follow the procedures to enable and instrument distributed tracing. Time a call to an external resource (such as an external service, database server, or message queue) Follow the procedures to Instrument calls to external segments. Collect or log errors The C SDK detects errors automatically. If you want to change the way it reports errors to New Relic, change the error collector configuration. If you want to... Use this method... Set logging levels for your app Use newrelic_configure_log() to configure the C SDK logs and command-line flags to configure the C daemon logs. For more information, see the C SDK logging documentation. Report an error newrelic_notice_error() Send custom data from your app To record custom data with the C SDK, you can use any of the following methods: Custom events: At New Relic, event data is a fundamental data type. Event data represents a record of a single event at a particular moment in time. This is useful to view or query specific details. Custom event attributes: To include additional metadata about the event, you can add key/value pairs (custom-attributes) to your custom event. Custom metrics: Metric timeslice data is the statistical measure of data that New Relic aggregates so that you can view it in the UI and chart it. Typically metric data has a longer retention period than event data. Custom events The C SDK provides a custom events API that allows you to send custom events to New Relic. To send an event, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For example: // txn is a newrelic_txn_t*, created via newrelic_start_web_transaction newrelic_custom_event_t* custom_event=0; custom_event = newrelic_create_custom_event(\"aTypeForYourEvent\"); newrelic_record_custom_event(txn, &custom_event); Copy Be sure to review the custom data requirements and limits for guidance on what values are and are not allowed inside your custom event. For more information, see Custom events in APM. Tip If you created a custom event but need to remove it before the transaction has ended, use newrelic_discard_custom_event(&custom_event);. Custom event attributes You can also add int, long, double, and char* (string) attributes to your custom event by using the newrelic_custom_event_add_* family of functions. For example: // Example custom attributes: newrelic_custom_event_t* custom_event=0; custom_event = newrelic_create_custom_event(\"aTypeForYourEvent\"); newrelic_custom_event_add_attribute_int(custom_event, \"keya\", 42); newrelic_custom_event_add_attribute_long(custom_event, \"keyb\", 84); newrelic_custom_event_add_attribute_double(custom_event, \"keyc\", 42.42); newrelic_custom_event_add_attribute_string(custom_event, \"keyd\", \"A string\"); newrelic_record_custom_event(txn, &custom_event); Copy For more information, see the documentation about custom attributes. Custom metrics The C SDK provides the newrelic_record_custom_metric() function. This allows you to record time-based performance data using an API call, such as: Transaction timing data Computer resource data Subscription or purchasing data To create a custom metric, provide a name or other identifier and an amount of time in milliseconds to the function, along with the active transaction. Important Always prefix custom metric names with Custom/. For example: // txn is a newrelic_txn_t*, created via newrelic_start_web_transaction // Record a metric value of 100ms in the transaction txn newrelic_record_custom_metric(txn, \"Custom/MyMetric/My_label\", 100); Copy For more information, see Collect custom metrics. Here are some ways to use your custom data. For code details and examples for these options, see the New Relic globals documentation on GitHub. If you want to... Use this method... Create a custom event to populate with a timestamp and attributes. newrelic_create_custom_event() Timestamp and add the custom event to the current transaction so you can query or visualize it. newrelic_record_custom_event() Enhance your custom event with additional metadata. Add custom event attributes to your custom event based on type: newrelic_custom_event_add_attribute_double() newrelic_custom_event_add_attribute_int() newrelic_custom_event_add_attribute_long() newrelic_custom_event_add_attribute_string() Discard a custom event after it was created, but before its transaction has ended, to avoid reporting it to New Relic. newrelic_discard_custom_event This is necessary to free the allocated memory for your unwanted custom event in order to avoid leaks in your program. Report a custom performance duration that you can search or chart. newrelic_record_custom_metric() Monitor desktop browser performance To monitor desktop browser performance for your application, install the browser agent using the copy/paste method. Change configuration settings Typically the default settings for your application's configuration do not need to be changed. However, when necessary, you can adjust some of the settings. For more information, see the C SDK configuration documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.34125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Guide to using the <em>C</em> <em>SDK</em> API",
        "sections": "Guide to using the <em>C</em> <em>SDK</em> API",
        "tags": "<em>Agents</em>",
        "body": "New Relic&#x27;s <em>C</em> <em>SDK</em> monitors your applications and microservices to help you identify and solve performance issues. <em>C</em> applications run from a compiled, native binary file. In order to monitor transactions, you must manually <em>instrument</em> your code by adding New Relic methods to it. This guide helps you"
      },
      "id": "617e6d0ae7b9d29b84c03e9f"
    }
  ]
}