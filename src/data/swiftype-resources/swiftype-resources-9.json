{
  "/docs/browser/new-relic-browser/guides/guide-using-browser-spa-apis": [
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-18T07:16:54Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.21177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    },
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-18T18:43:26Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.033554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.70115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/installation/disable-browser-monitoring": [
    {
      "sections": [
        "Install the browser monitoring agent",
        "Enable browser monitoring",
        "Deployment options",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Use REST API",
        "Browser agent types: Lite, Pro, Pro+SPA"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-10-18T18:58:27Z",
      "updated_at": "2021-08-08T05:47:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet, also referred to as an \"agent,\" to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. If you don't have one already, create a New Relic account. It's free, forever. Enable browser monitoring Browser Pro+SPA is the default agent when you enable browser monitoring. This automatically gives you access to all of our browser monitoring features. For more information about the browser monitoring options, see Browser agent types in this document. To enable browser monitoring: Go to one.newrelic.com, select Browser, and then select Add more data. Follow the instructions in the UI to add browser monitoring to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After installation is complete and you are seeing data, go to the App settings page for additional agent configuration, or to change the browser agent type. It may take several minutes after enabling the browser monitoring agent before your webpage data appear in New Relic. If have problems, follow our troubleshooting tips. Deployment options No matter which option you use to deploy browser monitoring, the end result is the same: the browser monitoring JavaScript snippet (also referred to as the \"agent\") is inserted into your app pages. The method you select depends on your preferences and business needs. Enable an APM-monitored app When enabling browser monitoring, you can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that's already being monitored by APM. APM-monitored apps are listed on your APM Applications index. Enable with copy/paste When enabling browser monitoring, you can manually insert the JavaScript snippet into your app's webpages. The copy/paste option gives you control over the exact placement of our JavaScript snippet, which is required to monitor the webpage's performance. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Some tips for using the JavaScript snippet: Placement in your webpage: Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. License key and app ID: Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. Our APM agents can instrument webpages with the required JavaScript for page load timing. If you are using an APM agent's API to manually add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Use REST API This information applies to apps that are also monitored by APM. The REST API lets you manage deployment outside the browser monitoring UI. This is useful for large organizations deploying multiple apps. Browser agent types: Lite, Pro, Pro+SPA We have three types of browser agents: Lite, Pro, and Pro+SPA. The agent type has no impact on your billing. Browser agent type Comparison Pro+SPA This is the default installed agent when you enable browser monitoring. What it includes: Gives you access to all of the Browser Pro features and to Single Page App (SPA) monitoring. Provides detailed page timing data and the most up-to-date New Relic features, including distributed tracing, for all types of applications. Pro+SPA is not limited only to single page applications. After install, you can downgrade anytime to the less advanced agents if you don't want or need SPA monitoring. Pro What it includes: Gives you access to the Browser Pro features. What it doesn't include: Lacks the functionality designed for single page app monitoring. Lite What it includes: Gives you information about some basic page load timing and browser user information. What it doesn't include: Lacks the Browser Pro features and SPA features. Details about how agent types relate to pricing: New Relic One pricing: This pricing plan has data ingest as a billing factor. If you want to reduce data ingest, you may want to consider downgrading to lesser agent types after install. Original pricing: Your access to browser monitoring features is gated by your subscription plan, not by the agent type. This means there is no reason not to use the default Pro+SPA agent. After initial agent installation is finished, you can go to the App settings page to edit your configuration or to change your subscription.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.795944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>browser</em> <em>monitoring</em> agent",
        "sections": "<em>Install</em> the <em>browser</em> <em>monitoring</em> agent",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ". To enable <em>browser</em> <em>monitoring</em>: Go to one.newrelic.com, select <em>Browser</em>, and then select Add more data. Follow the instructions in the UI to add <em>browser</em> <em>monitoring</em> to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After <em>installation</em>"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "sections": [
        "Update the browser agent",
        "Check your version number",
        "Check deployment method",
        "Update your APM-managed installation",
        "Update your copy/paste installation",
        "Caution",
        "Retrieve the snippet from the UI",
        "Extract the snippet with the REST API",
        "Update using the loader endpoint"
      ],
      "title": "Update the browser agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "88c27eeabc364683eae41935bd6a1b178cae36ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/installation/update-browser-agent/",
      "published_at": "2021-10-18T07:20:37Z",
      "updated_at": "2021-07-21T20:02:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Running the latest version of our browser agent ensures you can access all browser features and enhancements. To update to the latest version, check your version number, then follow the steps for either updating an APM-managed installation or upgrading a copy/paste installation. Check your version number To verify your browser version number: View the source code of a page which includes the JavaScript snippet. Search the page source for js-agent.newrelic.com/nr-. The numbers that follow nr- are your current version. For example, js-agent.newrelic.com/nr-593.min.js indicates you are running version 593 of the browser script. There are different agent types. The Pro+SPA agent has the format js-agent.newrelic.com/nr-spa-1184.min.js To verify the latest version of the browser script loader: Go to js-agent.newrelic.com/nr-loader-full-current.min.js . Search for js-agent.newrelic.com/nr-, then note the numbers that follow nr-. If the latest version number is higher than the number of the version you are currently running, update your browser agent. Check deployment method Your browser agent may have been deployed in two ways: either using a manual implementation (copying and pasting the snippet) or automatically instrumented using an APM agent. To check which deployment method was used, run this command in the JavaScript console: > newrelic.info.sa Copy If the command returns 1, then your browser agent used the copy/paste method. Update your APM-managed installation To update your APM-managed browser installation, restart your APM agent. Your app will automatically update to the latest JavaScript snippet. To ensure the new script registers, you may need to clear your cache. For more information, follow the troubleshooting procedures to manually check and clear the cache. Update your copy/paste installation Use any of the following options to access the browser JavaScript snippet needed to update a copy/paste installation. After accessing the snippet, be sure to replace all of your existing snippet with the new version. If you have a standalone installation with a few applications, you can retrieve the snippet from the UI, and then replace it with the new version. If you have many applications, you can use the REST API or the loader endpoint to automate the update process. Caution Do not simply change the version number in the existing snippet. This can result in incomplete data collection. For best results after you use any of the following options, always update the agent. Retrieve the snippet from the UI Download the latest version of the snippet: Go to one.newrelic.com > Browser > (select an app) > Application settings. This option is only available for standalone installations. Extract the snippet with the REST API To update the snippet using the New Relic REST API, follow the process for viewing a specific browser app. The loader_script attribute in your response will include the latest JavaScript snippet. This may be a good solution if you have many applications to manage, or if your browser app is linked to an APM app. Update using the loader endpoint To update the snippet from the New Relic loader endpoint, you can choose which type of browser agent you want: Pro+SPA endpoint Pro endpoint Lite endpoint These endpoints always point to the latest version of the agent. We recommend using the Pro+SPA agent. Read more about these agent types. These loader endpoints are generic and do not include your specific configuration data. To add your configuration data to the loaders: Find your browser application ID and license key: Follow standard procedures to use the New Relic UI or the REST API. Set your browser application ID and license key immediately after the snippet. NREUM.info = { applicationID: \"YOUR-APPLICATION-ID\", licenseKey: \"YOUR-BROWSER-LICENSE-KEY\" }; Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.10093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>browser</em> agent",
        "sections": "Update your APM-managed <em>installation</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Running the latest version of our <em>browser</em> agent ensures you can access all <em>browser</em> features and enhancements. To update to the latest version, check your version number, then follow the steps for either updating an APM-managed <em>installation</em> or upgrading a copy&#x2F;paste <em>installation</em>. Check your version"
      },
      "id": "603ec40c64441f245f4e8879"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.316444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ", follow the steps for troubleshooting <em>browser</em> <em>monitoring</em> <em>installation</em>. If you have a single-page style application and are expecting to see your route changes as views, consider using <em>browser</em> SPA <em>monitoring</em>, which provides an integrated view of initial page loads and route changes. If <em>browser</em> <em>monitoring</em>"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/installation/update-browser-agent": [
    {
      "sections": [
        "Install the browser monitoring agent",
        "Enable browser monitoring",
        "Deployment options",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Use REST API",
        "Browser agent types: Lite, Pro, Pro+SPA"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-10-18T18:58:27Z",
      "updated_at": "2021-08-08T05:47:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet, also referred to as an \"agent,\" to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. If you don't have one already, create a New Relic account. It's free, forever. Enable browser monitoring Browser Pro+SPA is the default agent when you enable browser monitoring. This automatically gives you access to all of our browser monitoring features. For more information about the browser monitoring options, see Browser agent types in this document. To enable browser monitoring: Go to one.newrelic.com, select Browser, and then select Add more data. Follow the instructions in the UI to add browser monitoring to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After installation is complete and you are seeing data, go to the App settings page for additional agent configuration, or to change the browser agent type. It may take several minutes after enabling the browser monitoring agent before your webpage data appear in New Relic. If have problems, follow our troubleshooting tips. Deployment options No matter which option you use to deploy browser monitoring, the end result is the same: the browser monitoring JavaScript snippet (also referred to as the \"agent\") is inserted into your app pages. The method you select depends on your preferences and business needs. Enable an APM-monitored app When enabling browser monitoring, you can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that's already being monitored by APM. APM-monitored apps are listed on your APM Applications index. Enable with copy/paste When enabling browser monitoring, you can manually insert the JavaScript snippet into your app's webpages. The copy/paste option gives you control over the exact placement of our JavaScript snippet, which is required to monitor the webpage's performance. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Some tips for using the JavaScript snippet: Placement in your webpage: Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. License key and app ID: Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. Our APM agents can instrument webpages with the required JavaScript for page load timing. If you are using an APM agent's API to manually add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Use REST API This information applies to apps that are also monitored by APM. The REST API lets you manage deployment outside the browser monitoring UI. This is useful for large organizations deploying multiple apps. Browser agent types: Lite, Pro, Pro+SPA We have three types of browser agents: Lite, Pro, and Pro+SPA. The agent type has no impact on your billing. Browser agent type Comparison Pro+SPA This is the default installed agent when you enable browser monitoring. What it includes: Gives you access to all of the Browser Pro features and to Single Page App (SPA) monitoring. Provides detailed page timing data and the most up-to-date New Relic features, including distributed tracing, for all types of applications. Pro+SPA is not limited only to single page applications. After install, you can downgrade anytime to the less advanced agents if you don't want or need SPA monitoring. Pro What it includes: Gives you access to the Browser Pro features. What it doesn't include: Lacks the functionality designed for single page app monitoring. Lite What it includes: Gives you information about some basic page load timing and browser user information. What it doesn't include: Lacks the Browser Pro features and SPA features. Details about how agent types relate to pricing: New Relic One pricing: This pricing plan has data ingest as a billing factor. If you want to reduce data ingest, you may want to consider downgrading to lesser agent types after install. Original pricing: Your access to browser monitoring features is gated by your subscription plan, not by the agent type. This means there is no reason not to use the default Pro+SPA agent. After initial agent installation is finished, you can go to the App settings page to edit your configuration or to change your subscription.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.795944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>browser</em> <em>monitoring</em> agent",
        "sections": "<em>Install</em> the <em>browser</em> <em>monitoring</em> agent",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ". To enable <em>browser</em> <em>monitoring</em>: Go to one.newrelic.com, select <em>Browser</em>, and then select Add more data. Follow the instructions in the UI to add <em>browser</em> <em>monitoring</em> to your app. Generate some traffic for your app, then wait a few minutes for data to appear in New Relic. Optional: After <em>installation</em>"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "sections": [
        "Disable browser monitoring",
        "Disable monitoring of specific pages/URLs",
        "Deployed with selected APM agent",
        "Deployed with copy/paste method",
        "Disable domain monitoring",
        "Disable browser agent"
      ],
      "title": "Disable browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "0109af1704295c643c93616540cf9667ec6438e9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/installation/disable-browser-monitoring/",
      "published_at": "2021-10-18T07:20:37Z",
      "updated_at": "2021-07-10T02:44:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using browser to monitor your application, you can manually disable monitoring for your app or for specific pages. Reasons for turning off browser monitoring on certain pages include: Some pages may not be relevant for monitoring. You want to monitor only specific pages. You want to remove the browser script for troubleshooting purposes. Disable monitoring of specific pages/URLs To disable browser on a specific page or URL, follow the procedures based on your deployment method: Deployed with selected APM agent If you used the APM agent to automatically insert your JavaScript snippet, you can disable injection for only those particular pages using the APM language agent's API or config file. For more information, see the instructions for your agent: Go (currently not applicable) Java .NET Node.js: This agent does not automatically insert JavaScript. To turn off monitoring on certain pages, simply remove the API calls from those pages. PHP Python Ruby Deployed with copy/paste method If you used the copy/paste deployment method and want to stop collecting data for a browser app, simply remove the browser monitoring JavaScript snippet from the pages you do not want to monitor. Disable domain monitoring To turn off monitoring for specific domains or sub-domains, update your browser domain conditions. Disable browser agent If you used the copy/paste deployment method and want to stop collecting data for a browser app, simply remove the browser JavaScript snippet from the pages you do not want to monitor. If you used the APM agent to install the browser agent, you can turn off some of the browser monitoring features individually, or you can disable browser entirely. Go to one.newrelic.com, click on Browser > (select a browser app) > Settings > Application settings. To disable only the Pro account level features, select Lite. To turn off browser monitoring completely, select Off. Select Save application settings. If applicable, restart your APM agent. When browser monitoring is off, the agent will not instrument pages with monitoring scripts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.76567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>browser</em> <em>monitoring</em>",
        "sections": "Disable <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "If you are using <em>browser</em> to <em>monitor</em> your application, you can manually disable <em>monitoring</em> for your app or for specific pages. Reasons for turning off <em>browser</em> <em>monitoring</em> on certain pages include: Some pages may not be relevant for <em>monitoring</em>. You want to <em>monitor</em> only specific pages. You want"
      },
      "id": "6043fd4164441f8728378f17"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.316444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ", follow the steps for troubleshooting <em>browser</em> <em>monitoring</em> <em>installation</em>. If you have a single-page style application and are expecting to see your route changes as views, consider using <em>browser</em> SPA <em>monitoring</em>, which provides an integrated view of initial page loads and route changes. If <em>browser</em> <em>monitoring</em>"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    }
  ],
  "/docs/browser/new-relic-browser/page-load-timing-resources/cached-pages": [
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-18T18:43:26Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.5566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "sections": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": " and firstContentfulPaint attributes already are available with <em>Browser</em>Interaction and <em>Page</em>View events. However, they are not always reliably captured before the window onload event fires. Using <em>PageViewTiming</em> gives you a way to capture these metrics even if they happen after the original <em>page</em> <em>load</em> <em>time</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.5579,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Page</em> <em>load</em> <em>timing</em> process",
        "sections": "<em>Page</em> <em>load</em> <em>time</em> charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "This document explains: How a web <em>page</em> loads How <em>browser</em> <em>monitoring</em> measures <em>page</em> <em>load</em> <em>timing</em>, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Browser</em> can also <em>monitor</em> asynchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Page</em> <em>load</em> process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    },
    {
      "sections": [
        "Navigation start time unknown",
        "Contents",
        "Network estimate",
        "Network estimate unavailable",
        "For more help"
      ],
      "title": "Navigation start time unknown",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "e0c839e445b4309c62704afd01702e6588232b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/navigation-start-time-unknown/",
      "published_at": "2021-10-18T18:43:25Z",
      "updated_at": "2021-07-10T02:45:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If a browser does not use the Navigation timing API for page load timing, the browser uses a cookie to determine the navigation start time. If a user navigates from a site without page load timing to a site with page load timing (for example, to the first page on your page load timing-enabled site), special considerations for navigation start time arise. Contents Network estimate The page load timing JavaScript utility file creates a cookie with the navigation start time when a user leaves a page (by hooking an event, beforeunload, or pagehide, depending on the browser). However, when navigating away from a site without page load timing enabled, the JavaScript code will not be present, and the cookie will not be created. Then, when the user hits the first page of a site, the navigation start time cannot be determined, because there is no cookie. In this case the browser agent has all the data (queue time, app time, DOM content and rendering time) except network time. Navigation start time is required to compute network time. Rather than toss the data, the page load timing feature estimates the network time based on recently accumulated averages for your application, regionally. This way the page load timing feature provides a more accurate throughput measurement, and the rest of the data is retained. This is especially important for sites with a high bounce rate (when users visit only one page). The more visitors you have from different regions, the more accurate the network estimate will be. Network estimate unavailable If a network estimate is not available for your application and for the region where the hit originated, the page load timing process reverts to a network estimate across all reporting apps for the region. Failing that, the data is tossed. Note: For browsers that have the Navigation Timing API, this is not an issue, as the navigation start time can be determined without using a cookie. For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Page load timing process (overview including time segments and colors, differences between app server requests and page load timing, outliers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.1532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Navigation start <em>time</em> unknown",
        "sections": "Navigation start <em>time</em> unknown",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "If a <em>browser</em> does not use the Navigation <em>timing</em> API for <em>page</em> <em>load</em> <em>timing</em>, the <em>browser</em> uses a cookie to determine the navigation start <em>time</em>. If a user navigates from a site without <em>page</em> <em>load</em> <em>timing</em> to a site with <em>page</em> <em>load</em> <em>timing</em> (for example, to the first <em>page</em> on your <em>page</em> <em>load</em> <em>timing</em>-enabled site"
      },
      "id": "6043ec3ae7b9d2b8d95799be"
    }
  ],
  "/docs/browser/new-relic-browser/page-load-timing-resources/instrumentation-browser-monitoring": [
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-18T18:43:26Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.55655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "sections": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": " and firstContentfulPaint attributes already are available with <em>Browser</em>Interaction and <em>Page</em>View events. However, they are not always reliably captured before the window onload event fires. Using <em>PageViewTiming</em> gives you a way to capture these metrics even if they happen after the original <em>page</em> <em>load</em> <em>time</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.55783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Page</em> <em>load</em> <em>timing</em> process",
        "sections": "<em>Page</em> <em>load</em> <em>time</em> charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "This document explains: How a web <em>page</em> loads How <em>browser</em> <em>monitoring</em> measures <em>page</em> <em>load</em> <em>timing</em>, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Browser</em> can also <em>monitor</em> asynchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Page</em> <em>load</em> process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    },
    {
      "sections": [
        "Navigation start time unknown",
        "Contents",
        "Network estimate",
        "Network estimate unavailable",
        "For more help"
      ],
      "title": "Navigation start time unknown",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "e0c839e445b4309c62704afd01702e6588232b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/navigation-start-time-unknown/",
      "published_at": "2021-10-18T18:43:25Z",
      "updated_at": "2021-07-10T02:45:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If a browser does not use the Navigation timing API for page load timing, the browser uses a cookie to determine the navigation start time. If a user navigates from a site without page load timing to a site with page load timing (for example, to the first page on your page load timing-enabled site), special considerations for navigation start time arise. Contents Network estimate The page load timing JavaScript utility file creates a cookie with the navigation start time when a user leaves a page (by hooking an event, beforeunload, or pagehide, depending on the browser). However, when navigating away from a site without page load timing enabled, the JavaScript code will not be present, and the cookie will not be created. Then, when the user hits the first page of a site, the navigation start time cannot be determined, because there is no cookie. In this case the browser agent has all the data (queue time, app time, DOM content and rendering time) except network time. Navigation start time is required to compute network time. Rather than toss the data, the page load timing feature estimates the network time based on recently accumulated averages for your application, regionally. This way the page load timing feature provides a more accurate throughput measurement, and the rest of the data is retained. This is especially important for sites with a high bounce rate (when users visit only one page). The more visitors you have from different regions, the more accurate the network estimate will be. Network estimate unavailable If a network estimate is not available for your application and for the region where the hit originated, the page load timing process reverts to a network estimate across all reporting apps for the region. Failing that, the data is tossed. Note: For browsers that have the Navigation Timing API, this is not an issue, as the navigation start time can be determined without using a cookie. For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Page load timing process (overview including time segments and colors, differences between app server requests and page load timing, outliers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.1532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Navigation start <em>time</em> unknown",
        "sections": "Navigation start <em>time</em> unknown",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "If a <em>browser</em> does not use the Navigation <em>timing</em> API for <em>page</em> <em>load</em> <em>timing</em>, the <em>browser</em> uses a cookie to determine the navigation start <em>time</em>. If a user navigates from a site without <em>page</em> <em>load</em> <em>timing</em> to a site with <em>page</em> <em>load</em> <em>timing</em> (for example, to the first <em>page</em> on your <em>page</em> <em>load</em> <em>timing</em>-enabled site"
      },
      "id": "6043ec3ae7b9d2b8d95799be"
    }
  ],
  "/docs/browser/new-relic-browser/page-load-timing-resources/navigation-start-time-unknown": [
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-18T18:43:26Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.55655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "sections": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": " and firstContentfulPaint attributes already are available with <em>Browser</em>Interaction and <em>Page</em>View events. However, they are not always reliably captured before the window onload event fires. Using <em>PageViewTiming</em> gives you a way to capture these metrics even if they happen after the original <em>page</em> <em>load</em> <em>time</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.55783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Page</em> <em>load</em> <em>timing</em> process",
        "sections": "<em>Page</em> <em>load</em> <em>time</em> charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "This document explains: How a web <em>page</em> loads How <em>browser</em> <em>monitoring</em> measures <em>page</em> <em>load</em> <em>timing</em>, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Browser</em> can also <em>monitor</em> asynchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Page</em> <em>load</em> process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    },
    {
      "sections": [
        "Instrumentation for browser monitoring",
        "Instrumentation to collect browser data",
        "JavaScript placement requirements",
        "Data transmission",
        "Important"
      ],
      "title": "Instrumentation for browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "a259fb8312470318f7907a17a9d228a3cf847a36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/instrumentation-browser-monitoring/",
      "published_at": "2021-10-18T07:20:59Z",
      "updated_at": "2021-07-10T02:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For standard page load timing, sometimes referred to as real user monitoring (RUM), we measure the overall time to load the entire webpage. Additional monitoring after page load provides details on in-page AJAX calls, JavaScript errors, and other events and interactions. Browser monitoring can leverage the New Relic agent to dynamically inject JavaScript into pages as they are built, in order to collect more detailed back-end timing information. Browser can also monitor apps with single-page application (SPA) architectures. Instrumentation to collect browser data To collect data, browser monitoring uses JavaScript elements pasted or injected into your webpages, typically as part of the HEAD of the page, containing configuration details and essential browser environment instrumentation. Once the page finishes loading, an additional script is downloaded from a CDN server. This additional script processes the collected data and reports it back to New Relic via bam.nr-data.net so that you can see the data in your New Relic account. The script elements can be injected automatically or via the agent API by an APM agent installed in the back-end application, or they can be inserted manually via copy/paste. Both API calls and the copy/paste method allow you to control when and where the script elements are inserted. We use these methods to collect the page load timing information: Method Collecting page load timing information Browsers with Navigation Timing Specification API For browsers that implement the Navigation Timing Specification API, page load timing information is read from the browser and reported to New Relic by the browser agent. The appropriate values simply are read from the webpage's performance timing object to capture the timing information. Navigation start: navigationStart First byte: responseStart DOM ready: DOMContentLoadedEventEnd Page ready: loadEventEnd Browsers without Navigation Timing Specification API For browsers that do not implement the Navigation Timing Specification API, we rely on the NREUM cookie and the browser agent to collect timing information. Additional instrumentation Browser also uses: Instrumentation of the XMLHttpRequest object to collect AJAX timing data. Instrumentation of JavaScript functions to collect uncaught JavaScript errors. Resource Timing API For browsers that implement the Resource Timing API, the browser agent reads and reports session trace details. Single page app (SPA) monitoring For SPA monitoring, we require the Navigation Timing Specification API and the addEventListener API. JavaScript placement requirements Injecting the JavaScript inline in the HEAD is an unusual requirement for a JavaScript library, and different from how third-party scripts are typically included. We require this so that browser provides accurate information without impacting page load performance. The injected browser JavaScript elements wrap many of the browser's built in APIs to record information about JavaScript errors or callback timings. The unusual placement of the code element is necessary for the following reasons: The inline HEAD placement ensures the instrumentation code is loaded before all other scripts so that wrapping will occur when other libraries are registered. Inline code placement also eliminates the network round trips caused by externally referenced scripts. Data transmission For both https and http webpages, we transmit data via https. This summarizes when the data is transmitted to and from the webpage. Important New Relic requires support of the SHA256 hash function, which some older operating systems do not support. If an end user lacks SHA256, the browser agent will not connect to New Relic and data will not be sent. Data transmission Frequency Fetch the agent script Once following page load via https Send page load timing data Once following page load via https Send AJAX and JavaScript error data Once per minute when there is activity via https Send session trace data Every ten seconds when there is activity and a session trace is occurring via https Send SPA data At the end of an interaction via https",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.15308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "sections": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "For standard <em>page</em> <em>load</em> <em>timing</em>, sometimes referred to as real user <em>monitoring</em> (RUM), we measure the overall <em>time</em> to <em>load</em> the entire webpage. Additional <em>monitoring</em> after <em>page</em> <em>load</em> provides details on in-<em>page</em> AJAX calls, JavaScript errors, and other events and interactions. <em>Browser</em> <em>monitoring</em> can"
      },
      "id": "6043ef69e7b9d2d7055799f9"
    }
  ],
  "/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process": [
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-18T18:43:26Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.5565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "sections": "<em>PageViewTiming</em>: Async or dynamic <em>page</em> details",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": " and firstContentfulPaint attributes already are available with <em>Browser</em>Interaction and <em>Page</em>View events. However, they are not always reliably captured before the window onload event fires. Using <em>PageViewTiming</em> gives you a way to capture these metrics even if they happen after the original <em>page</em> <em>load</em> <em>time</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Navigation start time unknown",
        "Contents",
        "Network estimate",
        "Network estimate unavailable",
        "For more help"
      ],
      "title": "Navigation start time unknown",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "e0c839e445b4309c62704afd01702e6588232b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/navigation-start-time-unknown/",
      "published_at": "2021-10-18T18:43:25Z",
      "updated_at": "2021-07-10T02:45:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If a browser does not use the Navigation timing API for page load timing, the browser uses a cookie to determine the navigation start time. If a user navigates from a site without page load timing to a site with page load timing (for example, to the first page on your page load timing-enabled site), special considerations for navigation start time arise. Contents Network estimate The page load timing JavaScript utility file creates a cookie with the navigation start time when a user leaves a page (by hooking an event, beforeunload, or pagehide, depending on the browser). However, when navigating away from a site without page load timing enabled, the JavaScript code will not be present, and the cookie will not be created. Then, when the user hits the first page of a site, the navigation start time cannot be determined, because there is no cookie. In this case the browser agent has all the data (queue time, app time, DOM content and rendering time) except network time. Navigation start time is required to compute network time. Rather than toss the data, the page load timing feature estimates the network time based on recently accumulated averages for your application, regionally. This way the page load timing feature provides a more accurate throughput measurement, and the rest of the data is retained. This is especially important for sites with a high bounce rate (when users visit only one page). The more visitors you have from different regions, the more accurate the network estimate will be. Network estimate unavailable If a network estimate is not available for your application and for the region where the hit originated, the page load timing process reverts to a network estimate across all reporting apps for the region. Failing that, the data is tossed. Note: For browsers that have the Navigation Timing API, this is not an issue, as the navigation start time can be determined without using a cookie. For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Page load timing process (overview including time segments and colors, differences between app server requests and page load timing, outliers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.1532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Navigation start <em>time</em> unknown",
        "sections": "Navigation start <em>time</em> unknown",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "If a <em>browser</em> does not use the Navigation <em>timing</em> API for <em>page</em> <em>load</em> <em>timing</em>, the <em>browser</em> uses a cookie to determine the navigation start <em>time</em>. If a user navigates from a site without <em>page</em> <em>load</em> <em>timing</em> to a site with <em>page</em> <em>load</em> <em>timing</em> (for example, to the first <em>page</em> on your <em>page</em> <em>load</em> <em>timing</em>-enabled site"
      },
      "id": "6043ec3ae7b9d2b8d95799be"
    },
    {
      "sections": [
        "Instrumentation for browser monitoring",
        "Instrumentation to collect browser data",
        "JavaScript placement requirements",
        "Data transmission",
        "Important"
      ],
      "title": "Instrumentation for browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "a259fb8312470318f7907a17a9d228a3cf847a36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/instrumentation-browser-monitoring/",
      "published_at": "2021-10-18T07:20:59Z",
      "updated_at": "2021-07-10T02:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For standard page load timing, sometimes referred to as real user monitoring (RUM), we measure the overall time to load the entire webpage. Additional monitoring after page load provides details on in-page AJAX calls, JavaScript errors, and other events and interactions. Browser monitoring can leverage the New Relic agent to dynamically inject JavaScript into pages as they are built, in order to collect more detailed back-end timing information. Browser can also monitor apps with single-page application (SPA) architectures. Instrumentation to collect browser data To collect data, browser monitoring uses JavaScript elements pasted or injected into your webpages, typically as part of the HEAD of the page, containing configuration details and essential browser environment instrumentation. Once the page finishes loading, an additional script is downloaded from a CDN server. This additional script processes the collected data and reports it back to New Relic via bam.nr-data.net so that you can see the data in your New Relic account. The script elements can be injected automatically or via the agent API by an APM agent installed in the back-end application, or they can be inserted manually via copy/paste. Both API calls and the copy/paste method allow you to control when and where the script elements are inserted. We use these methods to collect the page load timing information: Method Collecting page load timing information Browsers with Navigation Timing Specification API For browsers that implement the Navigation Timing Specification API, page load timing information is read from the browser and reported to New Relic by the browser agent. The appropriate values simply are read from the webpage's performance timing object to capture the timing information. Navigation start: navigationStart First byte: responseStart DOM ready: DOMContentLoadedEventEnd Page ready: loadEventEnd Browsers without Navigation Timing Specification API For browsers that do not implement the Navigation Timing Specification API, we rely on the NREUM cookie and the browser agent to collect timing information. Additional instrumentation Browser also uses: Instrumentation of the XMLHttpRequest object to collect AJAX timing data. Instrumentation of JavaScript functions to collect uncaught JavaScript errors. Resource Timing API For browsers that implement the Resource Timing API, the browser agent reads and reports session trace details. Single page app (SPA) monitoring For SPA monitoring, we require the Navigation Timing Specification API and the addEventListener API. JavaScript placement requirements Injecting the JavaScript inline in the HEAD is an unusual requirement for a JavaScript library, and different from how third-party scripts are typically included. We require this so that browser provides accurate information without impacting page load performance. The injected browser JavaScript elements wrap many of the browser's built in APIs to record information about JavaScript errors or callback timings. The unusual placement of the code element is necessary for the following reasons: The inline HEAD placement ensures the instrumentation code is loaded before all other scripts so that wrapping will occur when other libraries are registered. Inline code placement also eliminates the network round trips caused by externally referenced scripts. Data transmission For both https and http webpages, we transmit data via https. This summarizes when the data is transmitted to and from the webpage. Important New Relic requires support of the SHA256 hash function, which some older operating systems do not support. If an end user lacks SHA256, the browser agent will not connect to New Relic and data will not be sent. Data transmission Frequency Fetch the agent script Once following page load via https Send page load timing data Once following page load via https Send AJAX and JavaScript error data Once per minute when there is activity via https Send session trace data Every ten seconds when there is activity and a session trace is occurring via https Send SPA data At the end of an interaction via https",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.15308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "sections": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "For standard <em>page</em> <em>load</em> <em>timing</em>, sometimes referred to as real user <em>monitoring</em> (RUM), we measure the overall <em>time</em> to <em>load</em> the entire webpage. Additional <em>monitoring</em> after <em>page</em> <em>load</em> provides details on in-<em>page</em> AJAX calls, JavaScript errors, and other events and interactions. <em>Browser</em> <em>monitoring</em> can"
      },
      "id": "6043ef69e7b9d2d7055799f9"
    }
  ],
  "/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details": [
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.55777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Page</em> <em>load</em> <em>timing</em> process",
        "sections": "<em>Page</em> <em>load</em> <em>time</em> charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "This document explains: How a web <em>page</em> loads How <em>browser</em> <em>monitoring</em> measures <em>page</em> <em>load</em> <em>timing</em>, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Browser</em> can also <em>monitor</em> asynchronous <em>page</em> <em>load</em> <em>timing</em>. <em>Page</em> <em>load</em> process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    },
    {
      "sections": [
        "Navigation start time unknown",
        "Contents",
        "Network estimate",
        "Network estimate unavailable",
        "For more help"
      ],
      "title": "Navigation start time unknown",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "e0c839e445b4309c62704afd01702e6588232b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/navigation-start-time-unknown/",
      "published_at": "2021-10-18T18:43:25Z",
      "updated_at": "2021-07-10T02:45:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If a browser does not use the Navigation timing API for page load timing, the browser uses a cookie to determine the navigation start time. If a user navigates from a site without page load timing to a site with page load timing (for example, to the first page on your page load timing-enabled site), special considerations for navigation start time arise. Contents Network estimate The page load timing JavaScript utility file creates a cookie with the navigation start time when a user leaves a page (by hooking an event, beforeunload, or pagehide, depending on the browser). However, when navigating away from a site without page load timing enabled, the JavaScript code will not be present, and the cookie will not be created. Then, when the user hits the first page of a site, the navigation start time cannot be determined, because there is no cookie. In this case the browser agent has all the data (queue time, app time, DOM content and rendering time) except network time. Navigation start time is required to compute network time. Rather than toss the data, the page load timing feature estimates the network time based on recently accumulated averages for your application, regionally. This way the page load timing feature provides a more accurate throughput measurement, and the rest of the data is retained. This is especially important for sites with a high bounce rate (when users visit only one page). The more visitors you have from different regions, the more accurate the network estimate will be. Network estimate unavailable If a network estimate is not available for your application and for the region where the hit originated, the page load timing process reverts to a network estimate across all reporting apps for the region. Failing that, the data is tossed. Note: For browsers that have the Navigation Timing API, this is not an issue, as the navigation start time can be determined without using a cookie. For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Page load timing process (overview including time segments and colors, differences between app server requests and page load timing, outliers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.1532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Navigation start <em>time</em> unknown",
        "sections": "Navigation start <em>time</em> unknown",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "If a <em>browser</em> does not use the Navigation <em>timing</em> API for <em>page</em> <em>load</em> <em>timing</em>, the <em>browser</em> uses a cookie to determine the navigation start <em>time</em>. If a user navigates from a site without <em>page</em> <em>load</em> <em>timing</em> to a site with <em>page</em> <em>load</em> <em>timing</em> (for example, to the first <em>page</em> on your <em>page</em> <em>load</em> <em>timing</em>-enabled site"
      },
      "id": "6043ec3ae7b9d2b8d95799be"
    },
    {
      "sections": [
        "Instrumentation for browser monitoring",
        "Instrumentation to collect browser data",
        "JavaScript placement requirements",
        "Data transmission",
        "Important"
      ],
      "title": "Instrumentation for browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "a259fb8312470318f7907a17a9d228a3cf847a36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/instrumentation-browser-monitoring/",
      "published_at": "2021-10-18T07:20:59Z",
      "updated_at": "2021-07-10T02:44:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For standard page load timing, sometimes referred to as real user monitoring (RUM), we measure the overall time to load the entire webpage. Additional monitoring after page load provides details on in-page AJAX calls, JavaScript errors, and other events and interactions. Browser monitoring can leverage the New Relic agent to dynamically inject JavaScript into pages as they are built, in order to collect more detailed back-end timing information. Browser can also monitor apps with single-page application (SPA) architectures. Instrumentation to collect browser data To collect data, browser monitoring uses JavaScript elements pasted or injected into your webpages, typically as part of the HEAD of the page, containing configuration details and essential browser environment instrumentation. Once the page finishes loading, an additional script is downloaded from a CDN server. This additional script processes the collected data and reports it back to New Relic via bam.nr-data.net so that you can see the data in your New Relic account. The script elements can be injected automatically or via the agent API by an APM agent installed in the back-end application, or they can be inserted manually via copy/paste. Both API calls and the copy/paste method allow you to control when and where the script elements are inserted. We use these methods to collect the page load timing information: Method Collecting page load timing information Browsers with Navigation Timing Specification API For browsers that implement the Navigation Timing Specification API, page load timing information is read from the browser and reported to New Relic by the browser agent. The appropriate values simply are read from the webpage's performance timing object to capture the timing information. Navigation start: navigationStart First byte: responseStart DOM ready: DOMContentLoadedEventEnd Page ready: loadEventEnd Browsers without Navigation Timing Specification API For browsers that do not implement the Navigation Timing Specification API, we rely on the NREUM cookie and the browser agent to collect timing information. Additional instrumentation Browser also uses: Instrumentation of the XMLHttpRequest object to collect AJAX timing data. Instrumentation of JavaScript functions to collect uncaught JavaScript errors. Resource Timing API For browsers that implement the Resource Timing API, the browser agent reads and reports session trace details. Single page app (SPA) monitoring For SPA monitoring, we require the Navigation Timing Specification API and the addEventListener API. JavaScript placement requirements Injecting the JavaScript inline in the HEAD is an unusual requirement for a JavaScript library, and different from how third-party scripts are typically included. We require this so that browser provides accurate information without impacting page load performance. The injected browser JavaScript elements wrap many of the browser's built in APIs to record information about JavaScript errors or callback timings. The unusual placement of the code element is necessary for the following reasons: The inline HEAD placement ensures the instrumentation code is loaded before all other scripts so that wrapping will occur when other libraries are registered. Inline code placement also eliminates the network round trips caused by externally referenced scripts. Data transmission For both https and http webpages, we transmit data via https. This summarizes when the data is transmitted to and from the webpage. Important New Relic requires support of the SHA256 hash function, which some older operating systems do not support. If an end user lacks SHA256, the browser agent will not connect to New Relic and data will not be sent. Data transmission Frequency Fetch the agent script Once following page load via https Send page load timing data Once following page load via https Send AJAX and JavaScript error data Once per minute when there is activity via https Send session trace data Every ten seconds when there is activity and a session trace is occurring via https Send SPA data At the end of an interaction via https",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.15308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "sections": "Instrumentation for <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Page</em> <em>load</em> <em>timing</em> <em>resources</em>",
        "body": "For standard <em>page</em> <em>load</em> <em>timing</em>, sometimes referred to as real user <em>monitoring</em> (RUM), we measure the overall <em>time</em> to <em>load</em> the entire webpage. Additional <em>monitoring</em> after <em>page</em> <em>load</em> provides details on in-<em>page</em> AJAX calls, JavaScript errors, and other events and interactions. <em>Browser</em> <em>monitoring</em> can"
      },
      "id": "6043ef69e7b9d2d7055799f9"
    }
  ],
  "/docs/browser/new-relic-browser/performance-quality/browser-monitoring-performance-impact": [
    {
      "sections": [
        "Browser monitoring and search engine optimization",
        "Contents",
        "Efficiency of inline JavaScript",
        "Impact on SEO"
      ],
      "title": "Browser monitoring and search engine optimization",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "1f3f91b4e13af6b49f484d7ba08f338e7f4344f0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/browser-monitoring-search-engine-optimization/",
      "published_at": "2021-10-18T18:45:17Z",
      "updated_at": "2021-07-09T23:05:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring places a small \"loader\" script into the head section of each page on a monitored site. This JavaScript instrumentation has been designed to: Provide maximum visibility into front-end performance, accurately time how long it takes for pages to load in all browsers, and to report details for JavaScript errors and AJAX calls. Have minimal impact on overall page load time and search engine optimization (SEO), including search engine ranking, indexing, crawl efficiency, or other SEO-related concerns. Contents Efficiency of inline JavaScript The most effective method for browser monitoring is to include a minimal amount of JavaScript instrumentation code inline in the head of the monitored page. This code then retrieves the remainder of the necessary code after the page finishes loading. Other browser monitoring methods include JavaScript code at the end of the page body or exclusively using an external script. However, these methods can limit visibility into the end users' experience. Impact on SEO Performance testing results indicate that using browser monitoring's JavaScript has a negligible effect on page load time. In addition, it has no negative impact on how users or search engines interact with your site. Google's consistent recommendation to website owners is to build a site that is valuable to users and accessible to search engine crawlers. Google rankings favor sites that provide the most relevant information and the best user experience. Browser monitoring can help you improve user experience by identifying performance bottlenecks, including: Slow page loads Problematic JavaScript errors Long AJAX calls Identifying Javascript errors is especially helpful because Google's bots are increasingly running the JavaScript code on websites they crawl in order to access content provided by AJAX-heavy web applications. A JavaScript error that previously was only visible to human users (for example, a broken button) could affect whether the Google bots can successfully interact with your site. We understand that SEO and traffic referred by search engines are critically important to many businesses. When used effectively, browser monitoring can even increase a site's ranking in Google and other search engines by improving performance and user experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> <em>monitoring</em> and search engine optimization",
        "sections": "<em>Browser</em> <em>monitoring</em> and search engine optimization",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em> places a small &quot;loader&quot; script into the head section of each page on a monitored site. This JavaScript instrumentation has been designed to: Provide maximum visibility into front-end <em>performance</em>, accurately time how long it takes for pages to load in all browsers, and to report"
      },
      "id": "6043fa33196a675d7b960f85"
    },
    {
      "sections": [
        "Security for browser monitoring",
        "Reported data",
        "Page view data",
        "AJAX timing data",
        "JavaScript error data",
        "Session trace data",
        "SPA data",
        "URL query strings",
        "Visitor's IP address",
        "Browser types",
        "CDN access",
        "Important",
        "Cookies",
        "JSONP requests"
      ],
      "title": "Security for browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "99cd4023fc519082ebe94082e3a6affd1cc2344f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/security-browser-monitoring/",
      "published_at": "2021-10-18T18:45:18Z",
      "updated_at": "2021-07-09T23:05:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring provides insights into how your application or site behaves when it is loaded in a web browser. Browser only records performance data, as explained in this document. It does not record any data used or stored by the monitored application unless you explicitly configure it to do so. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Reported data Browser reports many different types of data to help you analyze your website's performance. It only reports page view data, unless you have subscribed to Pro features. You can also enable functionality for AJAX requests, JavaScript errors, and session traces. For most data types, browser transmits the data securely using HTTPS encryption. The browser agent transmits data to New Relic's collectors by using either of the domains bam.nr-data.net or bam-cell.nr-data.net. Here is a summary of the types of data reported by browser monitoring. Page view data This data is reported once per page view and consists of: Page load timing data Name of the server-side app controller that served the page, if available (obfuscated in the page and during transmission) Additional custom parameters set by the server-side app controller, if available (obfuscated in the page and during transmission) Additional custom parameters set by the browser agent API, if set prior to page load This information appears on the Page views page. For data security reasons, browser does not record or collect URL query strings. Server-side data can only be collected when the host is also instrumented by New Relic and the browser monitoring instrumentation is injected by the agent. For more information about how we collect and present this data, see Instrumentation for page load timing. AJAX timing data When enabled, browser periodically reports AJAX timing data until the user navigates away from or closes the page. (New Relic automatically filters out all AJAX requests that take longer than two minutes.) Data includes: Hostnames, ports, and paths (but not search/query parameters) of AJAX request URLs HTTP status code of responses Byte size of request message bodies Name of the server-side app controller servicing the AJAX request and server-side timing data (obfuscated in the page and during transmission), when the browser instrumentation is injected by the New Relic agent Timing data for the AJAX transaction Timing data for the AJAX callbacks This information appears on the AJAX page. JavaScript error data When enabled, browser periodically reports data about every error that occurs on the page until the user navigates away from or closes the page. This information appears on the JavaScript errors page. For each error, the data includes: Exception class of the error Error message containing arbitrary text Stack trace of the error, which may contain function names and URLs of scripts causing the error Error messages typically do not contain any confidential or sensitive information. However, it is possible for messages to be purposefully constructed with sensitive information. Before enabling JavaScript error reporting, ensure that your website does not expose any sensitive information in error messages. Session trace data When enabled, browser periodically reports data on the details of the a single page's life cycle, including user interactions, AJAX loads, and JavaScript errors, until the user navigates away from or closes the page. New Relic automatically stops recording further data after ten minutes. Data includes: Asset load timing details User interactions such as scrolling, mousing, and clicking JavaScript error timing and other JavaScript error information Triggered Javascript events Session traces are captured randomly at a fixed rate from among the monitored page views. Session trace information appears on the Session traces page. SPA data If you use browser's single-page app (SPA) monitoring, New Relic reports the following data once per page load or route change. Browser data for page views, AJAX timing, JavaScript errors, and session traces Hash fragments associated with SPA route changes Additional custom parameters added from the SPA API When SPA monitoring has been enabled, this information appears on the Page views page. Server-side data can only be collected when the host is also instrumented by New Relic, and the browser monitoring instrumentation is injected by the agent. For more information about how we collect and present this data, see Instrumentation for page load timing. URL query strings The browser agent uses the HTTP referer attribute to track page URLs. URLs can sometimes contain potentially sensitive user-entered query data (for example, a user's name). For data security reasons, browser does not record or collect URL query strings. Visitor's IP address Browser uses the visitor's IP address to enrich data for additional visitor segmentation. Details such as the ASN and geoID are mapped to browser data from the IP address. For data security reasons, browser does not retain the visitor's IP address for reporting. The IP address is obtained in the HTTP header from the request to the New Relic collector. New Relic does not retain the visitor's IP address after the attributes have been mapped. The IP address value is overwritten within 24 hours of data being collected. Browser types Browser determines the browser type from the User-Agent header and the geographical location based on the browser's IP address. New Relic does not retain the IP address, only the country and region associated with the performance data. This information appears on the selected app's Geography page. Also, details about specific browser types appear on the selected app's Browsers page. CDN access Page load timing requires access to the content delivery network (CDN), where New Relic's utility JavaScript file (nr.js) is hosted. The domain name for the file (js-agent.newrelic.com) remains static, but the number in the path (version) may change periodically. A script tag is injected by the New Relic agent (or pasted into the webpage for standalone apps) that references the JavaScript on the CDN, which is then loaded by the browser. The loaded JavaScript collects and reports the metrics dynamically to either of the domains bam.nr-data.net or bam-cell.nr-data.net. Important If your end users are behind a firewall or proxy and do not have access to the CDN or to New Relic's networks (including bam.nr-data.net and bam-cell.nr-data.net), browser monitoring will not work. Cookies Browser monitoring creates cookies in the end user's browser. If the user has cookies disabled, page load timing (sometimes referred to as real user monitoring or RUM) will not be able to track sessions properly. Also, if the user has an older browser that does not support the Navigation Timing Specification API, page load timing will not be able to track response times as accurately. New Relic's cookies generated by browser agents older than version 995 may not contain the secure attribute. This is because page load timing data transmission in versions before version 995 use HTTP when the page is HTTP, but use HTTPS when the page is HTTPS. All browser agent versions above version 995 will always use the secure flag for cookies and transmit over HTTPS. JavaScript and AJAX data may contain more sensitive information, so they are always transmitted over HTTPS. Transmission of these cookies using HTTP or access to them from JavaScript is not a significant security risk, because the cookies are not used to make security decisions or allow access to an account. They are used only to collect performance data, with any identifiable data obfuscated. For customers subject to special guidelines for cookie collection, such as those under the EU GDPR/PECR ICO Guidelines, we now provide the option to disable cookie collection for your application. Please see our browser agent v1169 release notes for more information. Important If your site uses P3P, it must be configured to allow these cookies. JSONP requests Page load timing metrics are reported to New Relic using a Script GET, also known as a JSONP request. The Script GET returns a value that is subsequently stored in a cookie and used to trigger trace capturing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>browser</em> <em>monitoring</em>",
        "sections": "Security for <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em> provides insights into how your application or site behaves when it is loaded in a web <em>browser</em>. <em>Browser</em> only records <em>performance</em> data, as explained in this document. It does not record any data used or stored by the monitored application unless you explicitly configure it to do"
      },
      "id": "6043efdf64441f772e378f12"
    },
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-18T07:16:54Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.211716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    }
  ],
  "/docs/browser/new-relic-browser/performance-quality/browser-monitoring-search-engine-optimization": [
    {
      "sections": [
        "Browser monitoring and performance impact",
        "Contents",
        "Overall impact",
        "Network impact",
        "For more help"
      ],
      "title": "Browser monitoring and performance impact",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "5504ef3846f4bcdae0ff4f58e8c745079d9a5cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/browser-monitoring-performance-impact/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-07-09T23:38:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's JavaScript snippet introduces a nearly invisible impact on website performance and user perception of the time it takes a page to load. The JavaScript is included in a packet of webpage data that is sent anyway. In addition, it immediately begins monitoring for errors and events as the rest of the webpage executes. The negligible amount of overhead required to load the JavaScript results in a significant return of actionable data. Contents Overall impact The JavaScript's overhead takes into consideration both the impact on the user and the impact on your systems' performance: User perception: Typically users cannot detect performance degradations on a website of less than 200ms. Browser's JavaScript adds less than 15ms in aggregated time per page load. This is split up over time, so at no point would a user be able to perceive any performance impact due to the JavaScript. Webserver and systems: Browser app monitoring occurs on the user's browser, not on the server. Processing time does not have an impact on your CPU consumption. In addition, we take additional steps to minimize any potential impact on the apps and webpages being monitored. For example, the \"loader\" script is loaded synchronously in the <HEAD> in order to ensure monitoring is enabled for the entire life cycle of the page. This script is included inline, which eliminates the need for another roundtrip network request to a content delivery network (CDN). The \"loader\" comes with the initial page load. Later in the life cycle of the page, New Relic loads an additional monitoring script asynchronously. This script should not have any perceivable effect to the user and is included in the overall overhead of less than 15ms per page. Network impact Browser monitoring also minimizes network traffic for the end user by aggregating data locally (in the client) and sending it back to New Relic on load, at periodic intervals, on unload, or when data has been collected. (During the browser session's idle periods, transmissions may not be required.) For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Browser monitoring and search engine optimization (how browser ensures that the JavaScript has a negligible impact on SEO)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> <em>monitoring</em> and <em>performance</em> impact",
        "sections": "<em>Browser</em> <em>monitoring</em> and <em>performance</em> impact",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s JavaScript snippet introduces a nearly invisible impact on website <em>performance</em> and user perception of the time it takes a page to load. The JavaScript is included in a packet of webpage data that is sent anyway. In addition, it immediately begins <em>monitoring</em> for errors"
      },
      "id": "603ec318196a67a757a83dd1"
    },
    {
      "sections": [
        "Security for browser monitoring",
        "Reported data",
        "Page view data",
        "AJAX timing data",
        "JavaScript error data",
        "Session trace data",
        "SPA data",
        "URL query strings",
        "Visitor's IP address",
        "Browser types",
        "CDN access",
        "Important",
        "Cookies",
        "JSONP requests"
      ],
      "title": "Security for browser monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "99cd4023fc519082ebe94082e3a6affd1cc2344f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/security-browser-monitoring/",
      "published_at": "2021-10-18T18:45:18Z",
      "updated_at": "2021-07-09T23:05:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring provides insights into how your application or site behaves when it is loaded in a web browser. Browser only records performance data, as explained in this document. It does not record any data used or stored by the monitored application unless you explicitly configure it to do so. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Reported data Browser reports many different types of data to help you analyze your website's performance. It only reports page view data, unless you have subscribed to Pro features. You can also enable functionality for AJAX requests, JavaScript errors, and session traces. For most data types, browser transmits the data securely using HTTPS encryption. The browser agent transmits data to New Relic's collectors by using either of the domains bam.nr-data.net or bam-cell.nr-data.net. Here is a summary of the types of data reported by browser monitoring. Page view data This data is reported once per page view and consists of: Page load timing data Name of the server-side app controller that served the page, if available (obfuscated in the page and during transmission) Additional custom parameters set by the server-side app controller, if available (obfuscated in the page and during transmission) Additional custom parameters set by the browser agent API, if set prior to page load This information appears on the Page views page. For data security reasons, browser does not record or collect URL query strings. Server-side data can only be collected when the host is also instrumented by New Relic and the browser monitoring instrumentation is injected by the agent. For more information about how we collect and present this data, see Instrumentation for page load timing. AJAX timing data When enabled, browser periodically reports AJAX timing data until the user navigates away from or closes the page. (New Relic automatically filters out all AJAX requests that take longer than two minutes.) Data includes: Hostnames, ports, and paths (but not search/query parameters) of AJAX request URLs HTTP status code of responses Byte size of request message bodies Name of the server-side app controller servicing the AJAX request and server-side timing data (obfuscated in the page and during transmission), when the browser instrumentation is injected by the New Relic agent Timing data for the AJAX transaction Timing data for the AJAX callbacks This information appears on the AJAX page. JavaScript error data When enabled, browser periodically reports data about every error that occurs on the page until the user navigates away from or closes the page. This information appears on the JavaScript errors page. For each error, the data includes: Exception class of the error Error message containing arbitrary text Stack trace of the error, which may contain function names and URLs of scripts causing the error Error messages typically do not contain any confidential or sensitive information. However, it is possible for messages to be purposefully constructed with sensitive information. Before enabling JavaScript error reporting, ensure that your website does not expose any sensitive information in error messages. Session trace data When enabled, browser periodically reports data on the details of the a single page's life cycle, including user interactions, AJAX loads, and JavaScript errors, until the user navigates away from or closes the page. New Relic automatically stops recording further data after ten minutes. Data includes: Asset load timing details User interactions such as scrolling, mousing, and clicking JavaScript error timing and other JavaScript error information Triggered Javascript events Session traces are captured randomly at a fixed rate from among the monitored page views. Session trace information appears on the Session traces page. SPA data If you use browser's single-page app (SPA) monitoring, New Relic reports the following data once per page load or route change. Browser data for page views, AJAX timing, JavaScript errors, and session traces Hash fragments associated with SPA route changes Additional custom parameters added from the SPA API When SPA monitoring has been enabled, this information appears on the Page views page. Server-side data can only be collected when the host is also instrumented by New Relic, and the browser monitoring instrumentation is injected by the agent. For more information about how we collect and present this data, see Instrumentation for page load timing. URL query strings The browser agent uses the HTTP referer attribute to track page URLs. URLs can sometimes contain potentially sensitive user-entered query data (for example, a user's name). For data security reasons, browser does not record or collect URL query strings. Visitor's IP address Browser uses the visitor's IP address to enrich data for additional visitor segmentation. Details such as the ASN and geoID are mapped to browser data from the IP address. For data security reasons, browser does not retain the visitor's IP address for reporting. The IP address is obtained in the HTTP header from the request to the New Relic collector. New Relic does not retain the visitor's IP address after the attributes have been mapped. The IP address value is overwritten within 24 hours of data being collected. Browser types Browser determines the browser type from the User-Agent header and the geographical location based on the browser's IP address. New Relic does not retain the IP address, only the country and region associated with the performance data. This information appears on the selected app's Geography page. Also, details about specific browser types appear on the selected app's Browsers page. CDN access Page load timing requires access to the content delivery network (CDN), where New Relic's utility JavaScript file (nr.js) is hosted. The domain name for the file (js-agent.newrelic.com) remains static, but the number in the path (version) may change periodically. A script tag is injected by the New Relic agent (or pasted into the webpage for standalone apps) that references the JavaScript on the CDN, which is then loaded by the browser. The loaded JavaScript collects and reports the metrics dynamically to either of the domains bam.nr-data.net or bam-cell.nr-data.net. Important If your end users are behind a firewall or proxy and do not have access to the CDN or to New Relic's networks (including bam.nr-data.net and bam-cell.nr-data.net), browser monitoring will not work. Cookies Browser monitoring creates cookies in the end user's browser. If the user has cookies disabled, page load timing (sometimes referred to as real user monitoring or RUM) will not be able to track sessions properly. Also, if the user has an older browser that does not support the Navigation Timing Specification API, page load timing will not be able to track response times as accurately. New Relic's cookies generated by browser agents older than version 995 may not contain the secure attribute. This is because page load timing data transmission in versions before version 995 use HTTP when the page is HTTP, but use HTTPS when the page is HTTPS. All browser agent versions above version 995 will always use the secure flag for cookies and transmit over HTTPS. JavaScript and AJAX data may contain more sensitive information, so they are always transmitted over HTTPS. Transmission of these cookies using HTTP or access to them from JavaScript is not a significant security risk, because the cookies are not used to make security decisions or allow access to an account. They are used only to collect performance data, with any identifiable data obfuscated. For customers subject to special guidelines for cookie collection, such as those under the EU GDPR/PECR ICO Guidelines, we now provide the option to disable cookie collection for your application. Please see our browser agent v1169 release notes for more information. Important If your site uses P3P, it must be configured to allow these cookies. JSONP requests Page load timing metrics are reported to New Relic using a Script GET, also known as a JSONP request. The Script GET returns a value that is subsequently stored in a cookie and used to trigger trace capturing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>browser</em> <em>monitoring</em>",
        "sections": "Security for <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em> provides insights into how your application or site behaves when it is loaded in a web <em>browser</em>. <em>Browser</em> only records <em>performance</em> data, as explained in this document. It does not record any data used or stored by the monitored application unless you explicitly configure it to do"
      },
      "id": "6043efdf64441f772e378f12"
    },
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-18T07:16:54Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.211716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    }
  ],
  "/docs/browser/new-relic-browser/performance-quality/security-browser-monitoring": [
    {
      "sections": [
        "Browser monitoring and performance impact",
        "Contents",
        "Overall impact",
        "Network impact",
        "For more help"
      ],
      "title": "Browser monitoring and performance impact",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "5504ef3846f4bcdae0ff4f58e8c745079d9a5cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/browser-monitoring-performance-impact/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-07-09T23:38:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's JavaScript snippet introduces a nearly invisible impact on website performance and user perception of the time it takes a page to load. The JavaScript is included in a packet of webpage data that is sent anyway. In addition, it immediately begins monitoring for errors and events as the rest of the webpage executes. The negligible amount of overhead required to load the JavaScript results in a significant return of actionable data. Contents Overall impact The JavaScript's overhead takes into consideration both the impact on the user and the impact on your systems' performance: User perception: Typically users cannot detect performance degradations on a website of less than 200ms. Browser's JavaScript adds less than 15ms in aggregated time per page load. This is split up over time, so at no point would a user be able to perceive any performance impact due to the JavaScript. Webserver and systems: Browser app monitoring occurs on the user's browser, not on the server. Processing time does not have an impact on your CPU consumption. In addition, we take additional steps to minimize any potential impact on the apps and webpages being monitored. For example, the \"loader\" script is loaded synchronously in the <HEAD> in order to ensure monitoring is enabled for the entire life cycle of the page. This script is included inline, which eliminates the need for another roundtrip network request to a content delivery network (CDN). The \"loader\" comes with the initial page load. Later in the life cycle of the page, New Relic loads an additional monitoring script asynchronously. This script should not have any perceivable effect to the user and is included in the overall overhead of less than 15ms per page. Network impact Browser monitoring also minimizes network traffic for the end user by aggregating data locally (in the client) and sending it back to New Relic on load, at periodic intervals, on unload, or when data has been collected. (During the browser session's idle periods, transmissions may not be required.) For more help Additional documentation resources include: Instrumentation for page load timing (JavaScript elements, data transmission) Browser monitoring and search engine optimization (how browser ensures that the JavaScript has a negligible impact on SEO)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> <em>monitoring</em> and <em>performance</em> impact",
        "sections": "<em>Browser</em> <em>monitoring</em> and <em>performance</em> impact",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em>&#x27;s JavaScript snippet introduces a nearly invisible impact on website <em>performance</em> and user perception of the time it takes a page to load. The JavaScript is included in a packet of webpage data that is sent anyway. In addition, it immediately begins <em>monitoring</em> for errors"
      },
      "id": "603ec318196a67a757a83dd1"
    },
    {
      "sections": [
        "Browser monitoring and search engine optimization",
        "Contents",
        "Efficiency of inline JavaScript",
        "Impact on SEO"
      ],
      "title": "Browser monitoring and search engine optimization",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Performance quality"
      ],
      "external_id": "1f3f91b4e13af6b49f484d7ba08f338e7f4344f0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/performance-quality/browser-monitoring-search-engine-optimization/",
      "published_at": "2021-10-18T18:45:17Z",
      "updated_at": "2021-07-09T23:05:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring places a small \"loader\" script into the head section of each page on a monitored site. This JavaScript instrumentation has been designed to: Provide maximum visibility into front-end performance, accurately time how long it takes for pages to load in all browsers, and to report details for JavaScript errors and AJAX calls. Have minimal impact on overall page load time and search engine optimization (SEO), including search engine ranking, indexing, crawl efficiency, or other SEO-related concerns. Contents Efficiency of inline JavaScript The most effective method for browser monitoring is to include a minimal amount of JavaScript instrumentation code inline in the head of the monitored page. This code then retrieves the remainder of the necessary code after the page finishes loading. Other browser monitoring methods include JavaScript code at the end of the page body or exclusively using an external script. However, these methods can limit visibility into the end users' experience. Impact on SEO Performance testing results indicate that using browser monitoring's JavaScript has a negligible effect on page load time. In addition, it has no negative impact on how users or search engines interact with your site. Google's consistent recommendation to website owners is to build a site that is valuable to users and accessible to search engine crawlers. Google rankings favor sites that provide the most relevant information and the best user experience. Browser monitoring can help you improve user experience by identifying performance bottlenecks, including: Slow page loads Problematic JavaScript errors Long AJAX calls Identifying Javascript errors is especially helpful because Google's bots are increasingly running the JavaScript code on websites they crawl in order to access content provided by AJAX-heavy web applications. A JavaScript error that previously was only visible to human users (for example, a broken button) could affect whether the Google bots can successfully interact with your site. We understand that SEO and traffic referred by search engines are critically important to many businesses. When used effectively, browser monitoring can even increase a site's ranking in Google and other search engines by improving performance and user experience.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.35284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> <em>monitoring</em> and search engine optimization",
        "sections": "<em>Browser</em> <em>monitoring</em> and search engine optimization",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> <em>monitoring</em> places a small &quot;loader&quot; script into the head section of each page on a monitored site. This JavaScript instrumentation has been designed to: Provide maximum visibility into front-end <em>performance</em>, accurately time how long it takes for pages to load in all browsers, and to report"
      },
      "id": "6043fa33196a675d7b960f85"
    },
    {
      "sections": [
        "addToTrace (browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples"
      ],
      "title": "addToTrace (browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "cfc07079342fec5115dbc68cff1d4a40a66f9836",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/addtotrace-browser-agent-api/",
      "published_at": "2021-10-18T07:16:54Z",
      "updated_at": "2021-10-01T23:08:02Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within browser session traces can provide context for other user actions, errors, and default events within the trace. This event will appear in the browser session trace details. If a session trace currently is in progress, this adds an object with a user-defined name, start time, and other optional fields. If you make this call and a session trace is not already in progress, this will not cause browser to capture a trace. Note that the number of events shared this way is limited by the Browser agent harvest cycle. Here is the last update on that limit. Parameters Parameter Description $custom_object JavaScript object Required. Supply a JavaScript object with these required and optional name/value pairs: Required name/value pairs: NAME, START Optional name/value pairs: END, ORIGIN, TYPE If you are sending the same event object to New Relic One as a PageAction, omit the TYPE attribute. (TYPE is a string to describe what type of event you are marking inside of a session trace.) If included, it will override the event type and cause the PageAction event to be sent incorrectly. Instead, use the NAME attribute for event information. Examples var obj = { // REQUIRED name: 'Event Name', start: 1417044274239, // Time in ms since epoch // OPTIONAL end: 1417044274252, // Time in ms since epoch. Defaults to same as start resulting in trace object with a duration of zero. origin: 'Origin of event', // Defaults to empty string type: 'What type of event was this' // Defaults to empty string } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.21171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addToTrace (<em>browser</em> agent API)",
        "sections": "addToTrace (<em>browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Syntax newrelic.addToTrace(JavaScript object $custom_object) Copy Adds a JavaScript object with a custom name, start time, etc. to an in-progress session trace. Requirements Agent version nr-593 or higher. Description Custom events within <em>browser</em> session traces can provide context for other user"
      },
      "id": "6043faae196a6774ac960f30"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/ajax-call-fails-cors-redirect-error-message": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.663284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.530136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/angularjs-errors-do-not-appear": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/app-server-requests-greatly-outnumber-browser-pageview-transactions": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    },
    {
      "sections": [
        "Troubleshooting session trace collection",
        "Problem",
        "Solution"
      ],
      "title": "Troubleshooting session trace collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "3b15d44fe2d49e081cbf39fb86da752f0726b6c8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/troubleshooting-session-trace-collection/",
      "published_at": "2021-10-18T18:48:58Z",
      "updated_at": "2021-07-22T02:20:45Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You're not seeing session traces for your browser application. Solution If your application is instrumented with APM and other features associated with the Pro browser agent are working, follow these steps: Check if you are using multiple names for your application. Session traces are written only to the primary application. If you are using multiple names, check your APM application names to verify that the app is listed first. If the application is not listed first, look for session traces in the application name listed first instead. Other reasons that you may not see session trace data include: The end users are not using browsers that support the Resource Timing API. The end users cannot post data to the /resources endpoint on bam.nr-data.net.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.56119,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshooting</em> session trace collection",
        "sections": "<em>Troubleshooting</em> session trace collection",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem You&#x27;re not seeing session traces for your <em>browser</em> application. Solution If your application is instrumented with APM and other features associated with the Pro <em>browser</em> agent are working, follow these steps: Check if you are using multiple names for your application. Session traces"
      },
      "id": "603e902c28ccbca1adeba793"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/browser-javascript-injection-causes-problems-page": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/get-browser-side-troubleshooting-details-har-file": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/not-seeing-specific-page-or-endpoint-names-browser-data": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.530075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/third-party-js-errors-missing-stack-traces": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshoot-ajax-data-collection": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/troubleshooting-session-trace-collection": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/new-relic-browser/troubleshooting/view-detailed-error-logs-browser": [
    {
      "sections": [
        "Troubleshoot your browser monitoring installation",
        "Problem",
        "Solution",
        "Deployment via APM agent",
        "Enable your app",
        "Update your APM agent",
        "Tip",
        "Verify the JavaScript snippets",
        "Check other JavaScript error monitors",
        "Configure auto-instrumentation",
        "Important",
        "Verify manual API instrumentation",
        "Restart your APM app",
        "Checkpoint: Verify JavaScript on page",
        "Verify end-user network access",
        "Deployment via JavaScript copy/paste",
        "Clear any cached versions of your pages",
        "Check the JavaScript placement and completeness",
        "Razor framework: Check for a parser error message"
      ],
      "title": "Troubleshoot your browser monitoring installation",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "38dd3206f05a9dda3e4561843c1488ecb0f3c276",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/troubleshooting/troubleshoot-your-browser-monitoring-installation/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-07-27T10:04:27Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem If you have just configured your application with browser monitoring, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these troubleshooting tips. Some of these tips depend on whether you deployed your app by allowing browser monitoring to automatically insert the JavaScript snippet into your APM-monitored app or by inserting the JavaScript snippet yourself. Solution Recommendation: Before following specific troubleshooting procedures, run the Diagnostics browser checks. Once Diagnostics CLI is downloaded, target the browser checks by running the command-line options: /nrdiag -browser-url YOUR-WEBSITE-URL -suites browser. The information returned from Diagnostics CLI can be used when communicating with New Relic Support. If your browser monitoring agent was deployed for an account monitored with an APM agent, see APM deployments. If your browser monitoring agent was deployed using the JavaScript copy/paste method, see Copy/paste deployment. If you are unsure which you have, the Diagnostics tool will return the deployment method. You can also troubleshoot situations where you are missing only AJAX or session trace data. Deployment via APM agent These troubleshooting steps apply to problems when the browser monitoring agent is installed on an app already being monitored by an APM agent: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Update your APM agent More recent APM agents place the page load timing scripts more accurately. Before continuing with these troubleshooting tips, make sure you have the most recent release for your APM agent. Tip For agent version requirements for page load timing, see Compatibility and requirements. Verify the JavaScript snippets Check your page's source for the two script elements required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> (window.NREUM||(NREUM={})).loader_config={xpid:\"VRUGVVJS\";window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){ ... Copy OR like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy Also verify that a second script element exists in one of two locations, depending on the app server agent language. C SDK: n/a Go: n/a Java: Before the </body> tag (which must be added to the page if missing) .NET: Immediately before the first script element Node.js: Immediately before the first script element PHP: At the end of the body element Python: In the head element or at the end of the body element Ruby: Immediately before the first script element The second tag contains configuration and timing data, and looks like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\"... Copy If either script element is missing, continue troubleshooting with the following steps. If the script elements are present and data does not appear after several minutes, get support at support.newrelic.com. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Configure auto-instrumentation If you are using New Relic's automatic instrumentation feature, ensure your agent is configured properly. Each agent has a configuration file setting and specific instructions to turn auto-instrumentation on or off: C SDK: n/a Go: n/a Java .NET Node.js agent: Currently not supported; see manual instrumentation procedures PHP Python Ruby Important If you modify your agent's configuration file, be sure to restart your app. Verify manual API instrumentation If you are manually calling the New Relic agent API to generate and insert the JavaScript, verify that the calls are actually being made. The APIs and how to use them are specific to your agent: C SDK: n/a Go: n/a Java agent .NET agent Node.js agent (see also the Node.js troubleshooting procedures) PHP agent Python agent Ruby agent Restart your APM app If you modified your APM agent's configuration file, be sure to restart your application so that it picks up the modified settings. Java agent: Flush the app server’s \"work\" cache. This forces the app server to recompile. .NET agent: Make sure your asp.net cache directory is clean by using the command flush_dotnet_temp.cmd. This forces the app server to recompile ASPs with page load timing instrumentation. Checkpoint: Verify JavaScript on page Verify that the JavaScript is on the page as detailed in the previous step Verify the JavaScript snippets. If it is not on the page, use the manual instrumentation as detailed in Verify manual API instrumentation. The Javascript must be present on your page before you can proceed to the next step. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Deployment via JavaScript copy/paste These troubleshooting steps apply to problems when New Relic's browser monitoring agent was deployed using the HTML copy/paste method: Enable your app Verify that browser monitoring has been enabled in your application's Browser settings: Go to one.newrelic.com > Browser > (select an app) > Settings. Follow standard procedures to enable browser settings for each app. Flush your webserver cache. Wait a few more minutes for data to arrive. Try the next steps if you still do not see any data. Verify the JavaScript snippets Check your page's source for the script element required to capture metrics and send them to New Relic. In a browser, view the source of your page, and look for a script element near the beginning like this: <script type=\"text/javascript\"> window.NREUM||(NREUM={}),__nr_require=function a (b,c,d){ ... Copy If the script element is missing, make sure that you have pasted it in and deployed your new code. If you have not yet pasted in the JavaScript snippet, you can copy it again from your browser app's Settings page. If applicable, restart the application serving these pages. If you still don't see the script, continue troubleshooting with the following steps. Clear any cached versions of your pages For the Javascript snippets to appear in pages served by your application, ensure that any cached versions of the pages from before you added the code have been cleared. Check any CDN caches. Flush your webserver cache. Check the JavaScript placement and completeness Insert the JavaScript as close to the top of the HEAD as possible, but after any position-sensitive META tags (X-UA-Compatible and charset). It must be outside any comments. Here is an example of the general format: <!DOCTYPE html> <html> <head> <meta tags> {PLACE NEW RELIC SCRIPT TAG HERE} <script and link tags> </head> <body> ... </body> </html> Copy If the Javascript is correctly placed, compare it with the original snippet you generated to ensure it is complete and identical. Incomplete or modified snippets may not report correctly. Check other JavaScript error monitors If you see JavaScript errors on your webpage, or if you do not see any data on your JavaScript errors page in the New Relic UI, check if any other JavaScript error monitoring frameworks have been enabled for your app. Some JavaScript error monitors may interfere with functionality for browser monitoring. Verify end-user network access If your application is loaded primarily within a secured local network, ensure that your users can reach the necessary network endpoints to report browser data. This includes New Relic's CDNs and beacon. Razor framework: Check for a parser error message If you use the copy/paste installation method in a .NET app that uses the Razor Framework, this may result in the following error: Parser Error Message: \"\").pop().split(\"\" is not valid at the start of a code block. Only identifiers, keywords, comments, \"(\" and \"{\" are valid. Copy The error is caused by an @ symbol in theJavaScript snippet for browser monitoring . The @ symbol represents the beginning of a code block in Razor. The line that causes the problem is: .split(\"@\").pop().split(\":\") Copy To fix this issue, use one of these workarounds: Wrap the browser JavaScript snippet in <text></text> tags to force it to be interpreted as content. OR Add another @ to the line to escape it. Check that the line looks like this: .split(\"@@\").pop().split(\":\") Copy Use only one of the workarounds. Using both will break the code again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.826904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "sections": "<em>Troubleshoot</em> your <em>browser</em> <em>monitoring</em> installation",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem If you have just configured your application with <em>browser</em> <em>monitoring</em>, wait a few minutes for data to appear. If you have already waited a few minutes and you still do not see any data, try these <em>troubleshooting</em> tips. Some of these tips depend on whether you deployed your app by allowing"
      },
      "id": "603e8f2864441fa5024e8877"
    },
    {
      "sections": [
        "Browser data doesn't match other analytics tools",
        "Problem",
        "Solution"
      ],
      "title": "Browser data doesn't match other analytics tools ",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "02439fadf41050ba60397b865b87f79576143295",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/browser-data-doesnt-match-other-analytics-tools/",
      "published_at": "2021-10-18T18:47:09Z",
      "updated_at": "2021-07-09T13:47:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem You see different data in browser monitoring than other analytics tools you use. Common symptoms include: Browser records fewer page views than you expect. Browser's geographical distribution for your users differs from the locations of your expected user base. Browser shows a different number of active sessions than you see elsewhere. Solution Follow these troubleshooting steps for browser monitoring: Check whether browser monitoring is properly installed in all of your application's pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic, follow the steps for troubleshooting browser monitoring installation. If you have a single-page style application and are expecting to see your route changes as views, consider using browser SPA monitoring, which provides an integrated view of initial page loads and route changes. If browser monitoring is working properly, you may be seeing different results because New Relic collects and presents information differently from other analytics tools. For more information about how we collects data, see: Page load timing process Instrumentation for browser monitoring Understand SPA data collection",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> data doesn&#x27;t match other analytics tools ",
        "sections": "<em>Browser</em> data doesn&#x27;t match other analytics tools",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " number of active sessions than you see elsewhere. Solution Follow these <em>troubleshooting</em> steps for <em>browser</em> <em>monitoring</em>: Check whether <em>browser</em> <em>monitoring</em> is properly installed in all of your application&#x27;s pages. If the JavaScript snippets are missing, or if users are unable to send data to New Relic"
      },
      "id": "6043ecc328ccbc6f972e1dcc"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-18T18:44:24Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.53003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring": [
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:21:56Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.00893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-18T07:21:57Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.80193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.6801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:06:59Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.22356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-18T07:21:57Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.80193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.6801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:06:59Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.22356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:21:56Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.00891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "New Relic <em>browser</em> <em>monitoring</em> has a <em>single</em>-<em>page</em> application (SPA) <em>monitoring</em> feature that provides deeper visibility and actionable insights into real user interactions with <em>single</em>-<em>page</em> apps, and for any <em>app</em> that uses AJAX requests. In addition to <em>monitoring</em> route changes automatically, our SPA API"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.6801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " are captured, either as a <em>Browser</em>Interaction event or as a <em>Page</em>Action event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Requirements",
        "Enable or disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:06:59Z",
      "updated_at": "2021-07-27T14:14:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page app (SPA) monitoring comes with the default install of the browser agent. Requirements You can review compability and requirements for SPA monitoring here. When you set up your first monitored app in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for an account. Enable or disable SPA monitoring When you enable browser monitoring, SPA monitoring is included by default because it gives access to a range of our most recent features, including distributed tracing. Some older agent installations may need to be upgraded. Read more about browser agent types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Single</em> <em>page</em> <em>app</em> (SPA) <em>monitoring</em> comes with the default install of the <em>browser</em> agent. Requirements You can review compability and requirements for SPA <em>monitoring</em> here. When you set up your first monitored <em>app</em> in a New Relic account, you must agree to the Terms of Service. By agreeing to the terms"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-10-18T07:21:56Z",
      "updated_at": "2021-07-21T20:07:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic browser monitoring has a single-page application (SPA) monitoring feature that provides deeper visibility and actionable insights into real user interactions with single-page apps, and for any app that uses AJAX requests. In addition to monitoring route changes automatically, our SPA API allows you to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring SPA monitoring is enabled by default for new browser agent installations. The SPA-enabled version of the agent gives access to other powerful New Relic features, like distributed tracing. For more information, see Enable browser monitoring. For compatability information for SPA-related features, see SPA requirements. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by browser monitoring includes: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing browser account's data usage, see SPA and browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.04643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " your <em>app</em>&#x27;s <em>page</em> loads and route changes, and be able to solve bottlenecks and <em>troubleshoot</em> errors. For more about how New Relic handles SPA data, see Understand SPA data collection. <em>Browser</em> SPA features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-10-18T07:21:57Z",
      "updated_at": "2021-07-09T07:41:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the browser snippet, available for browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow browser's guidelines for security with data collection and reporting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.2804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>browser</em> snippet, available for <em>browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-10-18T18:48:58Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.37878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-10-18T07:23:07Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.23856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.92667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-10-18T18:48:58Z",
      "updated_at": "2021-07-09T10:04:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by browser interaction name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line shows when the window load event is fired. This corresponds to the traditional page load timing measured by the browser agent without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.37877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-10-18T07:23:08Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.36461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.92667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-10-18T07:23:08Z",
      "updated_at": "2021-07-09T08:08:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, browser initiates monitoring but then discards them. If these interactions do lead to a route change, browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.36461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-10-18T07:23:07Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.23856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-10-18T07:23:54Z",
      "updated_at": "2021-08-20T21:36:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal throughout 2021 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The browser agent attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.92667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing route changes with <em>SPA</em> agent",
        "sections": "Missing route changes with <em>SPA</em> agent",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " Short term solutions To make sure all route changes are captured, you can <em>use</em> our <em>SPA</em> interaction() API. Using the interaction API will categorize the <em>Browser</em>Interaction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.6971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.6971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.69708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-18T07:25:32Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.70282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-18T07:25:32Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.70279,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format": [
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-18T07:25:32Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.70277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations": [
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.0376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integration configuration overview",
        "Overview of how configuration works",
        "Configuration file location",
        "Configuration formats"
      ],
      "title": "On-host integration configuration overview",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "b580c10bb0a6142dcb204639762561b65bd6ceb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview/",
      "published_at": "2021-10-18T07:07:51Z",
      "updated_at": "2021-09-27T16:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host integrations send data to the infrastructure agent, which in turn sends that data to New Relic. How integrations interact with the agent is controlled by each integration's config. Understanding more about configuration can help you troubleshoot issues with your on-host integration. Overview of how configuration works New Relic's on-host integrations are external programs executed by the infrastructure agent. Each integration monitors a specific service. An integration has, at minimum, these files: An executable that exports various types of data in a JSON format expected by the agent One or more YAML-format config files (for example, the Apache integration configuration). (We recommend linting YAML config files before use to avoid formatting issues.) Note that in addition to the specific on-host integration's configuration, you can also edit the infrastructure agent's configuration. Configuration file location With standard on-host integration installations, the configuration is located in the infrastructure agent's directory. The agent determines this config location by a setting in its own configuration file. For some implementations, the integration's configuration will be located elsewhere. For example: Services running on Kubernetes: The configuration is located in the Kubernetes integration config file. Services running on Amazon ECS: The configuration is placed in the AWS console. Configuration formats On-host integrations use two configuration formats: Standard: Starting December 2019, infrastructure agent version 1.8.0 began supporting a new format used by some integrations. This format uses a single configuration file and provides other improvements. For more details, see Standard configuration. Legacy: This is the format used by most on-host integrations. This configuration uses two files: a definition file and a configuration file. For more details, see Legacy configuration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.03555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> configuration overview",
        "sections": "On-host <em>integration</em> configuration overview",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic&#x27;s on-host <em>integrations</em> send data to the <em>infrastructure</em> agent, which in turn sends that data to New Relic. How <em>integrations</em> interact with the agent is controlled by each integration&#x27;s config. Understanding more about configuration can help you troubleshoot issues with your on-host"
      },
      "id": "6044091d28ccbc95852c60cb"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes": [
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-18T07:25:32Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.61038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.13852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.13849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data": [
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-18T07:25:32Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.61035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Legacy configuration format",
        "sections": "On-host <em>integrations</em>: Legacy configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format"
      },
      "id": "61505613196a676ce3b70d9a"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Standard configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-10-18T07:09:05Z",
      "updated_at": "2021-09-27T16:02:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In December 2019, Infrastructure agent version 1.8.0 began supporting this new configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older legacy configuration format is also supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Environment variables, using the env property. (recommended) Command-line arguments, passed in the exec property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Important New Relic recommends passing env keys in capital letters, as per the example below, for compatibility with all infrastructure agent versions since 1.8.0. If you are using agent version 1.20.0 or above you can use small caps as the agent will automatically uppercase them. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx cli_args: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: nri-apache env: METRICS: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 15s labels: env: production role: load_balancer - name: nri-apache env: INVENTORY: \"true\" STATUS_URL: http://127.0.0.1/server-status?auto REMOTE_MONITORING: true interval: 60s labels: env: production role: load_balancer inventory_source: config/apache Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.1385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format ",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " format is also supported by current <em>Infrastructure</em> agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration&#x27;s configuration YAML must have an <em>integrations</em> top-level section containing a YAML array, where each entry represents an integration"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-10-18T07:25:34Z",
      "updated_at": "2021-09-27T16:02:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent A configuration file For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.13847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    }
  ],
  "/docs/distributed-tracing/concepts/distributed-tracing-planning-guide": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-10-18T05:27:50Z",
      "updated_at": "2021-07-22T05:57:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.34195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.4713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.88997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-10-18T10:59:04Z",
      "updated_at": "2021-07-09T04:30:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.0898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine that <em>trace</em>. Cross-application <em>tracing</em> will be disabled"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.4713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.88997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/concepts/introduction-distributed-tracing": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-10-18T10:59:04Z",
      "updated_at": "2021-07-09T04:30:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.0898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine that <em>trace</em>. Cross-application <em>tracing</em> will be disabled"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-10-18T05:27:50Z",
      "updated_at": "2021-07-22T05:57:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.34195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.88997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and <em>get</em> <em>started</em> quickly, go to <em>Start</em> reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (Infinite <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.52194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:00:33Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.89178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.73729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> <em>enabled</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " won&#x27;t automatically propagate the <em>distributed</em> <em>tracing</em> header. In that case, you must <em>configure</em> that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in <em>trace</em>. If the intermediary"
      },
      "id": "6072a76764441f109b9d857b"
    }
  ],
  "/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-10-18T05:27:50Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.13766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:00:33Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.89178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.73729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> <em>enabled</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " won&#x27;t automatically propagate the <em>distributed</em> <em>tracing</em> header. In that case, you must <em>configure</em> that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in <em>trace</em>. If the intermediary"
      },
      "id": "6072a76764441f109b9d857b"
    }
  ],
  "/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.52193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up Infinite <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-10-18T05:27:50Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.13766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.73729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> <em>enabled</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " won&#x27;t automatically propagate the <em>distributed</em> <em>tracing</em> header. In that case, you must <em>configure</em> that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in <em>trace</em>. If the intermediary"
      },
      "id": "6072a76764441f109b9d857b"
    }
  ],
  "/docs/distributed-tracing/enable-configure/quick-start": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 647.9374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em> (recommended):",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of <em>distributed</em> <em>tracing</em>: <em>Quick</em> <em>start</em> for standard <em>distributed</em> <em>tracing</em> (recommended): A fast way to get started Infinite <em>Tracing</em>: An advanced alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-10-19T00:59:12Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-10-19T00:59:11Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our instrumentation examples: Extension repo Go agent repo Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.2.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.2.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.70517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " to function but they are required if you want your Lambda functions to be included in <em>distributed</em> traces. To enable <em>distributed</em> <em>tracing</em>, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-08-26T14:11:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry, OpenCensus, others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.79816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/index": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/ruby-8-0-0-update/",
      "sections": [
        "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0"
      ],
      "published_at": "2021-10-19T06:03:25Z",
      "title": "Distributed Tracing enabled by default with Ruby Agent Update: Version 8.0.0",
      "updated_at": "2021-10-17T11:31:06Z",
      "type": "docs",
      "external_id": "cefc251f04969df932c038b1afee81f1ceebb7d0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you'll have Distributed Tracing on by default. This eliminates the need to configure the agent to have access to distributed traces. Distributed Tracing gives software teams working in modern environments an easy way to capture, visualize, and analyze traces through complex architectures, including architectures that use both monoliths and microservices. What’s the impact? With this change, you'll see distributed traces immediately upon upgrading to Ruby version v8.0.0. Distributed Tracing on by default provides more data and better visibility for cross-application requests. If you do not need this feature, you can turn it off in the Ruby agent configuration file by setting distributed_tracing.enabled=false or by setting the environment variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=false. If you need more traces and are experiencing dropped spans, the agent reservoir can be expanded to accommodate more spans. To do so, set the environment variable or config item called span_events.max_samples_stored to a value greater than 2,000 up to a maximum value of 10,000. Note that increasing this value may impact memory usage. With Distributed Tracing on by default, Cross Application Tracing (CAT) will now be deprecated and will be removed in a future version of the agent. If you're on CAT, you'll now see distributed traces instead. If you want to revert back to CAT, you can do so by setting cross_application_tracer.enabled = true in the configuration file. We recommend you to keep using distributed tracing, given that CAT will be removed in the future.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 779.60046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>Tracing</em> enabled by default with Ruby Agent Update: Version 8.0.0",
        "sections": "<em>Distributed</em> <em>Tracing</em> enabled by default with Ruby Agent Update: Version 8.0.0",
        "body": "With the release of Ruby Agent version v8.0.0, upon agent upgrade, you&#x27;ll have <em>Distributed</em> <em>Tracing</em> on by default. This eliminates the need to configure the agent to have access to <em>distributed</em> traces. <em>Distributed</em> <em>Tracing</em> gives software teams working in modern environments an easy way to capture"
      },
      "id": "616c097ae7b9d2f64c477225"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://docs.newrelic.com/static/f487e8c287d614c494f56bd35fd38bb5/c1b63/arrow-step-diagram-trans.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/quick-start/",
      "sections": [
        "Distributed tracing quick start"
      ],
      "published_at": "2021-10-18T05:27:50Z",
      "title": "Distributed tracing quick start",
      "updated_at": "2021-09-14T05:45:31Z",
      "type": "docs",
      "external_id": "f9f4aa287602eee82a0eb7d15775d033ada26d63",
      "document_type": "page",
      "popularity": 1,
      "body": "To set up distributed tracing, you'll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you'll need this information in the next step). If you have an environment diagram like the following, you could use it to create a list of services handling requests: Instrument services: Instrument each service you identify so it can send your trace data. Some tools, such as APM agents, instrument services automatically, while other tools require you to insert some code in the services. Click the icon below for instrumentation steps: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Browser monitoring Mobile monitoring AWS Lambda Functions Istio Kamon OpenTelemetry X-Ray Zipkin format: custom integration New Relic format: custom integration View traces: After you instrument the services, generate some traffic in your application, and then go to the New Relic UI to see your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em> quick start",
        "sections": "<em>Distributed</em> <em>tracing</em> quick start",
        "body": "To set up <em>distributed</em> <em>tracing</em>, you&#x27;ll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you&#x27;ll need this information in the next step). If you have an environment diagram like"
      },
      "id": "6072a60564441f2f6f9d8541"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-proxy-support": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-random-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-span-attribute-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-10-18T11:13:51Z",
      "updated_at": "2021-09-14T09:14:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.50482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", and then click Traces. Select your entity in the left pane. If you don&#x27;t see the traces you want, you can filter by the <em>trace</em>.id. For more help finding your traces in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.37524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> API",
        "sections": "Introduction to the <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the <em>Trace</em> API? The <em>Trace</em> API is one way that New Relic collects <em>distributed</em> <em>tracing</em> data. We have some <em>tracing</em> tools that report data via this API (<em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.41118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-18T20:17:19Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.32043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-18T20:45:13Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.87631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-18T20:15:30Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.45659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.74483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-18T20:17:19Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.32043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-18T20:45:13Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.87631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.74483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-18T20:45:13Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.87631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-18T20:15:30Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.45657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.74483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-18T20:17:19Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.32043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Data limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-10-18T20:45:13Z",
      "updated_at": "2021-08-27T14:05:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via HTTPS POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires a license key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Data limits Distributed tracing rate limits are set per account and data type. For details about data limits, see New Relic data usage limits and policies. When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.87631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "). Infinite <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Introduction to the Trace API",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-10-18T20:16:20Z",
      "updated_at": "2021-08-26T14:08:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. Want to try out the Trace API? Make sure you've created a free New Relic account. No credit card required. To skip some introductory content and get started quickly, go to Start reporting data. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.74481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. Want to try out the <em>Trace</em> <em>API</em>? Make sure you&#x27;ve created a free New"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-10-18T20:17:19Z",
      "updated_at": "2021-08-26T14:09:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.32042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Report traces via the Trace API (New Relic format)",
        "Get started",
        "Send sample trace payload (non-Infinite Tracing)",
        "Tip",
        "Trace API payload (New Relic format)",
        "The Span object in the spans array",
        "The common object (optional)",
        "Highly recommended attributes",
        "Reserved attributes",
        "Other attributes",
        "Explore more about distributed tracing:"
      ],
      "title": "Report traces via the Trace API (New Relic format)",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "7b6be23c78b9a06ebf71671cc69590b4ac4b3311",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/",
      "published_at": "2021-10-18T20:15:30Z",
      "updated_at": "2021-08-26T14:10:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send traces in our general format, aka new-relic format. (To send Zipkin-format data, see Zipkin.) Get started Using our Trace API is as simple as: Sending trace data in the expected format (in this case, our new-relic format). Sending that data to the appropriate endpoint. Before using the Trace API, you should decide whether you want to use Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, follow one of these paths: Want to use Infinite Tracing? Follow the Set up a trace observer instructions. That walks you through creating a trace observer and sending a sample payload to the trace observer endpoint. Don't want Infinite Tracing? See how to send a sample payload (below). Send sample trace payload (non-Infinite Tracing) The following explains how to send a standard (non-Infinite Tracing) payload to the Trace API using our newrelic format. Get a license key for the account you want to report data to. Insert that key into the following JSON and then send the JSON to our endpoint. Note: if you have a EU New Relic account, use the EU endpoint instead. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $YOUR_LICENSE_KEY' \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"service.name\": \"Test Service A\", \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"name\": \"/home\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"error.message\": \"Invalid credentials\", \"service.name\": \"Test Service A\", \"host\": \"host456.example.com\", \"duration.ms\": 2.97, \"name\": \"/auth\", \"parent.id\": \"ABC\" } } ] } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Tip If you're sending more than one POST, change the trace.id to a unique value. Sending the same payload or span id multiple times for the same trace.id may result in fragmented traces in the UI. If your test returned HTTP/1.1 202 Accepted, go to our UI to see a query of your test data using the span attribute service.name = Test Service A. Tip Traces may take up to one minute to be processed by both the trace observer and the Trace API. Trace API payload (New Relic format) The Trace API JSON payload is an array of objects, with each object representing a single trace. Each of these objects requires a spans key and may also include a common key. spans (required) contains an array of objects, with each object representing a span. common (optional) shares information across multiple spans. The Span object in the spans array field type description required default id string Unique identifier for this span. yes N/A trace.id string Unique identifier shared by all spans within a single trace. yes N/A timestamp long Span start time in milliseconds since the Unix epoch. no Current time in UTC timezone attributes object Any set of key: value pairs that add more details about a span. duration.ms, name, and parent.id are strongly recommended to add. no N/A Requests without the required keys above will be rejected, and an NrIntegrationError will be generated. The common object (optional) field type description required default attributes object Any set of key: value pairs that add common details about spans in the payload. If a span contains an attribute that has been set in common, the key in the span attributes object will take precedence. duration.ms, name, and parent.id are strongly recommended to add. no N/A Highly recommended attributes While not required, these attributes should be included for the best experience with your data in the attributes object for each span. attribute default description duration.ms float none Duration of this span in milliseconds. name string none The name of this span. parent.id string none The id of the caller of this span. Value is null if this is the root span. Traces without a root span will not be displayed. service.name string none The name of the entity that created this span. Reserved attributes These attributes are currently reserved for internal New Relic usage. While they are not explicitly blocked, we recommend not using them. attribute default description entity.name string service.name This is derived from the service.name attribute. entity.type string service The entity type is assumed to be a service. entity.guid string None The entity.guid is a derived value that uniquely identifies the entity in New Relic's backend. Other attributes You can add any arbitrary attributes you want in the attributes object in either common or each span object, with the exception of the restricted attributes. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Requirements and guidelines for trace JSON using the newrelic format: Each JSON payload is an array of objects. Each object should contain a required spans key. Each object can contain an optional common key. Use this if you want to share information across multiple spans in a object. Any keys on a span have precedence over the same key in the common block. The value for a spans key is a list of span objects. Certain attributes are required, and must be included either in the optional common block, or in each span. Recommended and custom attributes can be optionally included in a list of key-value pairs under a key named attributes, in the optional common block and/or in each span. In the following example POST, there are two spans, both of which have the trace.id 12345 and the custom attribute host: host123.example.com. The first span has no parent.id, so that is the root of the trace; the second span's parent.id points to the ID of the first. [ { \"common\": { \"attributes\": { \"host\": \"host123.example.com\" } }, \"spans\": [ { \"trace.id\": \"12345\", \"id\": \"abc\", \"timestamp\": 1603336834823, \"attributes\": { \"user.email\": \"bob@newr.com\", \"service.name\": \"my-service\", \"duration.ms\": 750, \"name\": \"my-span\" } }, { \"trace.id\": \"12345\", \"id\": \"def\", \"timestamp\": 1603336834899, \"attributes\": { \"parent.id\": \"abc\", \"service.name\": \"second-service\", \"duration.ms\": 750, \"name\": \"second-span\" } } ] } ] Copy To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about distributed tracing: Learn where Trace API data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience. For example, you can have spans show up as datastore spans or display errors. Learn about general data limits, required metadata, and response validation. If you don't see your trace data, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.45657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>traces</em> via the <em>Trace</em> <em>API</em> (New Relic format)",
        "sections": "Explore more about <em>distributed</em> <em>tracing</em>:",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans. Explore more about <em>distributed</em> <em>tracing</em>: Learn where <em>Trace</em> <em>API</em> data shows up in the UI. Learn how to decorate spans for a richer, more detailed UI experience"
      },
      "id": "6071cfc8196a6790e864a7a4"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.67998,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem You have enabled <em>distributed</em> <em>tracing</em> but data you expected to see does not appear in New Relic&#x27;s <em>distributed</em> <em>tracing</em> UI. Solution Important Before performing <em>troubleshooting</em>, we recommend reading How <em>distributed</em> <em>tracing</em> works. Here are some causes and solutions when you have problems"
      },
      "id": "6072a76764441f109b9d857b"
    },
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "edc5ecde0c7ac8348afbcc6b82de546b0b60d349",
      "image": "",
      "url": "https://docs.newrelic.com/docs/understand-dependencies/understand-system-dependencies/service-maps/how-use-service-maps/",
      "published_at": "2021-10-19T05:23:47Z",
      "updated_at": "2021-08-21T10:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.01945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Minimum versions when <em>distributed</em> <em>tracing</em> is enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Service maps work with <em>distributed</em> <em>tracing</em> to connect relationships between entities. Service maps are still functional if you have not enabled <em>distributed</em> <em>tracing</em>, but we recommend having <em>distributed</em> <em>tracing</em> enabled for all agents. This ensures a more consistent experience while using service maps"
      },
      "id": "603ec23264441fb02c4e8893"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.63335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-10-18T20:12:37Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.2897,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infinite <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "Infinite <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled Infinite <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-Infinite <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling Infinite <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "edc5ecde0c7ac8348afbcc6b82de546b0b60d349",
      "image": "",
      "url": "https://docs.newrelic.com/docs/understand-dependencies/understand-system-dependencies/service-maps/how-use-service-maps/",
      "published_at": "2021-10-19T05:23:47Z",
      "updated_at": "2021-08-21T10:54:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.01944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Minimum versions when <em>distributed</em> <em>tracing</em> is enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Service maps work with <em>distributed</em> <em>tracing</em> to connect relationships between entities. Service maps are still functional if you have not enabled <em>distributed</em> <em>tracing</em>, but we recommend having <em>distributed</em> <em>tracing</em> enabled for all agents. This ensures a more consistent experience while using service maps"
      },
      "id": "603ec23264441fb02c4e8893"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.63333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.14459,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.6484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-18T15:35:56Z",
      "updated_at": "2021-10-13T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.91162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Logs <em>UI</em>",
        "sections": "Use Logs <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " were operating when performance noticeably slowed: Go to one.newrelic.com &gt; <em>Distributed</em> <em>tracing</em>. Select a particularly slow <em>trace</em>. From the <em>trace</em> Details, click See logs for this <em>trace</em>. Browse related logs in the Logs <em>UI</em>. Links to logs in New Relic Depending on your New Relic subscription, you can"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-09-13T22:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.14459,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.0972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-18T15:35:56Z",
      "updated_at": "2021-10-13T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.91156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Logs <em>UI</em>",
        "sections": "Use Logs <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " were operating when performance noticeably slowed: Go to one.newrelic.com &gt; <em>Distributed</em> <em>tracing</em>. Select a particularly slow <em>trace</em>. From the <em>trace</em> Details, click See logs for this <em>trace</em>. Browse related logs in the Logs <em>UI</em>. Links to logs in New Relic Depending on your New Relic subscription, you can"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-10-18T20:14:30Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.6484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-10-18T20:13:27Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.0972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-18T15:35:56Z",
      "updated_at": "2021-10-13T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if available) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.91156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Logs <em>UI</em>",
        "sections": "Use Logs <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " were operating when performance noticeably slowed: Go to one.newrelic.com &gt; <em>Distributed</em> <em>tracing</em>. Select a particularly slow <em>trace</em>. From the <em>trace</em> Details, click See logs for this <em>trace</em>. Browse related logs in the Logs <em>UI</em>. Links to logs in New Relic Depending on your New Relic subscription, you can"
      },
      "id": "603ea62e64441ff7ba4e8854"
    }
  ],
  "/docs/full-stack-observability/index": [
    {
      "sections": [
        "New Relic Instant Observability overview",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic Instant Observability overview",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-19T01:44:41Z",
      "updated_at": "2021-10-18T02:02:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Instant <em>Observability</em> overview",
        "sections": "New Relic Instant <em>Observability</em> overview",
        "tags": "<em>Observe</em> everything",
        "body": "Monitor your tech stack without the burden of manual set up. New Relic I&#x2F;O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by <em>observability</em> experts around the world, vetted by New Relic, and ready for you"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-10-18T06:36:55Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.97358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "New Relic <em>solutions</em>"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2021-10-18T05:03:19Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.22507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "New Relic <em>solutions</em>"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations": [
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-10-19T05:58:32Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.42906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: <em>Get</em> data flowing into New Relic with the Prometheus remote write integration",
        "body": " dashboards with Prometheus data look in our new dark mode. Step 1: <em>Get</em> data flowing into New Relic with the Prometheus remote write integration Go to <em>Instrument</em> <em>Everything</em> – US or <em>Instrument</em> <em>Everything</em> – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to <em>get</em>"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "bd62b563a23cb35cc2aabc7f1f44e3dcacbce3cf",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/introduction-new-relic/",
      "published_at": "2021-10-19T01:44:41Z",
      "updated_at": "2021-10-19T01:44:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will setup many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in our Telemetry Data Platform—no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic integrations. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. As a full user you get access to our entire set of observability tools in New Relic One: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.07902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with New Relic",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: <em>Instrument</em> <em>everything</em> and import data from across"
      },
      "id": "6043ad0764441f5a06378ecd"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.34621,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations": [
    {
      "image": "https://docs.newrelic.com/static/d2a9c929c7541b67b6fe4c87844fc01b/ae694/prometheus_grafana_dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2020/08/create-grafana-dashboards-prometheus-data-stored-new-relic/",
      "sections": [
        "Create Grafana dashboards with Prometheus data stored in New Relic",
        "Step 1: Get data flowing into New Relic with the Prometheus remote write integration",
        "Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic"
      ],
      "published_at": "2021-10-19T05:58:32Z",
      "title": "Create Grafana dashboards with Prometheus data stored in New Relic",
      "updated_at": "2021-10-19T05:58:32Z",
      "type": "docs",
      "external_id": "da09ab47a2ac806ad3ed1fa67e3a02dd54394383",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’ve teamed up with Grafana Labs so you can use our platform as a data source for Prometheus metrics and see them in your existing dashboards, seamlessly tapping into the reliability, scale, and security provided by New Relic. Follow the steps below or use this more detailed walkthrough to send Prometheus data to New Relic, so that Grafana can populate your existing Prometheus-specific dashboards with that data. This process requires Prometheus version 2.15.0 or higher and Grafana version 6.7.0 or higher. You’ll also need to sign up for New Relic. Here's an example of how these Grafana dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to Instrument Everything – US or Instrument Everything – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get your remote_write URL. For more information on how to set up the Prometheus remote write integration, check out our docs. Step 2: Configure your Grafana dashboards to use Prometheus data stored in New Relic For more information on how to configure New Relic as a Prometheus data source for Grafana, check out our docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.52583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " dashboards with Prometheus data look in our new dark mode. Step 1: Get data flowing into New Relic with the Prometheus remote write integration Go to <em>Instrument</em> <em>Everything</em> – US or <em>Instrument</em> <em>Everything</em> – EU, then click the Prometheus tile. You can also go to the Prometheus remote write setup page to get"
      },
      "id": "60445821e7b9d23b585799e4"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-10-18T07:28:05Z",
      "updated_at": "2021-07-27T09:41:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.90458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Instrument</em> <em>everything</em>",
        "body": " of <em>applications</em>, frameworks, <em>services</em>, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-10-19T03:19:38Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 64.55009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Instrument</em> <em>everything</em>",
        "body": "? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of <em>services</em>. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format"
      },
      "id": "6044e44f196a678d15960f6e"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability": [
    {
      "sections": [
        "New Relic Instant Observability overview",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic Instant Observability overview",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-19T01:44:41Z",
      "updated_at": "2021-10-18T02:02:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.20859,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Instant <em>Observability</em> overview",
        "sections": "New Relic Instant <em>Observability</em> overview",
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": " to install with one click. Leverage community expertise and <em>get</em> more value out of your telemetry data with New Relic I&#x2F;O, your hub for instant observability. Ready to <em>get</em> <em>started</em>? Find your quickstart in New Relic I&#x2F;O: New Relic I&#x2F;O Why it matters With our I&#x2F;O catalog, you can choose from hundreds"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-10-18T07:29:23Z",
      "updated_at": "2021-08-20T13:37:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.643234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.346146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview": [
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-18T13:05:54Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.81155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " allows you to <em>start</em> your <em>observability</em> journey from any element of your <em>stack</em>. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and <em>observe</em> the <em>full</em> <em>stack</em> of your software, see"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "New Relic Instant Observability overview",
        "Why it matters",
        "What are quickstarts",
        "Some technical detail"
      ],
      "title": "New Relic Instant Observability overview",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started",
        "Quickstarts",
        "Instant Observability"
      ],
      "external_id": "e12df6102b9361f953bdab2f4b49baa5756f7048",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview/",
      "published_at": "2021-10-19T01:44:41Z",
      "updated_at": "2021-10-18T02:02:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor your tech stack without the burden of manual set up. New Relic I/O is a rich catalog of open source quickstarts - out-of-the-box bundles of integrations, dashboards, and alerts. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O Why it matters With our I/O catalog, you can choose from hundreds of quickstarts that bundle the necessary building blocks to get started with monitoring your technology stack; that includes instrumentation, integrations, dashboards, and alerts, all ready to install with a click. What are quickstarts Quickstarts are bundles of dashboards, alerts, and instrumentation that are ready to install with a single click, specific to each technology we support. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of instrumentations, dashboards, and alerts. New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edit to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.20847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Instant <em>Observability</em> overview",
        "sections": "New Relic Instant <em>Observability</em> overview",
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": " to install with one click. Leverage community expertise and <em>get</em> more value out of your telemetry data with New Relic I&#x2F;O, your hub for instant <em>observability</em>. Ready to <em>get</em> <em>started</em>? Find your quickstart in New Relic I&#x2F;O: New Relic I&#x2F;O Why it matters With our I&#x2F;O catalog, you can choose from hundreds"
      },
      "id": "6157008964441f500d099617"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-10-18T07:28:05Z",
      "updated_at": "2021-07-27T09:41:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Choose what&#x27;s right for you We offer a wide range of solutions so you can easily collect"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-quickstarts-overview": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/10/instant-observability-10-13-21/",
      "sections": [
        "Get Instant Observability with New Relic I/O",
        "Solution overview",
        "Demo",
        "Get started",
        "Partner quickstarts"
      ],
      "published_at": "2021-10-19T03:36:18Z",
      "title": "Get Instant Observability with New Relic I/O",
      "updated_at": "2021-10-17T11:37:51Z",
      "type": "docs",
      "external_id": "c5c0dc59e4c357e64d4d41f42eed85b035e5cc55",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We're excited to announce New Relic Instant Observability (I/0), the fastest way to instrument, monitor, and analyze your technology stack while avoiding the burden of manual setup. It is a rich open source catalog of 400+ quickstarts (pre-built bundles of observability tools) contributed by experts around the world, reviewed by New Relic, and ready for you to install in a few clicks. Solution overview No matter what technologies and tools you use in your stack, you can get more insights from your telemetry data in minutes. With New Relic I/O, you can: Reduce instrumentation toil with an easy, guided installation Get started faster with pre-built dashboards and alerts Leverage best practices from domain experts and technology partners Quickstarts can contain any combination of instrumentation, integrations, dashboards, and alerts. Note that only full users will be able to access dashboards deployed from quickstarts. Every new account, including our Free Forever tier, gets one full user absolutely free. Demo Watch a quick demo and learn how to install a quickstart below: Get started Install a quickstart from New Relic I/O. If you don't have a New Relic account yet, browse the public New Relic I/O catalog. Want to share your monitoring use case or best practices? New Relic Instant Observability is open source, so it’s easy to add to quickstarts or build a brand new one. Help drive the mission to democratize observability—and be featured as a quickstart author. Contribute a quickstart! Learn more by reading the blog post. Partner quickstarts We are proud to launch New Relic Instant Observability with pre-built quickstarts from five leading enterprise software partners. We have partnered closely with them to create quickstarts that help you extend your New Relic One experience: Kentik is the network observability company. The Kentik quickstarts help network and development teams quickly identify and troubleshoot application performance issues correlated with network traffic performance and health data. Fastly is an edge cloud platform that enables its customers to create great digital experiences quickly, securely, and reliably. With the Fastly CDN quickstart, you can monitor key metrics from Fastly's content delivery network that can help you improve service reliability and ensure great online experiences for end users. Lacework is a data-driven security platform for the cloud that can collect, analyze, and accurately correlate data across an organization's AWS, Azure, GCP and Kubernetes environments, and narrow it down to the handful of security events that matter. The Lacework quickstart bridges the gap between observability and security teams, and integrates with New Relic's database to surface security events and alerts directly in New Relic One. Cribl is the observability pipeline company that lets customers parse and route any type of data. The Cribl quickstart allows you to get immediate visibility into your entire environment right from New Relic One without the need to create your own dashboards and alerts---simplifying your workflows and reducing time to value. Trend Micro is a global cyber security leader. The Trend Micro Cloud One quickstart ingests cloud security posture management (CSPM) data from Conformity into New Relic One to contextualize and correlate it with workload telemetry data, delivering AI-powered visualizations and quick insights. This allows security and cloud teams to immediately take action in improving their security and compliance postures. Gigamon is the cloud visibility company. The Gigamon Hawk hybrid-cloud visibility and analytics platform provides access to - and extracts intelligence from all network traffic. The Gigamon quickstart delivers advanced security capabilities that offer network detection and response to advanced threats, including shadow IT activities, crypto-mining and torrent activities, SSL cipher versions and expiration dates across both managed and unmanaged hosts, such as IoT/OT and containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.64284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>Instant</em> <em>Observability</em> with New Relic I&#x2F;O",
        "sections": "<em>Get</em> <em>Instant</em> <em>Observability</em> with New Relic I&#x2F;O",
        "body": " dashboards deployed from <em>quickstarts</em>. Every new account, including our Free Forever tier, gets one full user absolutely free. Demo Watch a quick demo and learn how to install a <em>quickstart</em> below: <em>Get</em> <em>started</em> Install a <em>quickstart</em> from New Relic I&#x2F;O. If you don&#x27;t have a New Relic account yet, browse"
      },
      "id": "616c0b0f196a671a8c3c9c10"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-10-18T13:05:54Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.90042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with Full-Stack <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with Full-Stack <em>Observability</em>",
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": " allows you to <em>start</em> your <em>observability</em> journey from any element of your stack. For example, you can <em>get</em> to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and <em>observe</em> the full stack of your software, see"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-10-18T07:29:23Z",
      "updated_at": "2021-08-20T13:37:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.12218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Observe</em> <em>everything</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-19T03:57:25Z",
      "updated_at": "2021-10-19T03:57:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. (Note that Request is deprecated, but these options still apply.) Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. We recommend using SSL to avoid exposing plain text credentials in your headers. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.616646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write synthetic <em>API</em> tests",
        "sections": "Write synthetic <em>API</em> tests",
        "body": " = &#x27;{YOUR_ACCOUNT_ID}&#x27;; var myQueryKey = &#x27;{YOUR_QUERY_KEY}&#x27;; var options = { &#x2F;&#x2F;Define endpoint URI uri: &#x27;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;&#x27;+myAccountID+&#x27;&#x2F;query?nrql=SELECT%20average(amount)%20<em>FROM</em>%20SyntheticsEvent&#x27;, &#x2F;&#x2F;Define query key and expected <em>data</em> type. headers: { &#x27;X-Query-Key&#x27;: myQueryKey, &#x27;Accept"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/logs-release-notes/logs-21-08-30/",
      "sections": [
        "Logs v210830",
        "New public APIs",
        "Headerless HTTP ingest",
        "More data, more power",
        "Bug fixes",
        "Notes"
      ],
      "published_at": "2021-10-19T03:56:24Z",
      "title": "Logs v210830",
      "updated_at": "2021-10-19T03:56:23Z",
      "type": "docs",
      "external_id": "16f8a2cd04064a3125b37fd4c9894b28aa209d90",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "New public APIs Public APIs are now available for parsing and pipeline configuration, such as drop filters. For more information, try out NerdGraph, our GraphQL-format API explorer, at api.newrelic.com/graphiql. Also see our NerdGraph parsing rules tutorial and drop data tutorial. Headerless HTTP ingest Added support for headerless HTTP log ingest. This enables Logs customers to send data to New Relic from sources that do not permit the customization of HTTP request headers (for example, Api-Key or X-License-Key). This approach is most often used when forwarding logs from cloud-based platforms. More data, more power Increased maximum attribute value size. The Logs team recognizes that keeping all data from a log is extremely important, and so we are providing additional functionality to store more data and reduce the chances of truncation. Attributes can now store and display up to 128 kb, the first 4096 bytes of which are searchable. For more information, see our documentation about finding data in long logs (blobs) and the Log Event API. Added ARM support to our Helm-based Kubernetes integration. Bug fixes Fixed several styling issues in Logs UI. Corrected typos on Add Your Data page. Notes In partnership with our customers, the New Relic log team has been rapidly innovating our log management capabilities since the initial release in 2019. Our goal is to give you the best log experience to advance observability and provide measurable impact to your business. To stay up to date the most recent fixes and enhancements, subscribe to our Logs RSS feed. More to come soon!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.6194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "New public <em>APIs</em>",
        "body": " ingest Added support for headerless HTTP log ingest. This enables Logs customers to send <em>data</em> to New Relic <em>from</em> sources that do not permit the customization of HTTP request headers (for example, <em>Api</em>-Key or X-License-Key). This approach is most often used when forwarding logs <em>from</em> cloud-based"
      },
      "id": "61372ebb64441fb7e3424382"
    },
    {
      "sections": [
        "Amazon API Gateway monitoring integration",
        "Features",
        "Requirements",
        "Tip",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Inventory data",
        "Dimensions"
      ],
      "title": "Amazon API Gateway monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "a0d3ee22f75f187dbf4fbe512d1b018e11e5684d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration/",
      "published_at": "2021-10-18T13:07:57Z",
      "updated_at": "2021-03-11T10:43:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon API Gateway data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features Amazon's API Gateway is a fully managed service that allows you to create, publish, maintain, monitor, and secure APIs at any scale. With the New Relic API Gateway integration, you get more data about how your API layer is working behind the scenes. You'll receive metric data about the number of API calls, the requests served, the number of errors, latency counts, and more. You can monitor and alert on your API Gateway data directly from New Relic, and query data and create dashboards. Requirements API Gateway will not send \"Call count by resource\", \"4xx error by resource\" and \"5xx errors by resource\" metrics unless you have explicitly enabled detailed CloudWatch metrics. Tip Enabling these metrics may add additional charges to your Amazon CloudWatch account pricing. To enable CloudWatch metrics, use either of these options: Go to the AWS Management Console, select the Settings option for CloudWatch, then select the option to enable detailed CloudWatch metrics. Call the stage:update action of the Amazon API Gateway REST API to update the metricsEnabled property to true. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon API gateway integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the API Gateway integration links. You can query and explore your data using the ApiGatewaySample event type. For more on how to use your data, see Understand and use integration data. Metric data This New Relic infrastructure integration collects the following Amazon API Gateway data: Metric Description 4XXError The number of client-side errors captured 5XXError The number of server-side errors captured. CacheHitCount The number of requests served from the API cache. CacheMissCount The number of requests served from the back end when API caching is enabled. Count The number of calls to API methods. IntegrationLatency The time in milliseconds between when API Gateway relays a request to the back end and when it receives a response from the back end. Latency The time in milliseconds between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Inventory data Inventory data provides information about the service's state and configuration. API Gateway configuration options are reported as inventory data. For more about inventory data, see Understand and use data. Object Inventory data /aws/apigateway/api apiId apiName awsRegion /aws/apigateway/resource awsRegion methods resource resourceid /aws/apigateway/stage apiName awsRegion cacheClusterEnable cacheClusterSize cacheClusterStatus lastUpdatedDate stageName /aws/apigateway/stage/variables value /aws/apigateway/stage/settings CacheDataEncrypted CacheTtlInSeconds CachingEnabled DataTraceEnabled LoginLevel MetricsEnabled RequireAuthorizationForCacheControl UnauthorizedCacheControlHeaderStrategy ThrottlingBurstLimit ThrottlingRateLimit /aws/apigateway/stage/resource-with-metrics apiName awsRegion method resource stageName Dimensions You can use the dimensions in the following table to filter API Gateway metrics. Dimensions Description ApiName Filters API Gateway metrics for an API of the specified API name. ApiName, Method, Resource, Stage Filters API Gateway metrics for an API method of the specified API, stage, resource, and method. ApiName, Stage Filters API Gateway metrics for an API stage of the specified API and stage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.47906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "sections": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "body": ", and more. You can monitor and alert on your <em>API</em> <em>Gateway</em> <em>data</em> directly <em>from</em> New Relic, and query <em>data</em> and create dashboards. Requirements <em>API</em> <em>Gateway</em> will not send &quot;Call count by resource&quot;, &quot;4xx error by resource&quot; and &quot;5xx errors by resource&quot; metrics unless you have explicitly enabled detailed CloudWatch"
      },
      "id": "6043ee9964441fa2c3378eee"
    }
  ],
  "/docs/infrastructure/index": [
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.14577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 63.51976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em>",
        "body": "Before installing our <em>infrastructure</em> agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The <em>infrastructure</em> agent supports these processor architectures"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 49.638214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual install of the <em>infrastructure</em> agent for Windows",
        "sections": "Zip manual install of the <em>infrastructure</em> agent for Windows",
        "tags": "<em>Infrastructure</em>",
        "body": "Our custom installation process for the <em>infrastructure</em> agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition": [
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-10-18T19:02:14Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.37453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-10-18T19:03:03Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-10-18T19:02:13Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/verify-your-alerts-after-activating-remote-monitoring": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/",
      "sections": [
        "Drop data using NerdGraph",
        "Tip",
        "Requirements",
        "Create drop data rule",
        "Caution",
        "NRQL restrictions",
        "Example drop rules",
        "Drop two event types",
        "Drop events meeting certain criteria",
        "Drop sensitive attributes while maintaining the rest of the data",
        "Verify your drop rule works",
        "View rules",
        "Delete drop rules",
        "Audit drop rule history",
        "Cautions when dropping data",
        "Learn more"
      ],
      "published_at": "2021-10-19T03:57:25Z",
      "title": "Drop data using NerdGraph",
      "updated_at": "2021-10-19T03:57:25Z",
      "type": "docs",
      "external_id": "6d818aea12b567ec83c209fcc61237d79dd02450",
      "document_type": "page",
      "popularity": 1,
      "body": "You might find that you ingest data you don't need or want. You can drop some types of data, which enables you: To filter out unimportant low-value data To filter out potentially sensitive data If you choose to drop data, only new data will be affected. Existing data cannot be edited or deleted. Tip If you are sending data to New Relic using Prometheus remote write, you can also drop data by changing the remote_write section of your YAML config file. For more information, see Drop data using Prometheus remote write. Requirements You must have a user role with permissions for dropping data. Currently the following types of data can be targeted for data dropping: APM-reported events Browser-reported events Mobile-reported events Synthetics-reported events Custom events (like those generated by the APM agent APIs or the Event API) Log data Trace spans Default infrastructure monitoring events and infrastructure integrations events, with this exception: Downsampled SystemSample, ProcessSample, NetworkSample and StorageSample with time windows longer than 59 minutes can't be dropped. This data doesn't count towards your data ingest. Dimensional metrics, with these caveats: Billing impacts: for New Relic One pricing, dropped data is not billable. For original pricing, dropped data is billable. For metrics generated by the events-to-metrics service: drop rules won't work but these metrics can be stopped or attributes pruned by disabling or re-configuring the events-to-metric rule. Support for additional types are planned for the future. Create drop data rule Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, please review caution information below. To drop data, create a NerdGraph-format drop rule that includes: A NRQL string that specifies what data types to drop An action type specifying how to apply the NRQL string You can form and make the call in the NerdGraph explorer. There are two ways to drop data: Drop entire data types or a data subset (with optional filter). This uses the DROP_DATA action type and uses NRQL of the form: SELECT * FROM DATA_TYPE_1, DATA_TYPE_2 (WHERE OPTIONAL_FILTER) Copy For this type of drop rule, you cannot use anything other than * in the SELECT clause. Drop attributes from data types (with optional filter). This uses the DROP_ATTRIBUTES action type and uses NRQL of the form: SELECT dropAttr1, dropAttr2 FROM DATA_TYPE (WHERE OPTIONAL_FILTER) Copy For this type of drop rule, you must pass in a non-empty list of raw attributes names. NRQL restrictions Not all NRQL clauses make sense for generating drop rules. You can provide a WHERE clause to select data with specific attributes. Other features such as TIMESERIES, COMPARE WITH, FACET, and other clauses cannot be used. The two action types have these restrictions: DROP_DATA can use only SELECT *. DROP_ATTRIBUTES requires use of SELECT with \"raw\" attributes (attributes with no aggregator function applied). This also means you cannot use SELECT *. Additionally, there are some attributes that are integral to their data type and cannot be dropped (such as timestamp on event data). If you include them, registration will fail. Example drop rules Here are some example drop rules: Drop two event types Let's say you notice you have some event types being sent to New Relic that are not important to you. Also, stopping the source from sending those event types quickly is unrealistic, requiring changes to agents and/or API instrumentation. Using a drop rule is an easier way to accomplish the same goal. Here is an example NerdGraph call that drops two event types: Event1 and Event2. mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_DATA nrql: \"SELECT * FROM Event1, Event2\" description: \"Drops all data for Event1 and Event2.\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Drop events meeting certain criteria Let’s say you have a high volume custom event type that arrives from multiple sources. If you don't find all of that data important, you can use a drop rule. Here is an example of a drop rule that filters out events based on specific criteria. mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_DATA nrql: \"SELECT * FROM MyCustomEvent WHERE appName='LoadGeneratingApp' AND environment='development'\" description: \"Drops all data for MyCustomEvent that comes from the LoadGeneratingApp in the dev environment, because there is too much and we don’t look at it.\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Drop sensitive attributes while maintaining the rest of the data Let's say you noticed an event has attributes that contain Personally Identifiable Information (PII). You are working to update your services to stop sending the data, but until then, you need to cease storing further PII in New Relic. Although you could drop all of the data as it comes in the door with a DROP_DATA rule, the rest of the data still provides value. Therefore, you can register a drop rule to remove only the offending PII from your data: mutation { nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [ { action: DROP_ATTRIBUTES nrql: \"SELECT userEmail, userName FROM MyCustomEvent description: \"Removes the user name and email fields from MyCustomEvent\" } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy Verify your drop rule works After you create a drop rule, verify that it is working as expected. The rule should take effect quickly after a successful registration, so try running a TIMESERIES version of the query you registered to see that the data drops off. Drop rule type NRQL DROP_DATA Drop rule NRQL: SELECT * FROM MyEvent WHERE foo = bar Copy Validation NRQL: SELECT count(*) FROM MyEvent WHERE foo = bar TIMESERIES Copy This should drop to 0. To verify that it did not affect any thing else, invert the WHERE clause. DROP_ATTRIBUTES Drop rule NRQL: SELECT dropAttr1, dropAttr2 FROM MyEvent WHERE foo = bar Copy Validation NRQL: SELECT count(dropAttr1), count(dropAttr2) FROM MyEvent WHERE foo = bar TIMESERIES Copy Both lines should drop to 0. To verify that it did not affect events that contained these attributes and still should, invert the WHERE clause. View rules Here is an example NerdGraph call that returns the drop rules set on an account: { actor { account(id: YOUR_ACCOUNT_ID) { nrqlDropRules { list { rules { id nrql accountId action createdBy createdAt description } error { reason description } } } } } } Copy Delete drop rules Here is an example NerdGraph call deleting two specific drop rules: mutation { nrqlDropRulesDelete(accountId: YOUR_ACCOUNT_ID, ruleIds: [\"48\", \"98\"]) { successes { id nrql accountId action description } failures { error { reason description } submitted { ruleId accountId } } } } Copy Audit drop rule history To see who created and deleted drop rules, query your account audit logs. The list endpoint also includes the user ID of the person who created the rule. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic does not review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Rules you create, including all information in those rules, can be viewed and edited by any user with the relevant role-based access control permissions. Only new data will be dropped. Existing data cannot be edited or deleted. Learn more Recommendations for learning more: NerdGraph basics and terminology NRQL basics Browse the Explorers Hub for community discussions about NRQL drop rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.23804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Verify</em> <em>your</em> drop rule works",
        "body": " MyCustomEvent&quot; } ]) { successes { id } failures { submitted { nrql } error { reason description } } } } Copy <em>Verify</em> <em>your</em> drop rule works <em>After</em> you create a drop rule, <em>verify</em> that it is working as expected. The rule should take effect quickly <em>after</em> a successful registration, so try running a TIMESERIES version"
      },
      "id": "60a7c4ef64441f7607f263e2"
    },
    {
      "sections": [
        "Remote monitoring in on-host integrations",
        "Important",
        "Effects of activating remote_monitoring",
        "Alert verification",
        "New entity attributes",
        "Changes in recorded metrics",
        "Unrecorded attributes",
        "Updated hostname"
      ],
      "title": "Remote monitoring in on-host integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "Understand and use data"
      ],
      "external_id": "1cfea4c65b855ce9ac5078d2a36ba11b63a6101b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/understand-use-data/remote-monitoring-host-integrations/",
      "published_at": "2021-10-19T03:30:45Z",
      "updated_at": "2021-03-16T06:05:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "From a New Relic perspective, entity is a broad concept. An entity is anything New Relic can identify that has data you can monitor. Integrations can be configured to create their own entity, called a remote entity, by setting the remote_monitoring option to true. If set to false, an integration will be considered a local entity, and the data related to it will be attached to the host entity that the agent creates. Remote monitoring requires infrastructure agent version 1.2.25 or higher. For the Apache, Cassandra, MySQL, NGINX, and Redis integrations, remote monitoring (and multi-tenancy) is enabled by activating the configuration parameter remote_monitoring. Important If your Apache, Cassandra, MySQL, NGINX, or Redis service is located in the same host as the agent, when you activate remote monitoring the resulting entity will be considered as remote, regardless of its actual location. This may affect alerts, alter attributes, and have other effects, as explained here. Effects of activating remote_monitoring By enabling remote_monitoring, the integration becomes a different entity which is no longer attached to the infrastructure agent. As a result, the following items may be affected: Alert verification Enabling remote monitoring can affect your configured alerts in case they are using any of the values that are affected by this new feature. We strongly recommend checking your existing alerts to make sure they keep on working as expected. New entity attributes These attributes are modified in the resulting entity: Display name: New entity unique key (instead of using the display name) Entity GUID: New entity GUID Entity ID: New entity ID Entity key: New entity unique key (instead of using the display name) External key: Using integration entity name (instead of using the agent display) Changes in recorded metrics When remote monitoring is enabled, we will add the hostname and port values to all metrics. If the nricluster name or nriservice are defined in the integration configuration file, they will also be decorated. Unrecorded attributes Since the integration is now an independent entity which is not attached to the agent, the following agent attributes are not collected: agentName agentVersion coreCount criticalViolationCount fullHostname instanceType kernelVersion linuxDistribution entityType operatingSystem processorCount systemMemoryBytes warningViolationCount Your custom attributes Updated hostname For the ApacheSample, RedisSample, CassandraSample, and NginxSample integration metrics, we will use the integration configuration hostname instead of the short hostname from the agent. When the integration hostname is a loopback address, the agent will replace it in order to guarantee uniqueness.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.78477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "sections": "<em>Remote</em> <em>monitoring</em> in on-host integrations",
        "body": " be affected: <em>Alert</em> verification Enabling <em>remote</em> <em>monitoring</em> can affect <em>your</em> configured <em>alerts</em> in case they are using any of the values that are affected by this new feature. We strongly recommend checking <em>your</em> existing <em>alerts</em> to make sure they keep on working as expected. New entity attributes"
      },
      "id": "603ec000e7b9d216732a07ef"
    },
    {
      "sections": [
        "Aporia MLOps integration",
        "What is MLOps?",
        "The Aporia integration",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia"
      ],
      "title": "Aporia MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "Aporia integrations"
      ],
      "external_id": "0647ffc0aeb237f183c4c17f90ab41ab0b255090",
      "image": "https://docs.newrelic.com/static/2077501e83076cea955a8743815ab8e4/c1b63/aporia1.png",
      "url": "https://docs.newrelic.com/docs/integrations/mlops-integrations/aporia-mlops-integration/",
      "published_at": "2021-10-18T20:16:19Z",
      "updated_at": "2021-10-17T12:54:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "What is MLOps? MLOps stands for machine-learning operations. As more companies invest in artificial intelligence and machine learning, there's a gap in understanding between the data science teams developing machine-learning models and the DevOps teams operating the applications that power those models. MLOps provides a tool for monitoring and observing the performance and effectiveness of machine-learning models in a production environment. This increases the possibilities for collaboration between data science and DevOps teams, feeding into a continuous process of development, testing, and operational monitoring. The Aporia integration Aporia is a fast, easy, and secure way for data science teams to monitor their machine learning models in production. With Aporia, teams can build their own customizable monitors in minutes to receive live alerts for early detection of issues like data drift, unexpected bias, data integrity issues, and performance degradation. Aporia also has an investigation toolbox to enable further investigation and root cause analysis. Learn more about Aporia. Aporia now offers an integration with New Relic to provide full model management of the MLOps infrastructure, with customized dashboards within New Relic that show inferences investigation. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Login into Aporia’s console: On the navbar on the left, click on Integrations and choose New Relic. Login into your New Relic account: Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia: In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API key: Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You need to create a new API key or use an existing one. Copy and paste the token in Aporia: Copy the token by clicking on the Copy icon next to the API Key. On Aporia’s dashboard, under the New Relic Integration screen, paste the token under New Relic insert token and click Save. Verify the tokens: In the Aporia dashboard, click on the Verify tokens button to verify both tokens are working properly. Green check marks or Red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using dashboards with automated charts created by Aporia. Go to the integration dashboard: Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard. Aporia’s dashboard contains 6 charts: The Most active models chart displays the different models which reported predictions in the selected timeframe. The Most active model versions chart displays the different versions which reported predictions in the selected timeframe. The Model inferences graph displays the number of unique predictions reported for each model and version. The Average numeric inferences chart displays the average value numeric predictions reported for each model and version. The Numeric inferences heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. Filter data: Click on the … button and click on Edit. On the right navbar, under User as filter, enable Filter the current dashboard and click Save. Setup alert notifications: Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents: In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.59279,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Monitor</em> <em>your</em> machine learning models with Aporia",
        "body": ", and operational <em>monitoring</em>. The Aporia integration Aporia is a fast, easy, and secure way for data science teams to <em>monitor</em> their machine learning models in production. With Aporia, teams can build their own customizable monitors in minutes to receive live <em>alerts</em> for early detection of issues like data"
      },
      "id": "61663eaa28ccbc951900119c"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring": [
    {
      "sections": [
        "Compatibility and requirements for the Python agent",
        "Basic requirements",
        "Python package instrumentation",
        "Python version support",
        "Support for new Python releases",
        "End of support for Python releases reaching EOL",
        "Connect the agent to other Full-Stack Observability capabilities"
      ],
      "title": "Compatibility and requirements for the Python agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Python agent",
        "Getting started"
      ],
      "external_id": "bac256a07ebdd3c81f4f7eefdee029990831a57e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/python-agent/getting-started/compatibility-requirements-python-agent/",
      "published_at": "2021-10-18T13:35:40Z",
      "updated_at": "2021-10-18T13:35:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Python agent, make sure your system meets these requirements. Basic requirements The Python agent supports many of the most common Python web frameworks. Additional configuration may be required depending on your specific hosting mechanism, hosting service, web framework, or back-end services. If you don't have one already, create a New Relic account. It's free, forever. Resource Requirements Operating systems UNIX-like operating systems including Linux, Solaris, FreeBSD, and macOS. The Python agent does not support Windows environments. Python Python (CPython/PyPy) versions supported: 2.7, 3.6, 3.7, 3.8, 3.9, and 3.10. Recommendation: Use Python version 3.6 or higher with our agent. Python versions 2.6 and 3.3 are supported only by Python agent versions 3.4.0.95 or lower. Python version 3.4 is supported only by Python agent versions 4.20.0.120 or lower. Python version 3.5 is supported only by Python agent versions 5.24.0.153 or lower. Python versions 2.7 and 3.6 follow our end of life (EOL) support requirements. Supported web frameworks Supported web frameworks include: Aiohttp Bottle CherryPy Django Falcon FastAPI Flask GraphQL gRPC Pylons Pyramid Sanic Starlette Tornado 6 Web2Py Unsupported frameworks Some WSGI servers, frameworks, and apps have special requirements. Although a specific Python WSGI web framework may not be supported, you can still use the agent. For unsupported frameworks, a breakout of time spent in key parts of the framework will not appear in web transaction performance breakdowns and transaction traces. In addition, the agent will not be able to meaningfully group any web transactions handled by specific handlers in your code that you use to make them more useful and targeted. In these situations you can use the Python agent API to name web transactions or add custom instrumentation. Hosting Web hosting mechanisms compliant with WSGI 1.0 (PEP 333). For example, you can install the Python agent in a Google App Engine flexible environment. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Other monitoring software If your application uses other monitoring software besides ours, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Python package instrumentation The agent also provides instrumentation for a range of other Python packages and modules. Instrumentation includes database queries, memcache requests, external service requests, instance-level details, and more. The results will appear automatically in APM's user interface within web transaction performance breakdowns and transaction traces for slow transactions. Python version support The agent in general will support all released and active Python branches. However, to keep up with upcoming changes, the agent will also follow this Python version support schedule. The version support policy does not replace the general New Relic agent and plugin end-of-life (EOL) policy. Support for new Python releases The following are proposed time ranges. The actual release date may vary. Python version Active long term support (LTS) start date Initial release date of Python agent with support 3.10 October 04, 2021 October 12, 2021 3.11 October 03, 2022 November 2022 End of support for Python releases reaching EOL The following are proposed time ranges. The actual release date may vary. Python version End of life (EOL) date Initial release date of Python agent dropping support 3.6 December 2021 Python agent versions released after March 2022 will not support Python 3.6. For more information, see our Python agent release notes. 2.7 January 1, 2020 TBD Connect the agent to other Full-Stack Observability capabilities The Python agent integrates with other capabilities to give you end-to-end visibility: Product Integration Browser monitoring The Python agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Python agent. Infrastructure monitoring When you install the Infrastructure monitoring and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure monitoring UI. For more information, see APM data in Infrastructure. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.26302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see Browser <em>monitoring</em> and the Python agent. <em>Infrastructure</em> <em>monitoring</em> When you install the <em>Infrastructure</em> <em>monitoring</em> and APM agents on the same host, they automatically"
      },
      "id": "6044108b64441fb65f378efc"
    },
    {
      "sections": [
        "Compatibility and requirements for the Node.js agent",
        "Node.js version support",
        "Tip",
        "Support for new Node.js releases",
        "End of support for Node.js releases reaching EOL",
        "Node.js 12 errors",
        "Supported Node.js frameworks",
        "EOL NOTICE",
        "Operating systems",
        "Datastores",
        "Instance details",
        "Messages queues",
        "Hosting services",
        "Process managers",
        "Security requirements",
        "Connect the agent to other New Relic features"
      ],
      "title": "Compatibility and requirements for the Node.js agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Getting started"
      ],
      "external_id": "dd144d7ffce53c47f9dd6d872f61905157023f6f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/nodejs-agent/getting-started/compatibility-requirements-nodejs-agent/",
      "published_at": "2021-10-19T03:58:30Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Node.js agent is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you install the Node.js agent, make sure your application meets the following system requirements. If you haven't already, create a New Relic account. It's free, forever. Node.js version support Tip For best performance, use the latest active long term support (LTS) version of Node.js. Support for new Node.js releases We will support the latest even versions of Node.js releases by the beginning of the following active long term support schedule. The version support policy does not replace the general agent and plugin end-of-life (EOL) policy. The following are proposed time ranges. The actual release date may vary. Node.js version Active long term support (LTS) start date Initial release date of Node.js agent with support 18 October 2022 April-October 2022 16 October 2021 July 26, 2021 with Node.js agent v8.0.0 End of support for Node.js releases reaching EOL When support for a new long term support agent version is made available, support for the Node.js agent version that reaches end-of-life during the same time period will simultaneously drop. The following are proposed time ranges. The actual release date may vary. Node.js version End of life (EOL) date Initial release date of Node.js agent dropping support 12 April 2022 April-October 2022 10 April 2021 As of July 26, 2021, we have discontinued support for Node.js 10 with v8 of the Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Node.js 12 errors For Node.js 12, the following change affects the Node.js agent: Errors resulting in unhandled rejections are not scoped to the transaction that was active when the rejected promise was created. This is because the promise responsible for triggering the init async hook is no longer passed through on the promise wrap instance. This breaks the linkage that associates a given promise rejection with the transaction it was scheduled in. Supported Node.js frameworks Express 4.6.0 or higher Restify Connect Hapi Koa 2.0.0 or higher (external module loaded with the agent) If you are using a supported framework with default routers, the Node.js agent can read these frameworks' route names as is. However, if you want more specific names than are provided by your framework, you may want to use one or more of the tools New Relic provides with the Node.js transaction naming API. EOL NOTICE We're discontinuing support for several capabilities in November 2021. This includes the Oracle Driver Package and Hapi versions prior to Hapi 19.2 for our Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Operating systems Linux SmartOS macOS 10.7 and higher Windows Server 2008 and higher Datastores The Node.js agent monitors the performance of Node.js application calls to these datastores: Cassandra Memcached MongoDB MySQL (via mysql and mysql2 packages) Redis Postgres (including the native and pure JavaScript packages) Instance details We collect instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your agent version. New Relic's Node.js agent version 1.31.0 or higher supports the following: Database npm module name Minimum module version Minimum agent version PostgreSQL pg 4.0.0 1.31.0 Redis redis 2.0.0 1.31.0 MongoDB mongodb 2.1.0 1.32.0 MySQL mysql 2.4.1 1.32.0 Memcached memcached 1.0.0 1.33.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Messages queues Message queue instrumentation is only available with the New Relic Node.js agent v2 or higher. Currently supported message queue instrumentation: amqplib For other message queue libraries, use custom instrumentation. Hosting services Google App Engine (GAE) flexible environment AWS EC2 Microsoft Azure Heroku Process managers In general, process managers that handle starting, stopping, and restarting of Node.js (like Forever) should be compatible with the Node.js agent. If you are using PM2, the minimum supported version of PM2 is 2.0. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Connect the agent to other New Relic features The Node.js agent integrates with other features to give you observability across your entire stack: Product Integration Browser monitoring The Node.js agent can add the benefits of browser monitoring when you enable auto-instrumentation. After enabling browser monitoring injection, simply follow our guide to installing browser monitoring with the Node.js agent. Once you've completed these steps, you can view your browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see browser monitoring and the Node.js agent. Infrastructure monitoring When you install the infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. New Relic dashboards The Node.js agent sends default events and attributes for NRQL queries. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.28702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Getting</em> <em>started</em>",
        "body": ". <em>Infrastructure</em> <em>monitoring</em> When you install the <em>infrastructure</em> and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your <em>infrastructure</em> hosts by APM app in the <em>Infrastructure</em> UI. For more information, see APM data"
      },
      "id": "6043d8dae7b9d2d4415799df"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.20943,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> UI",
        "body": ", or modified. Services: Can be <em>started</em>, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. The Events page includes a heatmap, which provides a snapshot of the events"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/infrastructure-security/infrastructure-security": [
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.99405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> UI",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Compatibility and requirements for the Python agent",
        "Basic requirements",
        "Python package instrumentation",
        "Python version support",
        "Support for new Python releases",
        "End of support for Python releases reaching EOL",
        "Connect the agent to other Full-Stack Observability capabilities"
      ],
      "title": "Compatibility and requirements for the Python agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Python agent",
        "Getting started"
      ],
      "external_id": "bac256a07ebdd3c81f4f7eefdee029990831a57e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/python-agent/getting-started/compatibility-requirements-python-agent/",
      "published_at": "2021-10-18T13:35:40Z",
      "updated_at": "2021-10-18T13:35:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Python agent, make sure your system meets these requirements. Basic requirements The Python agent supports many of the most common Python web frameworks. Additional configuration may be required depending on your specific hosting mechanism, hosting service, web framework, or back-end services. If you don't have one already, create a New Relic account. It's free, forever. Resource Requirements Operating systems UNIX-like operating systems including Linux, Solaris, FreeBSD, and macOS. The Python agent does not support Windows environments. Python Python (CPython/PyPy) versions supported: 2.7, 3.6, 3.7, 3.8, 3.9, and 3.10. Recommendation: Use Python version 3.6 or higher with our agent. Python versions 2.6 and 3.3 are supported only by Python agent versions 3.4.0.95 or lower. Python version 3.4 is supported only by Python agent versions 4.20.0.120 or lower. Python version 3.5 is supported only by Python agent versions 5.24.0.153 or lower. Python versions 2.7 and 3.6 follow our end of life (EOL) support requirements. Supported web frameworks Supported web frameworks include: Aiohttp Bottle CherryPy Django Falcon FastAPI Flask GraphQL gRPC Pylons Pyramid Sanic Starlette Tornado 6 Web2Py Unsupported frameworks Some WSGI servers, frameworks, and apps have special requirements. Although a specific Python WSGI web framework may not be supported, you can still use the agent. For unsupported frameworks, a breakout of time spent in key parts of the framework will not appear in web transaction performance breakdowns and transaction traces. In addition, the agent will not be able to meaningfully group any web transactions handled by specific handlers in your code that you use to make them more useful and targeted. In these situations you can use the Python agent API to name web transactions or add custom instrumentation. Hosting Web hosting mechanisms compliant with WSGI 1.0 (PEP 333). For example, you can install the Python agent in a Google App Engine flexible environment. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Other monitoring software If your application uses other monitoring software besides ours, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Python package instrumentation The agent also provides instrumentation for a range of other Python packages and modules. Instrumentation includes database queries, memcache requests, external service requests, instance-level details, and more. The results will appear automatically in APM's user interface within web transaction performance breakdowns and transaction traces for slow transactions. Python version support The agent in general will support all released and active Python branches. However, to keep up with upcoming changes, the agent will also follow this Python version support schedule. The version support policy does not replace the general New Relic agent and plugin end-of-life (EOL) policy. Support for new Python releases The following are proposed time ranges. The actual release date may vary. Python version Active long term support (LTS) start date Initial release date of Python agent with support 3.10 October 04, 2021 October 12, 2021 3.11 October 03, 2022 November 2022 End of support for Python releases reaching EOL The following are proposed time ranges. The actual release date may vary. Python version End of life (EOL) date Initial release date of Python agent dropping support 3.6 December 2021 Python agent versions released after March 2022 will not support Python 3.6. For more information, see our Python agent release notes. 2.7 January 1, 2020 TBD Connect the agent to other Full-Stack Observability capabilities The Python agent integrates with other capabilities to give you end-to-end visibility: Product Integration Browser monitoring The Python agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Python agent. Infrastructure monitoring When you install the Infrastructure monitoring and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure monitoring UI. For more information, see APM data in Infrastructure. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.82797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements for the Python agent",
        "sections": "Compatibility <em>and</em> requirements for the Python agent",
        "body": " page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see Browser <em>monitoring</em> and the Python agent. <em>Infrastructure</em> <em>monitoring</em> When you install the <em>Infrastructure</em> <em>monitoring</em> and APM agents on the same host, they automatically"
      },
      "id": "6044108b64441fb65f378efc"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.45256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": ". Generate some traffic for your app. Wait a few minutes, and then check for APM data in <em>infrastructure</em> <em>monitoring</em>. Make sure the hostnames are the same in APM and <em>Infrastructure</em>. If the hostnames are different in APM and <em>infrastructure</em> <em>monitoring</em>, New Relic cannot integrate the data. One common cause"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29039,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-10-18T19:06:09Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.8371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-10-18T18:52:42Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and won’t be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.0297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.0297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure": [
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-10-18T19:01:11Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-10-18T07:30:06Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.47385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page": [
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-10-18T19:01:11Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.72668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-18T07:29:23Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.53793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.49628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Configuration</em> <em>management</em> <em>tools</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " <em>management</em> <em>tools</em> The <em>infrastructure</em> <em>agent</em> can be deployed programmatically using several <em>config</em> <em>management</em> and deploy <em>tools</em>: Ansible Chef Elastic Beanstalk Puppet"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.33847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-18T07:29:23Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.53793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.49628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Configuration</em> <em>management</em> <em>tools</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " <em>management</em> <em>tools</em> The <em>infrastructure</em> <em>agent</em> can be deployed programmatically using several <em>config</em> <em>management</em> and deploy <em>tools</em>: Ansible Chef Elastic Beanstalk Puppet"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-10-18T14:07:37Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.49603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Configuration</em> <em>management</em> <em>tools</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " <em>management</em> <em>tools</em> The <em>infrastructure</em> <em>agent</em> can be deployed programmatically using several <em>config</em> <em>management</em> and deploy <em>tools</em>: Ansible Chef Elastic Beanstalk Puppet"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-10-18T14:07:37Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.33847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef": [
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-10-18T07:29:23Z",
      "updated_at": "2021-07-27T09:36:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.53793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.49603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Configuration</em> <em>management</em> <em>tools</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " <em>management</em> <em>tools</em> The <em>infrastructure</em> <em>agent</em> can be deployed programmatically using several <em>config</em> <em>management</em> and deploy <em>tools</em>: Ansible Chef Elastic Beanstalk Puppet"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-10-18T14:07:37Z",
      "updated_at": "2021-07-02T00:51:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.8174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/config-file-template-newrelic-infrayml": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.12738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.7672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " with the following structure: <em>Install</em> the service script. Optionally, you can: Change the location of the <em>configuration</em> file. Configure the plugin directory. Configure the <em>agent</em> directory. Configure the log file. Important As of version 1.4.0, the <em>infrastructure</em> <em>agent</em> package includes the additional"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-19T05:56:32Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.98592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.12738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.7672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " with the following structure: <em>Install</em> the service script. Optionally, you can: Change the location of the <em>configuration</em> file. Configure the plugin directory. Configure the <em>agent</em> directory. Configure the log file. Important As of version 1.4.0, the <em>infrastructure</em> <em>agent</em> package includes the additional"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-10-19T05:56:32Z",
      "updated_at": "2021-09-20T19:24:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user:access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.98592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.12714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.76712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " with the following structure: <em>Install</em> the service script. Optionally, you can: Change the location of the <em>configuration</em> file. Configure the plugin directory. Configure the <em>agent</em> directory. Configure the log file. Important As of version 1.4.0, the <em>infrastructure</em> <em>agent</em> package includes the additional"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.23131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can <em>install</em> the <em>agent</em> manually. Before installing <em>infrastructure</em>, be sure to: Review the requirements. Have a valid New Relic license key. To <em>install</em> <em>infrastructure</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 432.01904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.2073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " with the following structure: <em>Install</em> the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the <em>agent</em> directory. Configure the log file. Important As of version 1.4.0, the <em>infrastructure</em> <em>agent</em> package includes the additional"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Compatibility and requirements for the Node.js agent",
        "Node.js version support",
        "Tip",
        "Support for new Node.js releases",
        "End of support for Node.js releases reaching EOL",
        "Node.js 12 errors",
        "Supported Node.js frameworks",
        "EOL NOTICE",
        "Operating systems",
        "Datastores",
        "Instance details",
        "Messages queues",
        "Hosting services",
        "Process managers",
        "Security requirements",
        "Connect the agent to other New Relic features"
      ],
      "title": "Compatibility and requirements for the Node.js agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Getting started"
      ],
      "external_id": "dd144d7ffce53c47f9dd6d872f61905157023f6f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/nodejs-agent/getting-started/compatibility-requirements-nodejs-agent/",
      "published_at": "2021-10-19T03:58:30Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Node.js agent is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you install the Node.js agent, make sure your application meets the following system requirements. If you haven't already, create a New Relic account. It's free, forever. Node.js version support Tip For best performance, use the latest active long term support (LTS) version of Node.js. Support for new Node.js releases We will support the latest even versions of Node.js releases by the beginning of the following active long term support schedule. The version support policy does not replace the general agent and plugin end-of-life (EOL) policy. The following are proposed time ranges. The actual release date may vary. Node.js version Active long term support (LTS) start date Initial release date of Node.js agent with support 18 October 2022 April-October 2022 16 October 2021 July 26, 2021 with Node.js agent v8.0.0 End of support for Node.js releases reaching EOL When support for a new long term support agent version is made available, support for the Node.js agent version that reaches end-of-life during the same time period will simultaneously drop. The following are proposed time ranges. The actual release date may vary. Node.js version End of life (EOL) date Initial release date of Node.js agent dropping support 12 April 2022 April-October 2022 10 April 2021 As of July 26, 2021, we have discontinued support for Node.js 10 with v8 of the Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Node.js 12 errors For Node.js 12, the following change affects the Node.js agent: Errors resulting in unhandled rejections are not scoped to the transaction that was active when the rejected promise was created. This is because the promise responsible for triggering the init async hook is no longer passed through on the promise wrap instance. This breaks the linkage that associates a given promise rejection with the transaction it was scheduled in. Supported Node.js frameworks Express 4.6.0 or higher Restify Connect Hapi Koa 2.0.0 or higher (external module loaded with the agent) If you are using a supported framework with default routers, the Node.js agent can read these frameworks' route names as is. However, if you want more specific names than are provided by your framework, you may want to use one or more of the tools New Relic provides with the Node.js transaction naming API. EOL NOTICE We're discontinuing support for several capabilities in November 2021. This includes the Oracle Driver Package and Hapi versions prior to Hapi 19.2 for our Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Operating systems Linux SmartOS macOS 10.7 and higher Windows Server 2008 and higher Datastores The Node.js agent monitors the performance of Node.js application calls to these datastores: Cassandra Memcached MongoDB MySQL (via mysql and mysql2 packages) Redis Postgres (including the native and pure JavaScript packages) Instance details We collect instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your agent version. New Relic's Node.js agent version 1.31.0 or higher supports the following: Database npm module name Minimum module version Minimum agent version PostgreSQL pg 4.0.0 1.31.0 Redis redis 2.0.0 1.31.0 MongoDB mongodb 2.1.0 1.32.0 MySQL mysql 2.4.1 1.32.0 Memcached memcached 1.0.0 1.33.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Messages queues Message queue instrumentation is only available with the New Relic Node.js agent v2 or higher. Currently supported message queue instrumentation: amqplib For other message queue libraries, use custom instrumentation. Hosting services Google App Engine (GAE) flexible environment AWS EC2 Microsoft Azure Heroku Process managers In general, process managers that handle starting, stopping, and restarting of Node.js (like Forever) should be compatible with the Node.js agent. If you are using PM2, the minimum supported version of PM2 is 2.0. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Connect the agent to other New Relic features The Node.js agent integrates with other features to give you observability across your entire stack: Product Integration Browser monitoring The Node.js agent can add the benefits of browser monitoring when you enable auto-instrumentation. After enabling browser monitoring injection, simply follow our guide to installing browser monitoring with the Node.js agent. Once you've completed these steps, you can view your browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see browser monitoring and the Node.js agent. Infrastructure monitoring When you install the infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. New Relic dashboards The Node.js agent sends default events and attributes for NRQL queries. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.87704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>the</em> Node.js <em>agent</em>",
        "sections": "Compatibility and requirements for <em>the</em> Node.js <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Our Node.js <em>agent</em> is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you <em>install</em> the Node.js <em>agent</em>, make sure your application meets the following system requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. Node.js"
      },
      "id": "6043d8dae7b9d2d4415799df"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent": [
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.2073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " with the following structure: <em>Install</em> the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the <em>agent</em> directory. Configure the log file. Important As of version 1.4.0, the <em>infrastructure</em> <em>agent</em> package includes the additional"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure agent",
        "Quick start: Use our guided install",
        "Important",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "One agent, many capabilities",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-10-19T04:54:18Z",
      "updated_at": "2021-09-02T09:05:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from infrastructure integrations to New Relic, as well as log data for log analytics. The infrastructure monitoring agent can currently run on many Linux distributions, Windows, and macOS. There are multiple ways to install and deploy the agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. Ready to get started? Click one of these button to try it out. Guided install EU Guided install The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. For more information on where you can run the agent, check the compatibility and requirements page. Important If you install the agent using the New Relic One UI, the Infrastructure status API is enabled by default. Install the infrastructure monitoring agent Linux If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually, see our tutorial. Windows Server and 10 If you don't have a New Relic account yet, the guided install doesn't work, or prefer to follow the procedure manually using our MSI installer, see our tutorial. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Infrastructre can also be deployed in macOS. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, for Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.5145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " distributions, Windows, and macOS. There are multiple ways to <em>install</em> and deploy the <em>agent</em>, depending on your setup and needs. This document describes how the <em>infrastructure</em> monitoring <em>agent</em> works and how to <em>install</em> it. Quick <em>start</em>: Use our guided <em>install</em> The quickest way to <em>get</em> <em>started</em> with our"
      },
      "id": "603e79bd64441f99814e8888"
    },
    {
      "sections": [
        "Compatibility and requirements for the Node.js agent",
        "Node.js version support",
        "Tip",
        "Support for new Node.js releases",
        "End of support for Node.js releases reaching EOL",
        "Node.js 12 errors",
        "Supported Node.js frameworks",
        "EOL NOTICE",
        "Operating systems",
        "Datastores",
        "Instance details",
        "Messages queues",
        "Hosting services",
        "Process managers",
        "Security requirements",
        "Connect the agent to other New Relic features"
      ],
      "title": "Compatibility and requirements for the Node.js agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Nodejs agent",
        "Getting started"
      ],
      "external_id": "dd144d7ffce53c47f9dd6d872f61905157023f6f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/nodejs-agent/getting-started/compatibility-requirements-nodejs-agent/",
      "published_at": "2021-10-19T03:58:30Z",
      "updated_at": "2021-10-19T03:58:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Node.js agent is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you install the Node.js agent, make sure your application meets the following system requirements. If you haven't already, create a New Relic account. It's free, forever. Node.js version support Tip For best performance, use the latest active long term support (LTS) version of Node.js. Support for new Node.js releases We will support the latest even versions of Node.js releases by the beginning of the following active long term support schedule. The version support policy does not replace the general agent and plugin end-of-life (EOL) policy. The following are proposed time ranges. The actual release date may vary. Node.js version Active long term support (LTS) start date Initial release date of Node.js agent with support 18 October 2022 April-October 2022 16 October 2021 July 26, 2021 with Node.js agent v8.0.0 End of support for Node.js releases reaching EOL When support for a new long term support agent version is made available, support for the Node.js agent version that reaches end-of-life during the same time period will simultaneously drop. The following are proposed time ranges. The actual release date may vary. Node.js version End of life (EOL) date Initial release date of Node.js agent dropping support 12 April 2022 April-October 2022 10 April 2021 As of July 26, 2021, we have discontinued support for Node.js 10 with v8 of the Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Node.js 12 errors For Node.js 12, the following change affects the Node.js agent: Errors resulting in unhandled rejections are not scoped to the transaction that was active when the rejected promise was created. This is because the promise responsible for triggering the init async hook is no longer passed through on the promise wrap instance. This breaks the linkage that associates a given promise rejection with the transaction it was scheduled in. Supported Node.js frameworks Express 4.6.0 or higher Restify Connect Hapi Koa 2.0.0 or higher (external module loaded with the agent) If you are using a supported framework with default routers, the Node.js agent can read these frameworks' route names as is. However, if you want more specific names than are provided by your framework, you may want to use one or more of the tools New Relic provides with the Node.js transaction naming API. EOL NOTICE We're discontinuing support for several capabilities in November 2021. This includes the Oracle Driver Package and Hapi versions prior to Hapi 19.2 for our Node.js agent. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Operating systems Linux SmartOS macOS 10.7 and higher Windows Server 2008 and higher Datastores The Node.js agent monitors the performance of Node.js application calls to these datastores: Cassandra Memcached MongoDB MySQL (via mysql and mysql2 packages) Redis Postgres (including the native and pure JavaScript packages) Instance details We collect instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your agent version. New Relic's Node.js agent version 1.31.0 or higher supports the following: Database npm module name Minimum module version Minimum agent version PostgreSQL pg 4.0.0 1.31.0 Redis redis 2.0.0 1.31.0 MongoDB mongodb 2.1.0 1.32.0 MySQL mysql 2.4.1 1.32.0 Memcached memcached 1.0.0 1.33.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Messages queues Message queue instrumentation is only available with the New Relic Node.js agent v2 or higher. Currently supported message queue instrumentation: amqplib For other message queue libraries, use custom instrumentation. Hosting services Google App Engine (GAE) flexible environment AWS EC2 Microsoft Azure Heroku Process managers In general, process managers that handle starting, stopping, and restarting of Node.js (like Forever) should be compatible with the Node.js agent. If you are using PM2, the minimum supported version of PM2 is 2.0. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Connect the agent to other New Relic features The Node.js agent integrates with other features to give you observability across your entire stack: Product Integration Browser monitoring The Node.js agent can add the benefits of browser monitoring when you enable auto-instrumentation. After enabling browser monitoring injection, simply follow our guide to installing browser monitoring with the Node.js agent. Once you've completed these steps, you can view your browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see browser monitoring and the Node.js agent. Infrastructure monitoring When you install the infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. New Relic dashboards The Node.js agent sends default events and attributes for NRQL queries. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from synthetic monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.87704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>the</em> Node.js <em>agent</em>",
        "sections": "Compatibility and requirements for <em>the</em> Node.js <em>agent</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Our Node.js <em>agent</em> is publicly available on the Node Package Manager (npm) repository as well as on GitHub. Before you <em>install</em> the Node.js <em>agent</em>, make sure your application meets the following system requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. Node.js"
      },
      "id": "6043d8dae7b9d2d4415799df"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/azure-extensions-infrastructure": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.76303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.31482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.76303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.31482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-18T07:30:41Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.91971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    },
    {
      "sections": [
        "Docker instrumentation for infrastructure monitoring",
        "Requirements",
        "Enable Docker container monitoring",
        "View your Docker data",
        "Docker attributes",
        "Set alert conditions"
      ],
      "title": "Docker instrumentation for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "7d6febf75c3e6b5a67fdda3226d31132cfc81b43",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/",
      "published_at": "2021-10-18T07:30:41Z",
      "updated_at": "2021-07-27T11:56:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure agent automatically monitors your Docker containers. With Docker monitoring you can: Group containers by tags, attributes, and other metadata. Search for containers relevant to your monitoring scenario. Link to related entities that may be affected by issues with the container. Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic's infrastructure agent: Infrastructure agent 1.8.32 or higher running on Linux If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable Docker container monitoring If you meet the requirements and have installed the correct infrastructure monitoring agent, there are no additional steps to enable Docker monitoring. If Docker is running, data will automatically be reported. You can also use a Docker image containing the infrastructure monitoring agent. For more information, see Docker container for infrastructure monitoring. View your Docker data To view your Docker data in the New Relic UI, use either of these options: Go to one.newrelic.com > Infrastructure > Hosts > Containers. OR Go to one.newrelic.com > Infrastructure > Third-party services, and select Docker-related links. For more information, see Query your data. Docker attributes Docker attributes (metrics and metadata) are attached to the ContainerSample event. Here's an example of a query to find out how many containers are associated with each Docker image: SELECT uniqueCount(containerId) FROM ContainerSample FACET imageName SINCE 1 HOUR AGO TIMESERIES Copy To see all ContainerSample attributes, use our data dictionary. Attributes include: General metadata (like containerId, name, and image) CPU metrics (like cpuUsedCores, cpuPercent, and cpuThrottleTimeMs) Memory metrics (like memoryUsageBytes, memoryCacheBytes, and memoryResidentSizeBytes) Network metrics (like networkRxBytes, networkRxDropped, and networkTxBytes) Docker metrics are also attached to the ProcessSample event. The reported data does not include information related to the container orchestrator (for example, ECS or Kubernetes). To monitor those, you can add the orchestrator's cluster and task names as labels. Set alert conditions To create Docker-related alert conditions, use either of these options: Go to one.newrelic.com > Alerts & AI. OR Go to one.newrelic.com > Infrastructure > Settings > Alerts. Create a new alert condition. For the condition type, select Container metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.91971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "sections": "Docker instrumentation for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Set Docker-related alert conditions. Requirements Requirement details for automatic Docker container monitoring for New Relic&#x27;s <em>infrastructure</em> <em>agent</em>: <em>Infrastructure</em> <em>agent</em> 1.8.32 or higher running on <em>Linux</em> If using CentOS, you must have CentOS version 6.0 or higher Docker version 1.12 or higher Enable"
      },
      "id": "603e9f3ee7b9d2d57c2a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.76297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.76297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Quick start",
        "Tip",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL & Oracle Linux",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-09-27T15:22:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. No matter which installation option you choose, make sure you've created a free New Relic account (No credit card required). Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Step-by-step instructions If guided install doesn't work, you can install the agent manually. Before installing infrastructure, be sure to: Review the requirements. Have a valid New Relic license key. To install infrastructure in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 11 (\"Bullseye\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bullseye main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20.10 (\"Groovy\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt groovy main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 21.04 (\"Hirsute Hippo\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt hirsute main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/amazonlinux/2/aarch64/newrelic-infra.repo Copy CentOS / RHEL & Oracle Linux CentOS, RHEL, Oracle Linux 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS RHEL, Oracle Linux 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS, RHEL, Oracle Linux 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy SLES 12.5 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/x86_64/newrelic-infra.repo Copy SLES 12.5 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.5/aarch64/newrelic-infra.repo Copy SLES 15.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/x86_64/newrelic-infra.repo Copy SLES 15.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.1/aarch64/newrelic-infra.repo Copy SLES 15.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/x86_64/newrelic-infra.repo Copy SLES 15.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.2/aarch64/newrelic-infra.repo Copy SLES 15.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/x86_64/newrelic-infra.repo Copy SLES 15.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/15.3/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.76294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. No matter which <em>installation</em> option you choose, make sure you&#x27;ve created a free New Relic account"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Operating system Supported by the <em>infrastructure</em> <em>agent</em> Amazon <em>Linux</em> 2 All versions CentOS Version 7 or higher Debian Version 8 (&quot;Jessie&quot;) or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise <em>Linux</em> (RHEL) Version 7 or higher Oracle <em>Linux</em> Version 7 or higher SUSE"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Docker container for infrastructure monitoring",
        "What you need",
        "Custom setup (recommended)",
        "Docker CLI",
        "Docker Compose",
        "Basic setup",
        "Required container privileges",
        "Next steps after install",
        "Inventory collected",
        "Container data",
        "Containerized agent image",
        "Check the source code"
      ],
      "title": "Docker container for infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "022f4fba474d662414d9542a107d4d8a30d24895",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-08-02T23:06:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure monitoring agent for Linux supports Docker environments by default. If you're running a container OS or have restrictions that require deploying the agent as a container, you can run a containerized version of our infrastructure monitoring agent. This can monitor metrics for the container itself, as well as the underlying host. Using the custom (recommended) or basic setup allows the infrastructure agent to run inside a container environment. A host can only run one instance of the agent at a time, whether that's the containerized agent or the non-containerized version. What you need The containerized version of the infrastructure agent requires Docker 1.12 or higher. The container must run any of the Linux distributions and versions supported by our agent. The container image is available and supported on AMD64 and ARM64 architectures. The log forwarder is not included with the containerized agent. We recommend installing the agent on the underlying host which provides all capabilities. Custom setup (recommended) The following are basic instructions for creating a custom Docker image on Linux. This allows you to deploy the infrastructure agent as a container that can monitor its underlying host. Recommendation: Extend the newrelic/infrastructure image, and use your own newrelic-infra.yml agent config file. Once your image is built, you can easily spin up a container without having to provide more launch time configurations. Do not provide secrets using environment variables with Docker. Docker CLI Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. license_key: YOUR_LICENSE_KEY Copy Create the Dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Build and tag your image: docker build -t YOUR_IMAGE_NAME . Copy Run the container from the image you built with the required required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ YOUR_IMAGE_NAME Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create a folder to store the configuration files: mkdir ~/newrelic-infra-setup Copy Change directory to the one you've just created: cd ~/newrelic-infra-setup Copy Create the newrelic-infra.yml agent config file with your New Relic license key. For config option explanations, see configuration settings. echo \"license_key: YOUR_LICENSE_KEY\" > newrelic-infra.yml Copy Create the newrelic-infra.dockerfile extending the newrelic/infrastructure image, and add your config to /etc/newrelic-infra.yml: touch newrelic-infra.dockerfile Copy vim newrelic-infra.dockerfile #you can use any text editor Copy Put the following content in the file: FROM newrelic/infrastructure:latest ADD newrelic-infra.yml /etc/newrelic-infra.yml Copy Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra build: context: . dockerfile: newrelic-infra.dockerfile cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Basic setup To use the basic setup with a base New Relic infrastructure image: Docker CLI Run the container with the required run flags: docker run \\ -d \\ --name newrelic-infra \\ --network=host \\ --cap-add=SYS_PTRACE \\ --privileged \\ --pid=host \\ -v \"/:/host:ro\" \\ -v \"/var/run/docker.sock:/var/run/docker.sock\" \\ -e NRIA_LICENSE_KEY=YOUR_LICENSE_KEY \\ newrelic/infrastructure:latest Copy For potential next steps, like how to see data in the UI, see What's next? Docker Compose Create docker-compose.yaml: touch docker-compose.yaml Copy vim docker-compose.yaml #you can use any text editor Copy Put following content in the file: version: '3' services: agent: container_name: newrelic-infra image: newrelic/infrastructure:latest cap_add: - SYS_PTRACE network_mode: host pid: host privileged: true volumes: - \"/:/host:ro\" - \"/var/run/docker.sock:/var/run/docker.sock\" environment: NRIA_LICENSE_KEY: \"YOUR_LICENSE_KEY\" restart: unless-stopped Copy Build and start docker-compose: docker-compose -f docker-compose.yaml up -d Copy For potential next steps, like how to see data in the UI, see What's next? Required container privileges Due to resource isolation from the host and other containers via Linux namespaces, a container has a very restricted view and control of its underlying host's resources by default. Without these extra privileges, the infrastructure agent cannot monitor the host and its containers. The infrastructure agent collects data about its host using system files and system calls. For more information about how the infrastructure agent collects data, see our documentation about infrastructure monitoring and security. Required privileges include: Privilege Description --network=host Sets the container's network namespace to the host's network namespace. This allows the agent to collect the network metrics about the host. -v \"/:/host:ro\" Bind mounts the host's root volume to the container. This read-only access to the host's root allows the agent to collect process and storage metrics as well as Inventory data from the host. --cap-add=SYS_PTRACE Adds the Linux capability to trace system processes. This allows the agent to gather data about processes running on the host. Read more here. --privileged --pid=host -v \"/var/run/docker.sock:/var/run/docker.sock\" Bind mounts the host's Docker daemon socket to the container. This allows the agent to connect to the Engine API via the Docker daemon socket to collect the host's container data. Next steps after install For next steps after install is completed, see What's next? Inventory collected Inventory is collected from the infrastructure agent's built-in data collectors. The infrastructure agent collects this data for Linux systems running with containers. Category Source Data collected using metadata agent_config Agent's complete config file system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name Container data Once the infrastructure agent is running in a Docker container, it can collect the same host compute data and event data that the infrastructure agent is capable of collecting when running natively on a host. For more information, see our documentation about how to view your Docker container data. Containerized agent image The containerized agent image is built from an Alpine base image. A CentOS base image is also available. Alpine is used as the base image since version 0.0.55. This is the one pointed by latest tag. Earlier versions used CentOS 7 as base image. In order to keep using that legacy image, some backports may be included there. To fetch the latest CentOS 7 based image, point to the latest-centos tag. Check the source code This integration is open source software. You can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.94724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Docker container for <em>infrastructure</em> monitoring",
        "sections": "Docker container for <em>infrastructure</em> monitoring",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> supports Docker environments by default. If you&#x27;re running a container OS or have restrictions that require deploying the <em>agent</em> as a container, you can run a containerized version of our <em>infrastructure</em> monitoring <em>agent</em>. This can monitor metrics"
      },
      "id": "6043ef6a28ccbce71b2c6062"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/macos-installation/install-infrastructure-monitoring-agent-macos": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.3142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. <em>macOS</em>: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of your distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.30742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for Windows",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for Windows allows you to tailor all aspects of the <em>installation</em>. You can place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>. You are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.08606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> overhead",
        "sections": "<em>Infrastructure</em> <em>agent</em> overhead",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host&#x27;s workload, particularly on the number of processes running on the host. This is because the <em>agent</em> collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size": [
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 364.2171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> overhead",
        "sections": "<em>Infrastructure</em> <em>agent</em> overhead",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> is a lightweight piece of software, designed to minimize its impact on the performance of <em>your</em> hosts. However, the exact load varies depending on <em>your</em> host&#x27;s workload, particularly on the number of processes running on the host. This is because the <em>agent</em> collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. macOS: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-10-18T18:55:37Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.81345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ]
}